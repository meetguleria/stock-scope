{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c0a790-3299-41b6-87b4-b191fd3efe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 : Standard Library Imports\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import joblib\n",
    "import warnings\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Third-Party Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import yfinance as yf\n",
    "import keras_tuner as kt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import ta\n",
    "from pandas.tseries.offsets import BDay\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import pandas_market_calendars as mcal\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional, Input, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, \n",
    "                             mean_absolute_percentage_error, r2_score)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import skew, kurtosis, shapiro\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67173a79-1f45-43c7-9ec7-82dddc594b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed00<?, ?it/s]\n",
      "[*********************100%%**********************]  1 of 1 completed,  2.31s/it]\n",
      "[*********************100%%**********************]  1 of 1 completed,  2.24s/it]\n",
      "[*********************100%%**********************]  1 of 1 completed,  2.24s/it]\n",
      "Fetching stocks data: 100%|███████████████████████| 4/4 [00:08<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series data fetching and saving complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Fetch the Stock Data (Time-series Only)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize dictionaries to store dataframes\n",
    "daily_data_dict = {}\n",
    "\n",
    "# List of stocks to fetch data for\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
    "\n",
    "# Define the time frames for data\n",
    "end_date = datetime.now()\n",
    "start_date_daily = end_date - timedelta(days=10*365)   # 10 years of daily data\n",
    "\n",
    "# Create directories for the data\n",
    "os.makedirs('../data/stock_data', exist_ok=True)\n",
    "\n",
    "# Function to fetch stock data\n",
    "def fetch_stock_data(ticker, start, end, interval):\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start, end=end, interval=interval)\n",
    "        if data.empty:\n",
    "            logging.warning(f\"No data retrieved for {ticker} from {start} to {end} with interval {interval}\")\n",
    "        return data.drop(columns=['Adj Close'], errors='ignore')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch and save daily time-series data\n",
    "for stock in tqdm(stocks, desc=\"Fetching stocks data\"):\n",
    "\n",
    "    # Daily Data (10 years)\n",
    "    daily_data = fetch_stock_data(stock, start_date_daily, end_date, '1d')\n",
    "    if not daily_data.empty:\n",
    "        daily_data_dict[stock] = daily_data\n",
    "        daily_data.to_csv(f'../data/stock_data/{stock}_daily.csv', index=True)\n",
    "\n",
    "    # Add a delay to avoid API rate limits\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"Time-series data fetching and saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "badb5640-0f73-4230-bff8-7416550f8dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 01:27:13,181 - INFO - 'Close' price-based technical indicators added for daily data of AAPL\n",
      "2024-10-30 01:27:13,188 - INFO - Sample features for AAPL:\n",
      "           Date        Open        High         Low       Close    Volume  \\\n",
      "2509 2024-10-23  234.080002  235.139999  227.759995  230.759995  52287000   \n",
      "2510 2024-10-24  229.979996  230.820007  228.410004  230.570007  31109500   \n",
      "2511 2024-10-25  229.740005  233.220001  229.570007  231.410004  38802300   \n",
      "2512 2024-10-28  233.320007  234.729996  232.550003  233.399994  36087100   \n",
      "2513 2024-10-29  233.100006  234.330002  232.320007  233.669998  35332800   \n",
      "\n",
      "           SMA_5      SMA_10    SMA_20       EMA_5  ...  Highest_Close_14  \\\n",
      "2509  234.049997  232.376999  229.7270  233.270769  ...        236.479996   \n",
      "2510  233.734000  232.530000  229.8795  232.370515  ...        236.479996   \n",
      "2511  233.016000  232.916000  230.0605  232.050345  ...        236.479996   \n",
      "2512  232.400000  233.125999  230.0805  232.500228  ...        236.479996   \n",
      "2513  231.962000  233.107999  230.4535  232.890151  ...        236.479996   \n",
      "\n",
      "      Lowest_Close_14  Williams_%R  EMA_5_10_Diff  EMA_5_20_Diff  Lag_Close_1  \\\n",
      "2509       221.690002   -38.674806       1.005485       3.033556   235.860001   \n",
      "2510       221.690002   -39.959372       0.413463       2.101607   230.759995   \n",
      "2511       225.770004   -47.338899       0.192756       1.672761   230.570007   \n",
      "2512       227.550003   -34.490530       0.362202       1.834796   231.410004   \n",
      "2513       227.550003   -31.466964       0.473585       1.938570   233.399994   \n",
      "\n",
      "      Lag_Close_2  Lag_Close_3  Rolling_Skew_Close_5  Rolling_Kurt_Close_5  \n",
      "2509   236.479996   235.000000             -0.585788             -2.123954  \n",
      "2510   235.860001   236.479996             -0.460781             -3.114673  \n",
      "2511   230.759995   235.860001              0.583578             -3.120002  \n",
      "2512   230.570007   230.759995              1.152873              0.194491  \n",
      "2513   231.410004   230.570007              0.437788             -3.021501  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "2024-10-30 01:27:13,201 - INFO - 'Close' price-based technical indicators added for daily data of MSFT\n",
      "2024-10-30 01:27:13,205 - INFO - Sample features for MSFT:\n",
      "           Date        Open        High         Low       Close    Volume  \\\n",
      "2509 2024-10-23  430.859985  431.079987  422.529999  424.600006  19654400   \n",
      "2510 2024-10-24  425.329987  425.980011  422.399994  424.730011  13581600   \n",
      "2511 2024-10-25  426.760010  432.519989  426.570007  428.149994  16899100   \n",
      "2512 2024-10-28  431.660004  431.940002  426.299988  426.589996  14882400   \n",
      "2513 2024-10-29  428.000000  433.170013  425.799988  431.950012  17581800   \n",
      "\n",
      "           SMA_5      SMA_10      SMA_20       EMA_5  ...  Highest_Close_14  \\\n",
      "2509  421.154004  419.193002  419.684500  422.252034  ...        427.510010   \n",
      "2510  422.756006  420.082004  419.355501  423.078026  ...        427.510010   \n",
      "2511  424.754004  421.265002  419.362001  424.768682  ...        428.149994   \n",
      "2512  426.316003  422.010001  419.176501  425.375787  ...        428.149994   \n",
      "2513  427.204004  423.331003  419.739502  427.567195  ...        431.950012   \n",
      "\n",
      "      Lowest_Close_14  Williams_%R  EMA_5_10_Diff  EMA_5_20_Diff  Lag_Close_1  \\\n",
      "2509       409.540009   -16.193675       1.646248       1.797626   427.510010   \n",
      "2510       409.540009   -15.470220       1.722381       2.216418   424.600006   \n",
      "2511       414.709991    -0.000000       2.177701       3.212942   424.730011   \n",
      "2512       415.839996   -12.672607       2.057712       3.340594   428.149994   \n",
      "2513       415.839996    -0.000000       2.679677       4.587734   426.589996   \n",
      "\n",
      "      Lag_Close_2  Lag_Close_3  Rolling_Skew_Close_5  Rolling_Kurt_Close_5  \n",
      "2509   418.779999   418.160004              0.705217             -1.932473  \n",
      "2510   427.510010   418.779999             -0.235099             -2.475652  \n",
      "2511   424.600006   427.510010             -1.256666              1.737974  \n",
      "2512   424.730011   424.600006             -0.115645             -2.680677  \n",
      "2513   428.149994   424.730011              1.120309              0.787774  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "2024-10-30 01:27:13,215 - INFO - 'Close' price-based technical indicators added for daily data of GOOGL\n",
      "2024-10-30 01:27:13,218 - INFO - Sample features for GOOGL:\n",
      "           Date        Open        High         Low       Close    Volume  \\\n",
      "2509 2024-10-23  164.759995  165.820007  161.929993  162.779999  18280500   \n",
      "2510 2024-10-24  162.830002  163.330002  161.009995  162.720001  22412500   \n",
      "2511 2024-10-25  163.669998  165.589996  163.419998  165.270004  19828900   \n",
      "2512 2024-10-28  168.750000  168.750000  163.949997  166.720001  32138600   \n",
      "2513 2024-10-29  167.729996  170.380005  167.089996  169.679993  41612900   \n",
      "\n",
      "           SMA_5      SMA_10      SMA_20       EMA_5  ...  Highest_Close_14  \\\n",
      "2509  163.667999  163.924002  164.338001  163.811581  ...        167.059998   \n",
      "2510  163.626001  163.988002  164.337502  163.447721  ...        165.460007   \n",
      "2511  163.996002  164.191002  164.403502  164.055149  ...        165.460007   \n",
      "2512  164.526001  164.367001  164.447002  164.943433  ...        166.720001   \n",
      "2513  165.434000  164.789000  164.581501  166.522286  ...        169.679993   \n",
      "\n",
      "      Lowest_Close_14  Williams_%R  EMA_5_10_Diff  EMA_5_20_Diff  Lag_Close_1  \\\n",
      "2509       161.860001   -82.307717      -0.091526       0.256868   165.139999   \n",
      "2510       161.860001   -76.111135      -0.240275      -0.027495   162.779999   \n",
      "2511       161.860001    -5.277837       0.079514       0.409000   162.720001   \n",
      "2512       161.860001    -0.000000       0.468823       1.004537   165.270004   \n",
      "2513       162.080002    -0.000000       1.101243       2.036619   166.720001   \n",
      "\n",
      "      Lag_Close_2  Lag_Close_3  Rolling_Skew_Close_5  Rolling_Kurt_Close_5  \n",
      "2509   164.070007   163.419998              0.991594              0.142442  \n",
      "2510   165.139999   164.070007              0.893666             -0.168780  \n",
      "2511   162.779999   165.139999             -0.069590             -2.971679  \n",
      "2512   162.720001   162.779999             -0.000702             -2.005598  \n",
      "2513   165.270004   162.720001              0.668809             -0.584208  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "2024-10-30 01:27:13,227 - INFO - 'Close' price-based technical indicators added for daily data of AMZN\n",
      "2024-10-30 01:27:13,230 - INFO - Sample features for AMZN:\n",
      "           Date        Open        High         Low       Close    Volume  \\\n",
      "2509 2024-10-23  188.850006  189.160004  183.690002  184.710007  31937100   \n",
      "2510 2024-10-24  185.250000  187.110001  183.860001  186.380005  21647400   \n",
      "2511 2024-10-25  187.850006  190.449997  187.529999  187.830002  29362100   \n",
      "2512 2024-10-28  189.570007  190.210007  188.210007  188.389999  27930800   \n",
      "2513 2024-10-29  188.580002  191.460007  187.820007  190.830002  35534000   \n",
      "\n",
      "           SMA_5      SMA_10      SMA_20       EMA_5  ...  Highest_Close_14  \\\n",
      "2509  188.000003  187.759001  186.505001  187.371135  ...        189.699997   \n",
      "2510  187.770004  187.732002  186.266001  187.040759  ...        189.699997   \n",
      "2511  187.538004  187.633002  186.259001  187.303840  ...        189.699997   \n",
      "2512  187.402002  187.718002  186.362001  187.665893  ...        189.699997   \n",
      "2513  187.628003  188.032002  186.647001  188.720596  ...        190.830002   \n",
      "\n",
      "      Lowest_Close_14  Williams_%R  EMA_5_10_Diff  EMA_5_20_Diff  Lag_Close_1  \\\n",
      "2509       180.800003   -56.067344       0.054008       0.683657   189.699997   \n",
      "2510       180.800003   -37.303307      -0.105983       0.382563   184.710007   \n",
      "2511       182.720001   -26.790777       0.032869       0.534044   186.380005   \n",
      "2512       184.710007   -26.252507       0.191463       0.741792   187.830002   \n",
      "2513       184.710007    -0.000000       0.636062       1.424504   188.389999   \n",
      "\n",
      "      Lag_Close_2  Lag_Close_3  Rolling_Skew_Close_5  Rolling_Kurt_Close_5  \n",
      "2509   189.070007   188.990005             -1.481593              1.912489  \n",
      "2510   189.699997   189.070007             -0.864547             -1.336046  \n",
      "2511   184.710007   189.699997             -0.522014             -1.113179  \n",
      "2512   186.380005   184.710007             -0.436133             -0.398613  \n",
      "2513   187.830002   186.380005              0.225679              0.222597  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete. Data is ready for splitting into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature Engineering\n",
    "\n",
    "def add_close_price_features(df):\n",
    "    # Ensure the 'Close' column is numeric\n",
    "    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with NaN 'Close' values\n",
    "    df.dropna(subset=['Close'], inplace=True)\n",
    "    \n",
    "    # Sort by 'Date' if not already sorted\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Moving Averages with min_periods\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5, min_periods=1).mean()\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10, min_periods=1).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20, min_periods=1).mean()\n",
    "    df['EMA_5'] = df['Close'].ewm(span=5, adjust=False, min_periods=1).mean()\n",
    "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False, min_periods=1).mean()\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False, min_periods=1).mean()\n",
    "\n",
    "    # Momentum Indicators\n",
    "    df['Momentum_5'] = df['Close'] - df['Close'].shift(5)\n",
    "    df['Momentum_10'] = df['Close'] - df['Close'].shift(10)\n",
    "    df['ROC_5'] = df['Close'].pct_change(periods=5)\n",
    "    df['ROC_10'] = df['Close'].pct_change(periods=10)\n",
    "    \n",
    "    # Volatility Indicators with min_periods\n",
    "    df['Volatility_5'] = df['Close'].rolling(window=5, min_periods=1).std()\n",
    "    df['Volatility_10'] = df['Close'].rolling(window=10, min_periods=1).std()\n",
    "    \n",
    "    # Relative Strength Index (RSI) with min_periods\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    average_gain = gain.rolling(window=14, min_periods=1).mean()\n",
    "    average_loss = loss.rolling(window=14, min_periods=1).mean()\n",
    "    rs = average_gain / (average_loss + 1e-10)  # Add small constant to avoid division by zero\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False, min_periods=1).mean()\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False, min_periods=1).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False, min_periods=1).mean()\n",
    "    df['MACD_diff'] = df['MACD'] - df['MACD_signal']\n",
    "    \n",
    "    # Bollinger Bands with min_periods\n",
    "    df['Middle_Band'] = df['Close'].rolling(window=20, min_periods=1).mean()\n",
    "    df['Std_Dev'] = df['Close'].rolling(window=20, min_periods=1).std()\n",
    "    df['Upper_Band'] = df['Middle_Band'] + (df['Std_Dev'] * 2)\n",
    "    df['Lower_Band'] = df['Middle_Band'] - (df['Std_Dev'] * 2)\n",
    "    df['Bollinger_Width'] = df['Upper_Band'] - df['Lower_Band']\n",
    "    \n",
    "    # Percent B (%B) Indicator\n",
    "    df['Percent_B'] = (df['Close'] - df['Lower_Band']) / (df['Upper_Band'] - df['Lower_Band'] + 1e-10)\n",
    "    \n",
    "    # Simplified Williams %R with min_periods\n",
    "    df['Highest_Close_14'] = df['Close'].rolling(window=14, min_periods=1).max()\n",
    "    df['Lowest_Close_14'] = df['Close'].rolling(window=14, min_periods=1).min()\n",
    "    df['Williams_%R'] = ((df['Highest_Close_14'] - df['Close']) / (df['Highest_Close_14'] - df['Lowest_Close_14'] + 1e-10)) * -100\n",
    "    \n",
    "    # Exponential Moving Average Differences\n",
    "    df['EMA_5_10_Diff'] = df['EMA_5'] - df['EMA_10']\n",
    "    df['EMA_5_20_Diff'] = df['EMA_5'] - df['EMA_20']\n",
    "    \n",
    "    # Lag Features\n",
    "    df['Lag_Close_1'] = df['Close'].shift(1)\n",
    "    df['Lag_Close_2'] = df['Close'].shift(2)\n",
    "    df['Lag_Close_3'] = df['Close'].shift(3)\n",
    "    \n",
    "    # Rolling Statistics with min_periods\n",
    "    df['Rolling_Skew_Close_5'] = df['Close'].rolling(window=5, min_periods=1).skew()\n",
    "    df['Rolling_Kurt_Close_5'] = df['Close'].rolling(window=5, min_periods=1).kurt()\n",
    "    \n",
    "    # Handle NaN values appropriately\n",
    "    # Replace deprecated fillna methods with ffill() and bfill()\n",
    "    df.ffill(inplace=True)\n",
    "    df.bfill(inplace=True)\n",
    "    \n",
    "    # Reset index after processing\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to each stock's daily data\n",
    "for stock in stocks:\n",
    "    df_daily = daily_data_dict[stock].copy()\n",
    "    \n",
    "    # Reset index if 'Date' is not a column\n",
    "    if 'Date' not in df_daily.columns:\n",
    "        df_daily.reset_index(inplace=True)\n",
    "    \n",
    "    # Ensure 'Date' is of datetime type\n",
    "    df_daily['Date'] = pd.to_datetime(df_daily['Date'])\n",
    "    \n",
    "    # Sort by 'Date'\n",
    "    df_daily.sort_values('Date', inplace=True)\n",
    "    df_daily.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add enhanced 'Close' price-based features\n",
    "    df_daily_with_features = add_close_price_features(df_daily)\n",
    "    \n",
    "    # Log information\n",
    "    logging.info(f\"'Close' price-based technical indicators added for daily data of {stock}\")\n",
    "    logging.info(f\"Sample features for {stock}:\\n{df_daily_with_features.tail(5)}\")\n",
    "    \n",
    "    # Update the dictionary\n",
    "    daily_data_dict[stock] = df_daily_with_features\n",
    "\n",
    "print(\"Feature engineering complete. Data is ready for splitting into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511950f3-3177-4ab3-a9fb-299b9ab837e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 01:27:13,241 - INFO - Data for AAPL has been split into training and testing sets.\n",
      "2024-10-30 01:27:13,243 - INFO - Data for MSFT has been split into training and testing sets.\n",
      "2024-10-30 01:27:13,245 - INFO - Data for GOOGL has been split into training and testing sets.\n",
      "2024-10-30 01:27:13,246 - INFO - Data for AMZN has been split into training and testing sets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying Data Splitting:\n",
      "Verifying data split for AAPL:\n",
      " - Training set size: 2011 samples\n",
      " - Testing set size: 503 samples\n",
      " - Number of features: 36\n",
      " - Feature columns:\n",
      "['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "Verifying data split for MSFT:\n",
      " - Training set size: 2011 samples\n",
      " - Testing set size: 503 samples\n",
      " - Number of features: 36\n",
      " - Feature columns:\n",
      "['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "Verifying data split for GOOGL:\n",
      " - Training set size: 2011 samples\n",
      " - Testing set size: 503 samples\n",
      " - Number of features: 36\n",
      " - Feature columns:\n",
      "['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "Verifying data split for AMZN:\n",
      " - Training set size: 2011 samples\n",
      " - Testing set size: 503 samples\n",
      " - Number of features: 36\n",
      " - Feature columns:\n",
      "['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Data splitting complete. Ready for scaling in the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Splitting Data into Training and Testing Sets (Modified to Include 'test_dates')\n",
    "\n",
    "# Function to split time series data\n",
    "def split_time_series_data(df, date_column='Date', target_column='Close', split_ratio=0.8):\n",
    "    # Sort the DataFrame by the date/time column\n",
    "    df_sorted = df.sort_values(by=date_column).reset_index(drop=True)\n",
    "    \n",
    "    # Determine the split index\n",
    "    split_index = int(len(df_sorted) * split_ratio)\n",
    "    \n",
    "    # Split the data\n",
    "    train_df = df_sorted.iloc[:split_index]\n",
    "    test_df = df_sorted.iloc[split_index:]\n",
    "\n",
    "    # Prepare features and target\n",
    "    feature_cols = [col for col in df.columns if col not in [date_column, target_column]]\n",
    "    \n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[target_column]\n",
    "    \n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[target_column]\n",
    "    \n",
    "    # Extract 'test_dates'\n",
    "    test_dates = test_df[date_column].reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, feature_cols, test_dates\n",
    "\n",
    "# Initialize a dictionary to hold split data for each stock\n",
    "split_data_dict = {}\n",
    "\n",
    "# Apply the function to each stock's data\n",
    "for stock in stocks:\n",
    "    df = daily_data_dict[stock].copy()\n",
    "    \n",
    "    # Verify that the DataFrame is not empty\n",
    "    if df.empty:\n",
    "        logging.warning(f\"The DataFrame for {stock} is empty. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test, feature_cols, test_dates = split_time_series_data(\n",
    "        df,\n",
    "        date_column='Date',\n",
    "        target_column='Close',\n",
    "        split_ratio=0.8\n",
    "    )\n",
    "    \n",
    "    # Store the split data in the dictionary\n",
    "    split_data_dict[stock] = {\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'feature_columns': feature_cols,\n",
    "        'test_dates': test_dates  # Include 'test_dates'\n",
    "    }\n",
    "    \n",
    "    logging.info(f\"Data for {stock} has been split into training and testing sets.\")\n",
    "\n",
    "# Function to verify the split data\n",
    "def verify_split(split_dict, stocks):\n",
    "    for stock in stocks:\n",
    "        data = split_dict.get(stock)\n",
    "        if data is None:\n",
    "            print(f\"No data found for {stock}.\")\n",
    "            continue\n",
    "        \n",
    "        X_train = data.get('X_train')\n",
    "        X_test = data.get('X_test')\n",
    "        y_train = data.get('y_train')\n",
    "        y_test = data.get('y_test')\n",
    "        feature_columns = data.get('feature_columns', [])\n",
    "        test_dates = data.get('test_dates', None)\n",
    "        \n",
    "        # Check if any of the datasets are None or empty\n",
    "        if X_train is None or X_train.empty:\n",
    "            print(f\"X_train is None or empty for {stock}.\")\n",
    "            continue\n",
    "        if X_test is None or X_test.empty:\n",
    "            print(f\"X_test is None or empty for {stock}.\")\n",
    "            continue\n",
    "        if y_train is None or y_train.empty:\n",
    "            print(f\"y_train is None or empty for {stock}.\")\n",
    "            continue\n",
    "        if y_test is None or y_test.empty:\n",
    "            print(f\"y_test is None or empty for {stock}.\")\n",
    "            continue\n",
    "        if test_dates is None or test_dates.empty:\n",
    "            print(f\"test_dates is None or empty for {stock}.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Verifying data split for {stock}:\")\n",
    "        print(f\" - Training set size: {X_train.shape[0]} samples\")\n",
    "        print(f\" - Testing set size: {X_test.shape[0]} samples\")\n",
    "        print(f\" - Number of features: {len(feature_columns)}\")\n",
    "        print(f\" - Feature columns:\\n{feature_columns}\")\n",
    "        print(f\" - Test Dates (first 5): {test_dates.head().tolist()}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Verify the data splitting for each stock\n",
    "print(\"\\nVerifying Data Splitting:\")\n",
    "verify_split(split_data_dict, stocks)\n",
    "\n",
    "print(\"\\nData splitting complete. Ready for scaling in the next cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f740aa-6edf-4a11-a4be-e704ad21db5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 01:27:13,255 - INFO - Starting to scale Daily Data with target...\n",
      "2024-10-30 01:27:13,256 - INFO - Scaling data for AAPL...\n",
      "2024-10-30 01:27:13,262 - INFO - Scalers saved for AAPL at ../models/scalers/minmax_scaler_X_AAPL.joblib and ../models/scalers/minmax_scaler_y_AAPL.joblib.\n",
      "2024-10-30 01:27:13,262 - INFO - 'test_dates' found for AAPL. Including in scaled data.\n",
      "2024-10-30 01:27:13,262 - INFO - Completed scaling for AAPL.\n",
      "2024-10-30 01:27:13,262 - INFO - Scaling data for MSFT...\n",
      "2024-10-30 01:27:13,271 - INFO - Scalers saved for MSFT at ../models/scalers/minmax_scaler_X_MSFT.joblib and ../models/scalers/minmax_scaler_y_MSFT.joblib.\n",
      "2024-10-30 01:27:13,272 - INFO - 'test_dates' found for MSFT. Including in scaled data.\n",
      "2024-10-30 01:27:13,272 - INFO - Completed scaling for MSFT.\n",
      "2024-10-30 01:27:13,272 - INFO - Scaling data for GOOGL...\n",
      "2024-10-30 01:27:13,279 - INFO - Scalers saved for GOOGL at ../models/scalers/minmax_scaler_X_GOOGL.joblib and ../models/scalers/minmax_scaler_y_GOOGL.joblib.\n",
      "2024-10-30 01:27:13,280 - INFO - 'test_dates' found for GOOGL. Including in scaled data.\n",
      "2024-10-30 01:27:13,280 - INFO - Completed scaling for GOOGL.\n",
      "2024-10-30 01:27:13,281 - INFO - Scaling data for AMZN...\n",
      "2024-10-30 01:27:13,286 - INFO - Scalers saved for AMZN at ../models/scalers/minmax_scaler_X_AMZN.joblib and ../models/scalers/minmax_scaler_y_AMZN.joblib.\n",
      "2024-10-30 01:27:13,286 - INFO - 'test_dates' found for AMZN. Including in scaled data.\n",
      "2024-10-30 01:27:13,286 - INFO - Completed scaling for AMZN.\n",
      "2024-10-30 01:27:13,287 - INFO - Completed scaling Daily Data with target.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying Scaled Data for Daily Data (Including 'test_dates'):\n",
      "Scaled data for AAPL:\n",
      " - Scaled Training set shape: (2011, 36), Scaled Training targets shape: (2011,)\n",
      " - Scaled Testing set shape: (503, 36), Scaled Testing targets shape: (503,)\n",
      " - Feature columns: ['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "Scaled data for MSFT:\n",
      " - Scaled Training set shape: (2011, 36), Scaled Training targets shape: (2011,)\n",
      " - Scaled Testing set shape: (503, 36), Scaled Testing targets shape: (503,)\n",
      " - Feature columns: ['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "Scaled data for GOOGL:\n",
      " - Scaled Training set shape: (2011, 36), Scaled Training targets shape: (2011,)\n",
      " - Scaled Testing set shape: (503, 36), Scaled Testing targets shape: (503,)\n",
      " - Feature columns: ['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n",
      "Scaled data for AMZN:\n",
      " - Scaled Training set shape: (2011, 36), Scaled Training targets shape: (2011,)\n",
      " - Scaled Testing set shape: (503, 36), Scaled Testing targets shape: (503,)\n",
      " - Feature columns: ['Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20', 'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10', 'Volatility_5', 'Volatility_10', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'Middle_Band', 'Std_Dev', 'Upper_Band', 'Lower_Band', 'Bollinger_Width', 'Percent_B', 'Highest_Close_14', 'Lowest_Close_14', 'Williams_%R', 'EMA_5_10_Diff', 'EMA_5_20_Diff', 'Lag_Close_1', 'Lag_Close_2', 'Lag_Close_3', 'Rolling_Skew_Close_5', 'Rolling_Kurt_Close_5']\n",
      " - Test Dates (first 5): [Timestamp('2022-10-28 00:00:00'), Timestamp('2022-10-31 00:00:00'), Timestamp('2022-11-01 00:00:00'), Timestamp('2022-11-02 00:00:00'), Timestamp('2022-11-03 00:00:00')]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Scaling the Data Using MinMaxScaler\n",
    "\n",
    "# Function to scale data using MinMaxScaler for both features and targets\n",
    "def scale_data_with_target(split_data_dict):\n",
    "    scaled_data_dict = {}\n",
    "\n",
    "    # Directories to save scalers\n",
    "    scaler_save_dir = '../models/scalers'\n",
    "    os.makedirs(scaler_save_dir, exist_ok=True)\n",
    "    \n",
    "    for stock, data in split_data_dict.items():\n",
    "        logging.info(f\"Scaling data for {stock}...\")\n",
    "        \n",
    "        X_train = data['X_train']\n",
    "        X_test = data['X_test']\n",
    "        y_train = data['y_train'].values.reshape(-1, 1)  # Reshape for scaler\n",
    "        y_test = data['y_test'].values.reshape(-1, 1)\n",
    "        test_dates = data.get('test_dates')  # Retrieve 'test_dates'\n",
    "        \n",
    "        # Initialize scalers\n",
    "        scaler_X = MinMaxScaler()\n",
    "        scaler_y = MinMaxScaler()\n",
    "        \n",
    "        # Fit scalers on training data and transform both training and testing data\n",
    "        X_train_scaled = pd.DataFrame(scaler_X.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "        X_test_scaled = pd.DataFrame(scaler_X.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "        \n",
    "        y_train_scaled = scaler_y.fit_transform(y_train).flatten()  # Flatten to 1D array\n",
    "        y_test_scaled = scaler_y.transform(y_test).flatten()\n",
    "        \n",
    "        # Save scalers using joblib\n",
    "        scaler_X_path = os.path.join(scaler_save_dir, f'minmax_scaler_X_{stock}.joblib')\n",
    "        scaler_y_path = os.path.join(scaler_save_dir, f'minmax_scaler_y_{stock}.joblib')\n",
    "        joblib.dump(scaler_X, scaler_X_path)\n",
    "        joblib.dump(scaler_y, scaler_y_path)\n",
    "        logging.info(f\"Scalers saved for {stock} at {scaler_X_path} and {scaler_y_path}.\")\n",
    "        \n",
    "        # ----- Include 'test_dates' -----\n",
    "        if test_dates is not None and not test_dates.empty:\n",
    "            logging.info(f\"'test_dates' found for {stock}. Including in scaled data.\")\n",
    "        else:\n",
    "            logging.warning(f\"No 'test_dates' found for {stock}. Creating dummy dates.\")\n",
    "            test_dates = pd.date_range(start='2020-01-01', periods=len(y_test_scaled), freq='D')\n",
    "        \n",
    "        # Update the scaled data dictionary with 'test_dates'\n",
    "        scaled_data_dict[stock] = {\n",
    "            'X_train_scaled': X_train_scaled,\n",
    "            'X_test_scaled': X_test_scaled,\n",
    "            'y_train_scaled': y_train_scaled,\n",
    "            'y_test_scaled': y_test_scaled,\n",
    "            'scaler_X': scaler_X,\n",
    "            'scaler_y': scaler_y,\n",
    "            'feature_columns': data['feature_columns'],\n",
    "            'test_dates': test_dates  # Include 'test_dates'\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"Completed scaling for {stock}.\")\n",
    "    \n",
    "    return scaled_data_dict\n",
    "\n",
    "# Scale the split daily data with target\n",
    "logging.info(\"Starting to scale Daily Data with target...\")\n",
    "scaled_daily_data = scale_data_with_target(split_data_dict)\n",
    "logging.info(\"Completed scaling Daily Data with target.\")\n",
    "\n",
    "# Verification\n",
    "print(\"\\nVerifying Scaled Data for Daily Data (Including 'test_dates'):\")\n",
    "for stock in scaled_daily_data.keys():\n",
    "    data = scaled_daily_data[stock]\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_train_scaled = data['y_train_scaled']\n",
    "    y_test_scaled = data['y_test_scaled']\n",
    "    test_dates = data['test_dates']\n",
    "    \n",
    "    print(f\"Scaled data for {stock}:\")\n",
    "    print(f\" - Scaled Training set shape: {X_train_scaled.shape}, Scaled Training targets shape: {y_train_scaled.shape}\")\n",
    "    print(f\" - Scaled Testing set shape: {X_test_scaled.shape}, Scaled Testing targets shape: {y_test_scaled.shape}\")\n",
    "    print(f\" - Feature columns: {X_train_scaled.columns.tolist()}\")\n",
    "    \n",
    "    # Handle 'test_dates' based on its type\n",
    "    if isinstance(test_dates, pd.DatetimeIndex):\n",
    "        # Slice the first five dates and convert to a list\n",
    "        test_dates_list = test_dates[:5].tolist()\n",
    "    elif isinstance(test_dates, pd.Series):\n",
    "        # Use head() if it's a Series\n",
    "        test_dates_list = test_dates.head(5).tolist()\n",
    "    else:\n",
    "        # Convert to list and slice if it's another type\n",
    "        test_dates_list = list(test_dates)[:5]\n",
    "    \n",
    "    print(f\" - Test Dates (first 5): {test_dates_list}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6b973a-a31f-49e0-a6c0-e30aa9181a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training LSTM Model for AAPL\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m17,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0258\n",
      "Epoch 1: val_loss improved from inf to 0.00551, saving model to ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0255 - val_loss: 0.0055\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0026\n",
      "Epoch 2: val_loss did not improve from 0.00551\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 0.0103\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022\n",
      "Epoch 3: val_loss improved from 0.00551 to 0.00426, saving model to ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019\n",
      "Epoch 4: val_loss did not improve from 0.00426\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0102\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015\n",
      "Epoch 5: val_loss improved from 0.00426 to 0.00345, saving model to ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014\n",
      "Epoch 6: val_loss did not improve from 0.00345\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 7: val_loss improved from 0.00345 to 0.00258, saving model to ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014\n",
      "Epoch 8: val_loss did not improve from 0.00258\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0013\n",
      "Epoch 9: val_loss did not improve from 0.00258\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 10: val_loss did not improve from 0.00258\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6578e-04\n",
      "Epoch 11: val_loss did not improve from 0.00258\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.6566e-04 - val_loss: 0.0030\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010\n",
      "Epoch 12: val_loss did not improve from 0.00258\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.0990e-04\n",
      "Epoch 13: val_loss improved from 0.00258 to 0.00127, saving model to ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 9.1138e-04 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.8195e-04\n",
      "Epoch 14: val_loss did not improve from 0.00127\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.8120e-04 - val_loss: 0.0021\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.6879e-04\n",
      "Epoch 15: val_loss did not improve from 0.00127\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.6880e-04 - val_loss: 0.0032\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.0352e-04\n",
      "Epoch 16: val_loss did not improve from 0.00127\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.0411e-04 - val_loss: 0.0031\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.9326e-04\n",
      "Epoch 17: val_loss improved from 0.00127 to 0.00109, saving model to ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.9285e-04 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.7076e-04\n",
      "Epoch 18: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.6980e-04 - val_loss: 0.0037\n",
      "Epoch 19/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.1034e-04\n",
      "Epoch 19: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.1613e-04 - val_loss: 0.0015\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010\n",
      "Epoch 20: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0078\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.8976e-04\n",
      "Epoch 21: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.8809e-04 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.4340e-04\n",
      "Epoch 22: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.4425e-04 - val_loss: 0.0020\n",
      "Epoch 23/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.3820e-04\n",
      "Epoch 23: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.3944e-04 - val_loss: 0.0032\n",
      "Epoch 24/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 24: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.8904e-04\n",
      "Epoch 25: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.8753e-04 - val_loss: 0.0020\n",
      "Epoch 26/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.0946e-04\n",
      "Epoch 26: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.0996e-04 - val_loss: 0.0039\n",
      "Epoch 27/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.0165e-04\n",
      "Epoch 27: val_loss did not improve from 0.00109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.0287e-04 - val_loss: 0.0025\n",
      " - Loaded best model from ../models/lstm_models/lstm_AAPL_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for AAPL: RMSE = 11.7514, MAE = 8.4938, R2 = 0.7316\n",
      "Model training and evaluation completed for AAPL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training LSTM Model for MSFT\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m17,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0408\n",
      "Epoch 1: val_loss improved from inf to 0.00422, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0395 - val_loss: 0.0042\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029\n",
      "Epoch 2: val_loss improved from 0.00422 to 0.00387, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028\n",
      "Epoch 3: val_loss improved from 0.00387 to 0.00304, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 4: val_loss improved from 0.00304 to 0.00173, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019\n",
      "Epoch 5: val_loss improved from 0.00173 to 0.00157, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 6: val_loss improved from 0.00157 to 0.00151, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018\n",
      "Epoch 7: val_loss did not improve from 0.00151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015\n",
      "Epoch 8: val_loss did not improve from 0.00151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016\n",
      "Epoch 9: val_loss did not improve from 0.00151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0013\n",
      "Epoch 10: val_loss did not improve from 0.00151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 11: val_loss did not improve from 0.00151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 12/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011\n",
      "Epoch 12: val_loss improved from 0.00151 to 0.00137, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0012\n",
      "Epoch 13: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010\n",
      "Epoch 14: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.9211e-04\n",
      "Epoch 15: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.9347e-04 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0010\n",
      "Epoch 16: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.4341e-04\n",
      "Epoch 17: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.4513e-04 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.8137e-04\n",
      "Epoch 18: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.8277e-04 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6549e-04\n",
      "Epoch 19: val_loss did not improve from 0.00137\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.6602e-04 - val_loss: 0.0025\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.2547e-04\n",
      "Epoch 20: val_loss improved from 0.00137 to 0.00131, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.2522e-04 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.6999e-04\n",
      "Epoch 21: val_loss did not improve from 0.00131\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.7423e-04 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.5981e-04\n",
      "Epoch 22: val_loss did not improve from 0.00131\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.5973e-04 - val_loss: 0.0016\n",
      "Epoch 23/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.7447e-04\n",
      "Epoch 23: val_loss did not improve from 0.00131\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.7207e-04 - val_loss: 0.0027\n",
      "Epoch 24/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.1950e-04\n",
      "Epoch 24: val_loss improved from 0.00131 to 0.00128, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.1951e-04 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5986e-04\n",
      "Epoch 25: val_loss did not improve from 0.00128\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.6221e-04 - val_loss: 0.0018\n",
      "Epoch 26/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.7242e-04\n",
      "Epoch 26: val_loss did not improve from 0.00128\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.7160e-04 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.5605e-04\n",
      "Epoch 27: val_loss did not improve from 0.00128\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.5651e-04 - val_loss: 0.0023\n",
      "Epoch 28/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.0561e-04\n",
      "Epoch 28: val_loss did not improve from 0.00128\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.0668e-04 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.2301e-04\n",
      "Epoch 29: val_loss improved from 0.00128 to 0.00117, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.2773e-04 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5134e-04\n",
      "Epoch 30: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.5207e-04 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1958e-04\n",
      "Epoch 31: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.2121e-04 - val_loss: 0.0025\n",
      "Epoch 32/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.6876e-04\n",
      "Epoch 32: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.6870e-04 - val_loss: 0.0024\n",
      "Epoch 33/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4978e-04\n",
      "Epoch 33: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.4907e-04 - val_loss: 0.0015\n",
      "Epoch 34/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2315e-04\n",
      "Epoch 34: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.2282e-04 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4269e-04\n",
      "Epoch 35: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4504e-04 - val_loss: 0.0014\n",
      "Epoch 36/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0623e-04\n",
      "Epoch 36: val_loss improved from 0.00117 to 0.00111, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.0282e-04 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9714e-04\n",
      "Epoch 37: val_loss improved from 0.00111 to 0.00108, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.9750e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4577e-04\n",
      "Epoch 38: val_loss did not improve from 0.00108\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4629e-04 - val_loss: 0.0022\n",
      "Epoch 39/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8485e-04\n",
      "Epoch 39: val_loss did not improve from 0.00108\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.8498e-04 - val_loss: 0.0014\n",
      "Epoch 40/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2705e-04\n",
      "Epoch 40: val_loss did not improve from 0.00108\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.2928e-04 - val_loss: 0.0025\n",
      "Epoch 41/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.6327e-04\n",
      "Epoch 41: val_loss improved from 0.00108 to 0.00099, saving model to ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.6128e-04 - val_loss: 9.8539e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9435e-04\n",
      "Epoch 42: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.9597e-04 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3841e-04\n",
      "Epoch 43: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.3814e-04 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0966e-04\n",
      "Epoch 44: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.1334e-04 - val_loss: 0.0030\n",
      "Epoch 45/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7663e-04\n",
      "Epoch 45: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.7793e-04 - val_loss: 0.0041\n",
      "Epoch 46/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.1512e-04\n",
      "Epoch 46: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.1352e-04 - val_loss: 0.0021\n",
      "Epoch 47/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2770e-04\n",
      "Epoch 47: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2895e-04 - val_loss: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.2086e-04\n",
      "Epoch 48: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.2212e-04 - val_loss: 0.0038\n",
      "Epoch 49/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7827e-04\n",
      "Epoch 49: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.7779e-04 - val_loss: 0.0019\n",
      "Epoch 50/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8314e-04\n",
      "Epoch 50: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.8438e-04 - val_loss: 0.0028\n",
      "Epoch 51/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8695e-04\n",
      "Epoch 51: val_loss did not improve from 0.00099\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.8817e-04 - val_loss: 0.0018\n",
      " - Loaded best model from ../models/lstm_models/lstm_MSFT_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for MSFT: RMSE = 41.9165, MAE = 35.8593, R2 = 0.4687\n",
      "Model training and evaluation completed for MSFT.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training LSTM Model for GOOGL\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m17,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0207\n",
      "Epoch 1: val_loss improved from inf to 0.00319, saving model to ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0202 - val_loss: 0.0032\n",
      "Epoch 2/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031\n",
      "Epoch 2: val_loss improved from 0.00319 to 0.00230, saving model to ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 3: val_loss improved from 0.00230 to 0.00187, saving model to ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016\n",
      "Epoch 4: val_loss improved from 0.00187 to 0.00145, saving model to ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015\n",
      "Epoch 5: val_loss did not improve from 0.00145\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016\n",
      "Epoch 6: val_loss did not improve from 0.00145\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0014\n",
      "Epoch 7: val_loss improved from 0.00145 to 0.00135, saving model to ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 8/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013\n",
      "Epoch 8: val_loss did not improve from 0.00135\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010\n",
      "Epoch 9: val_loss did not improve from 0.00135\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0013\n",
      "Epoch 10: val_loss did not improve from 0.00135\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 11/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0012\n",
      "Epoch 11: val_loss did not improve from 0.00135\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011\n",
      "Epoch 12: val_loss did not improve from 0.00135\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 13: val_loss improved from 0.00135 to 0.00121, saving model to ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.9992e-04\n",
      "Epoch 14: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.2347e-04\n",
      "Epoch 15: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.2420e-04 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.2340e-04\n",
      "Epoch 16: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.2364e-04 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.7219e-04\n",
      "Epoch 17: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.7360e-04 - val_loss: 0.0013\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6103e-04\n",
      "Epoch 18: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.6088e-04 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1583e-04\n",
      "Epoch 19: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.1604e-04 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.3944e-04\n",
      "Epoch 20: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.4042e-04 - val_loss: 0.0014\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.1511e-04\n",
      "Epoch 21: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.1507e-04 - val_loss: 0.0016\n",
      "Epoch 22/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.2508e-04\n",
      "Epoch 22: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.2468e-04 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3003e-04\n",
      "Epoch 23: val_loss did not improve from 0.00121\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.2994e-04 - val_loss: 0.0016\n",
      " - Loaded best model from ../models/lstm_models/lstm_GOOGL_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for GOOGL: RMSE = 10.9816, MAE = 9.1367, R2 = 0.8016\n",
      "Model training and evaluation completed for GOOGL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training LSTM Model for AMZN\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m17,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,901</span> (151.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,901\u001b[0m (151.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0489\n",
      "Epoch 1: val_loss improved from inf to 0.01439, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0473 - val_loss: 0.0144\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042\n",
      "Epoch 2: val_loss improved from 0.01439 to 0.00321, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033\n",
      "Epoch 3: val_loss did not improve from 0.00321\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025\n",
      "Epoch 4: val_loss improved from 0.00321 to 0.00270, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0028\n",
      "Epoch 5: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 6: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021\n",
      "Epoch 7: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019\n",
      "Epoch 8: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 9: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017\n",
      "Epoch 10: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015\n",
      "Epoch 11: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018\n",
      "Epoch 12: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 13/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013\n",
      "Epoch 13: val_loss did not improve from 0.00270\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0012\n",
      "Epoch 14: val_loss improved from 0.00270 to 0.00260, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015\n",
      "Epoch 15: val_loss did not improve from 0.00260\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014\n",
      "Epoch 16: val_loss improved from 0.00260 to 0.00239, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011\n",
      "Epoch 17: val_loss did not improve from 0.00239\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 18: val_loss did not improve from 0.00239\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010\n",
      "Epoch 19: val_loss did not improve from 0.00239\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 20: val_loss did not improve from 0.00239\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.8605e-04\n",
      "Epoch 21: val_loss improved from 0.00239 to 0.00219, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.8729e-04 - val_loss: 0.0022\n",
      "Epoch 22/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0012\n",
      "Epoch 22: val_loss did not improve from 0.00219\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 23/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.4898e-04\n",
      "Epoch 23: val_loss did not improve from 0.00219\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.5048e-04 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010\n",
      "Epoch 24: val_loss improved from 0.00219 to 0.00212, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 25/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.9274e-04\n",
      "Epoch 25: val_loss did not improve from 0.00212\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.9262e-04 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.7230e-04\n",
      "Epoch 26: val_loss did not improve from 0.00212\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 9.7390e-04 - val_loss: 0.0022\n",
      "Epoch 27/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.5393e-04\n",
      "Epoch 27: val_loss did not improve from 0.00212\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.5514e-04 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.8024e-04\n",
      "Epoch 28: val_loss did not improve from 0.00212\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.8099e-04 - val_loss: 0.0032\n",
      "Epoch 29/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 29: val_loss did not improve from 0.00212\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 30/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.3053e-04\n",
      "Epoch 30: val_loss did not improve from 0.00212\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.2947e-04 - val_loss: 0.0022\n",
      "Epoch 31/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.7827e-04\n",
      "Epoch 31: val_loss improved from 0.00212 to 0.00199, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.7809e-04 - val_loss: 0.0020\n",
      "Epoch 32/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.4319e-04\n",
      "Epoch 32: val_loss improved from 0.00199 to 0.00196, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.4405e-04 - val_loss: 0.0020\n",
      "Epoch 33/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.3567e-04\n",
      "Epoch 33: val_loss did not improve from 0.00196\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.3649e-04 - val_loss: 0.0020\n",
      "Epoch 34/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0865e-04\n",
      "Epoch 34: val_loss did not improve from 0.00196\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.0920e-04 - val_loss: 0.0020\n",
      "Epoch 35/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.9086e-04\n",
      "Epoch 35: val_loss did not improve from 0.00196\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.9170e-04 - val_loss: 0.0021\n",
      "Epoch 36/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2423e-04\n",
      "Epoch 36: val_loss did not improve from 0.00196\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.2392e-04 - val_loss: 0.0020\n",
      "Epoch 37/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.2683e-04\n",
      "Epoch 37: val_loss improved from 0.00196 to 0.00184, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.2696e-04 - val_loss: 0.0018\n",
      "Epoch 38/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0247e-04\n",
      "Epoch 38: val_loss improved from 0.00184 to 0.00179, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.0264e-04 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2021e-04\n",
      "Epoch 39: val_loss did not improve from 0.00179\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.2035e-04 - val_loss: 0.0019\n",
      "Epoch 40/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8502e-04\n",
      "Epoch 40: val_loss improved from 0.00179 to 0.00163, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.8549e-04 - val_loss: 0.0016\n",
      "Epoch 41/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1446e-04\n",
      "Epoch 41: val_loss did not improve from 0.00163\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.1459e-04 - val_loss: 0.0017\n",
      "Epoch 42/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2507e-04\n",
      "Epoch 42: val_loss did not improve from 0.00163\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.2591e-04 - val_loss: 0.0021\n",
      "Epoch 43/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0493e-04\n",
      "Epoch 43: val_loss did not improve from 0.00163\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.0619e-04 - val_loss: 0.0021\n",
      "Epoch 44/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.2355e-04\n",
      "Epoch 44: val_loss did not improve from 0.00163\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.2313e-04 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7692e-04\n",
      "Epoch 45: val_loss improved from 0.00163 to 0.00161, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.7668e-04 - val_loss: 0.0016\n",
      "Epoch 46/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5526e-04\n",
      "Epoch 46: val_loss did not improve from 0.00161\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.5533e-04 - val_loss: 0.0018\n",
      "Epoch 47/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7254e-04\n",
      "Epoch 47: val_loss did not improve from 0.00161\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.7032e-04 - val_loss: 0.0017\n",
      "Epoch 48/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3403e-04\n",
      "Epoch 48: val_loss did not improve from 0.00161\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.3540e-04 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3176e-04\n",
      "Epoch 49: val_loss did not improve from 0.00161\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.3336e-04 - val_loss: 0.0018\n",
      "Epoch 50/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3778e-04\n",
      "Epoch 50: val_loss did not improve from 0.00161\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.3856e-04 - val_loss: 0.0018\n",
      "Epoch 51/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9384e-04\n",
      "Epoch 51: val_loss improved from 0.00161 to 0.00156, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.9767e-04 - val_loss: 0.0016\n",
      "Epoch 52/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2428e-04\n",
      "Epoch 52: val_loss did not improve from 0.00156\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2505e-04 - val_loss: 0.0018\n",
      "Epoch 53/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8591e-04\n",
      "Epoch 53: val_loss did not improve from 0.00156\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.9179e-04 - val_loss: 0.0022\n",
      "Epoch 54/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4022e-04\n",
      "Epoch 54: val_loss did not improve from 0.00156\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4083e-04 - val_loss: 0.0017\n",
      "Epoch 55/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1691e-04\n",
      "Epoch 55: val_loss did not improve from 0.00156\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.1773e-04 - val_loss: 0.0019\n",
      "Epoch 56/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4134e-04\n",
      "Epoch 56: val_loss did not improve from 0.00156\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4082e-04 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8781e-04\n",
      "Epoch 57: val_loss did not improve from 0.00156\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.8859e-04 - val_loss: 0.0019\n",
      "Epoch 58/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0462e-04\n",
      "Epoch 58: val_loss improved from 0.00156 to 0.00155, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.0601e-04 - val_loss: 0.0016\n",
      "Epoch 59/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.9488e-04\n",
      "Epoch 59: val_loss did not improve from 0.00155\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.9091e-04 - val_loss: 0.0016\n",
      "Epoch 60/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.6056e-04\n",
      "Epoch 60: val_loss did not improve from 0.00155\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.6138e-04 - val_loss: 0.0019\n",
      "Epoch 61/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9381e-04\n",
      "Epoch 61: val_loss did not improve from 0.00155\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.9433e-04 - val_loss: 0.0021\n",
      "Epoch 62/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9242e-04\n",
      "Epoch 62: val_loss did not improve from 0.00155\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.9262e-04 - val_loss: 0.0019\n",
      "Epoch 63/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4802e-04\n",
      "Epoch 63: val_loss improved from 0.00155 to 0.00154, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.4887e-04 - val_loss: 0.0015\n",
      "Epoch 64/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.6913e-04\n",
      "Epoch 64: val_loss did not improve from 0.00154\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.6965e-04 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.5810e-04\n",
      "Epoch 65: val_loss did not improve from 0.00154\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.5829e-04 - val_loss: 0.0022\n",
      "Epoch 66/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7744e-04\n",
      "Epoch 66: val_loss did not improve from 0.00154\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.7834e-04 - val_loss: 0.0025\n",
      "Epoch 67/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.3917e-04\n",
      "Epoch 67: val_loss improved from 0.00154 to 0.00154, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.3951e-04 - val_loss: 0.0015\n",
      "Epoch 68/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4105e-04\n",
      "Epoch 68: val_loss did not improve from 0.00154\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4304e-04 - val_loss: 0.0017\n",
      "Epoch 69/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.0367e-04\n",
      "Epoch 69: val_loss did not improve from 0.00154\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.0525e-04 - val_loss: 0.0017\n",
      "Epoch 70/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4173e-04\n",
      "Epoch 70: val_loss improved from 0.00154 to 0.00144, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.4251e-04 - val_loss: 0.0014\n",
      "Epoch 71/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7561e-04\n",
      "Epoch 71: val_loss did not improve from 0.00144\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.7517e-04 - val_loss: 0.0016\n",
      "Epoch 72/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1205e-04\n",
      "Epoch 72: val_loss did not improve from 0.00144\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.1219e-04 - val_loss: 0.0018\n",
      "Epoch 73/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.2679e-04\n",
      "Epoch 73: val_loss improved from 0.00144 to 0.00143, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.2747e-04 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.9312e-04\n",
      "Epoch 74: val_loss did not improve from 0.00143\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.9451e-04 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.0932e-04\n",
      "Epoch 75: val_loss did not improve from 0.00143\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.1152e-04 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2586e-04\n",
      "Epoch 76: val_loss did not improve from 0.00143\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2522e-04 - val_loss: 0.0024\n",
      "Epoch 77/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.8666e-04\n",
      "Epoch 77: val_loss did not improve from 0.00143\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.8782e-04 - val_loss: 0.0015\n",
      "Epoch 78/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.3093e-04\n",
      "Epoch 78: val_loss improved from 0.00143 to 0.00139, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.2984e-04 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8111e-04\n",
      "Epoch 79: val_loss did not improve from 0.00139\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.8128e-04 - val_loss: 0.0020\n",
      "Epoch 80/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.2398e-04\n",
      "Epoch 80: val_loss improved from 0.00139 to 0.00124, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.2417e-04 - val_loss: 0.0012\n",
      "Epoch 81/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5634e-04\n",
      "Epoch 81: val_loss did not improve from 0.00124\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.5522e-04 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.6060e-04\n",
      "Epoch 82: val_loss improved from 0.00124 to 0.00117, saving model to ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.6196e-04 - val_loss: 0.0012\n",
      "Epoch 83/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8916e-04\n",
      "Epoch 83: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.8935e-04 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.6947e-04\n",
      "Epoch 84: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.7098e-04 - val_loss: 0.0015\n",
      "Epoch 85/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4594e-04\n",
      "Epoch 85: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.4666e-04 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.0769e-04\n",
      "Epoch 86: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.0876e-04 - val_loss: 0.0018\n",
      "Epoch 87/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9241e-04\n",
      "Epoch 87: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.9298e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5159e-04\n",
      "Epoch 88: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.5206e-04 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5549e-04\n",
      "Epoch 89: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.5775e-04 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.6641e-04\n",
      "Epoch 90: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.6710e-04 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0788e-04\n",
      "Epoch 91: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0914e-04 - val_loss: 0.0012\n",
      "Epoch 92/100\n",
      "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.1707e-04\n",
      "Epoch 92: val_loss did not improve from 0.00117\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1718e-04 - val_loss: 0.0020\n",
      " - Loaded best model from ../models/lstm_models/lstm_AMZN_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for AMZN: RMSE = 8.4435, MAE = 6.3464, R2 = 0.9282\n",
      "Model training and evaluation completed for AMZN.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Summary of Model Performance\n",
      "==================================================\n",
      "AAPL: RMSE = 11.7514, MAE = 8.4938, R2 = 0.7316\n",
      "MSFT: RMSE = 41.9165, MAE = 35.8593, R2 = 0.4687\n",
      "GOOGL: RMSE = 10.9816, MAE = 9.1367, R2 = 0.8016\n",
      "AMZN: RMSE = 8.4435, MAE = 6.3464, R2 = 0.9282\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training and Evaluating LSTM Models for Daily Data\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Define Parameters\n",
    "TIMESTEPS = 60  # Number of past days to use for prediction\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100  # Increased to allow more training\n",
    "VALIDATION_SPLIT = 0.1  # Fraction of training data to use for validation\n",
    "\n",
    "# Define Evaluation Metrics Function\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Function to Create Sequences\n",
    "def create_sequences(X, y, timesteps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(timesteps, len(X)):\n",
    "        X_seq.append(X[i-timesteps:i].values)\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Function to Build LSTM Model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape)) # Explicit Input Layer\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dense(units=1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Initialize a dictionary to store model performance\n",
    "model_performance = {}\n",
    "\n",
    "# Directories to save models and scalers\n",
    "model_save_dir = '../models/lstm_models'\n",
    "scaler_save_dir = '../models/scalers'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(scaler_save_dir, exist_ok=True)\n",
    "\n",
    "# Iterate Through Each Stock\n",
    "for stock in scaled_daily_data.keys():\n",
    "    print(f\"\\n{'='*50}\\nTraining LSTM Model for {stock}\\n{'='*50}\")\n",
    "    \n",
    "    # Retrieve Scaled Data\n",
    "    data = scaled_daily_data[stock]\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_train_scaled = data['y_train_scaled']\n",
    "    y_test_scaled = data['y_test_scaled']\n",
    "    scaler_X = data['scaler_X']\n",
    "    scaler_y = data['scaler_y']\n",
    "    \n",
    "    # Create Sequences\n",
    "    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, TIMESTEPS)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, TIMESTEPS)\n",
    "    \n",
    "    print(f\" - Training sequences: {X_train_seq.shape}, Training targets: {y_train_seq.shape}\")\n",
    "    print(f\" - Testing sequences: {X_test_seq.shape}, Testing targets: {y_test_seq.shape}\")\n",
    "    \n",
    "    # Build the Model\n",
    "    model = build_lstm_model(input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
    "    model.summary()\n",
    "\n",
    "    # Define Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(model_save_dir, f'lstm_{stock}_best.keras'),  # Changed to .keras\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the Model\n",
    "    history = model.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Load the Best Model\n",
    "    best_model_path = os.path.join(model_save_dir, f'lstm_{stock}_best.keras')\n",
    "    model = load_model(best_model_path)\n",
    "    print(f\" - Loaded best model from {best_model_path}\")\n",
    "    \n",
    "    # Predict on Test Data\n",
    "    predictions_scaled = model.predict(X_test_seq).flatten()\n",
    "    \n",
    "    # Inverse Transform Predictions and Targets\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()\n",
    "    y_test = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Ensure Consistent Lengths\n",
    "    print(f\" - Length of y_test: {len(y_test)}\")\n",
    "    print(f\" - Length of predictions: {len(predictions)}\")\n",
    "    \n",
    "    # Evaluation Metrics\n",
    "    rmse, mae, r2 = evaluate_model(y_test, predictions)\n",
    "    model_performance[stock] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "    \n",
    "    print(f\" - Evaluation Metrics for {stock}: RMSE = {rmse:.4f}, MAE = {mae:.4f}, R2 = {r2:.4f}\")\n",
    "    \n",
    "    print(f\"Model training and evaluation completed for {stock}.\\n\")\n",
    "\n",
    "# Summary of Model Performance\n",
    "print(f\"\\n{'='*50}\\nSummary of Model Performance\\n{'='*50}\")\n",
    "for stock, metrics in model_performance.items():\n",
    "    print(f\"{stock}: RMSE = {metrics['RMSE']:.4f}, MAE = {metrics['MAE']:.4f}, R2 = {metrics['R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0720ab5c-ae48-4e11-842b-2bcf7da5c7f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GRU Model for AAPL\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m13,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m15,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0552\n",
      "Epoch 1: val_loss improved from inf to 0.00408, saving model to ../models/gru_models/gru_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0546 - val_loss: 0.0041\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036\n",
      "Epoch 2: val_loss improved from 0.00408 to 0.00248, saving model to ../models/gru_models/gru_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0030\n",
      "Epoch 3: val_loss did not improve from 0.00248\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026\n",
      "Epoch 4: val_loss did not improve from 0.00248\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020\n",
      "Epoch 5: val_loss improved from 0.00248 to 0.00242, saving model to ../models/gru_models/gru_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0017\n",
      "Epoch 6: val_loss did not improve from 0.00242\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018\n",
      "Epoch 7: val_loss did not improve from 0.00242\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015\n",
      "Epoch 8: val_loss did not improve from 0.00242\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 0.0102\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0012\n",
      "Epoch 9: val_loss did not improve from 0.00242\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0013\n",
      "Epoch 10: val_loss did not improve from 0.00242\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0011\n",
      "Epoch 11: val_loss improved from 0.00242 to 0.00227, saving model to ../models/gru_models/gru_AAPL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 12/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0012\n",
      "Epoch 12: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0010\n",
      "Epoch 13: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0012\n",
      "Epoch 14: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0092\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0011\n",
      "Epoch 15: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 16/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.8789e-04\n",
      "Epoch 16: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.8962e-04 - val_loss: 0.0045\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.9030e-04\n",
      "Epoch 17: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.9143e-04 - val_loss: 0.0027\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7919e-04\n",
      "Epoch 18: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.7865e-04 - val_loss: 0.0037\n",
      "Epoch 19/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.5126e-04\n",
      "Epoch 19: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.5154e-04 - val_loss: 0.0040\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.3067e-04\n",
      "Epoch 20: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.3125e-04 - val_loss: 0.0071\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.5985e-04\n",
      "Epoch 21: val_loss did not improve from 0.00227\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.5979e-04 - val_loss: 0.0029\n",
      " - Loaded best model from ../models/gru_models/gru_AAPL_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for GRU AAPL: RMSE = 19.0600, MAE = 16.2463, R2 = 0.2938\n",
      "GRU model training and evaluation completed for AAPL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training GRU Model for MSFT\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m13,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m15,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0267\n",
      "Epoch 1: val_loss improved from inf to 0.00245, saving model to ../models/gru_models/gru_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0264 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046\n",
      "Epoch 2: val_loss improved from 0.00245 to 0.00229, saving model to ../models/gru_models/gru_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034\n",
      "Epoch 3: val_loss improved from 0.00229 to 0.00094, saving model to ../models/gru_models/gru_MSFT_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 9.4191e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025\n",
      "Epoch 4: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026\n",
      "Epoch 5: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021\n",
      "Epoch 6: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0022\n",
      "Epoch 7: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021\n",
      "Epoch 8: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0013\n",
      "Epoch 9: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0013\n",
      "Epoch 10: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0011\n",
      "Epoch 11: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0011\n",
      "Epoch 12: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013\n",
      "Epoch 13: val_loss did not improve from 0.00094\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      " - Loaded best model from ../models/gru_models/gru_MSFT_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for GRU MSFT: RMSE = 30.0794, MAE = 26.1498, R2 = 0.7264\n",
      "GRU model training and evaluation completed for MSFT.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training GRU Model for GOOGL\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m13,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m15,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0625\n",
      "Epoch 1: val_loss improved from inf to 0.00814, saving model to ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0619 - val_loss: 0.0081\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0059\n",
      "Epoch 2: val_loss improved from 0.00814 to 0.00198, saving model to ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034\n",
      "Epoch 3: val_loss improved from 0.00198 to 0.00152, saving model to ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025\n",
      "Epoch 4: val_loss improved from 0.00152 to 0.00125, saving model to ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023\n",
      "Epoch 5: val_loss did not improve from 0.00125\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018\n",
      "Epoch 6: val_loss did not improve from 0.00125\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0016\n",
      "Epoch 7: val_loss improved from 0.00125 to 0.00111, saving model to ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0015\n",
      "Epoch 8: val_loss improved from 0.00111 to 0.00102, saving model to ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0014\n",
      "Epoch 9: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0015\n",
      "Epoch 10: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0015\n",
      "Epoch 11: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0015\n",
      "Epoch 12: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0013\n",
      "Epoch 13: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0010  \n",
      "Epoch 14: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.3671e-04\n",
      "Epoch 15: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.3737e-04 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.8750e-04\n",
      "Epoch 16: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.8889e-04 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0012\n",
      "Epoch 17: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0013\n",
      "Epoch 18: val_loss did not improve from 0.00102\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      " - Loaded best model from ../models/gru_models/gru_GOOGL_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for GRU GOOGL: RMSE = 9.5126, MAE = 7.9096, R2 = 0.8511\n",
      "GRU model training and evaluation completed for GOOGL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training GRU Model for AMZN\n",
      "==================================================\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m13,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_7 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m15,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,801</span> (116.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,801\u001b[0m (116.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0518\n",
      "Epoch 1: val_loss improved from inf to 0.00528, saving model to ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0513 - val_loss: 0.0053\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0059\n",
      "Epoch 2: val_loss improved from 0.00528 to 0.00383, saving model to ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031\n",
      "Epoch 3: val_loss improved from 0.00383 to 0.00296, saving model to ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0030\n",
      "Epoch 4: val_loss did not improve from 0.00296\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0031\n",
      "Epoch 5: val_loss improved from 0.00296 to 0.00296, saving model to ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 6/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0029\n",
      "Epoch 6: val_loss did not improve from 0.00296\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023\n",
      "Epoch 7: val_loss improved from 0.00296 to 0.00280, saving model to ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0021\n",
      "Epoch 8: val_loss improved from 0.00280 to 0.00255, saving model to ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019\n",
      "Epoch 9: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 10/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018\n",
      "Epoch 10: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016\n",
      "Epoch 11: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0017\n",
      "Epoch 12: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 13/100\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017\n",
      "Epoch 13: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0014\n",
      "Epoch 14: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016\n",
      "Epoch 15: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0014\n",
      "Epoch 16: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0013\n",
      "Epoch 17: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0013\n",
      "Epoch 18: val_loss did not improve from 0.00255\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      " - Loaded best model from ../models/gru_models/gru_AMZN_best.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      " - Length of y_test: 443\n",
      " - Length of predictions: 443\n",
      " - Evaluation Metrics for GRU AMZN: RMSE = 6.9025, MAE = 5.5648, R2 = 0.9520\n",
      "GRU model training and evaluation completed for AMZN.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Summary of GRU Model Performance\n",
      "==================================================\n",
      "AAPL: RMSE = 19.0600, MAE = 16.2463, R2 = 0.2938\n",
      "MSFT: RMSE = 30.0794, MAE = 26.1498, R2 = 0.7264\n",
      "GOOGL: RMSE = 9.5126, MAE = 7.9096, R2 = 0.8511\n",
      "AMZN: RMSE = 6.9025, MAE = 5.5648, R2 = 0.9520\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training and Evaluating GRU Models for Daily Data\n",
    "\n",
    "# Define Parameters\n",
    "TIMESTEPS = 60  # Number of past days to use for prediction\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "SEED = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Function to Create Sequences (Already Defined in Cell 6)\n",
    "def create_sequences(X, y, timesteps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(timesteps, len(X)):\n",
    "        X_seq.append(X[i-timesteps:i].values)\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Function to Build GRU Model\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dense(units=1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Initialize a dictionary to store GRU model performance\n",
    "gru_model_performance = {}\n",
    "\n",
    "# Define Directory to Save GRU Models\n",
    "gru_model_save_dir = '../models/gru_models'\n",
    "os.makedirs(gru_model_save_dir, exist_ok=True)\n",
    "\n",
    "# Iterate Through Each Stock\n",
    "for stock in scaled_daily_data.keys():\n",
    "    print(f\"\\n{'='*50}\\nTraining GRU Model for {stock}\\n{'='*50}\")\n",
    "    \n",
    "    # Retrieve Scaled Data\n",
    "    data = scaled_daily_data[stock]\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_train_scaled = data['y_train_scaled']\n",
    "    y_test_scaled = data['y_test_scaled']\n",
    "    scaler_y = data['scaler_y']\n",
    "    \n",
    "    # Create Sequences\n",
    "    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, TIMESTEPS)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, TIMESTEPS)\n",
    "    \n",
    "    print(f\" - Training sequences: {X_train_seq.shape}, Training targets: {y_train_seq.shape}\")\n",
    "    print(f\" - Testing sequences: {X_test_seq.shape}, Testing targets: {y_test_seq.shape}\")\n",
    "    \n",
    "    # Build the GRU Model\n",
    "    model = build_gru_model(input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
    "    model.summary()\n",
    "    \n",
    "    # Define Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(gru_model_save_dir, f'gru_{stock}_best.keras'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train the GRU Model\n",
    "    history = model.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Load the Best Model\n",
    "    best_model_path = os.path.join(gru_model_save_dir, f'gru_{stock}_best.keras')\n",
    "    if os.path.exists(best_model_path):\n",
    "        model = load_model(best_model_path)\n",
    "        print(f\" - Loaded best model from {best_model_path}\")\n",
    "    else:\n",
    "        print(f\" - Best GRU model for {stock} not found at {best_model_path}.\")\n",
    "        continue  # Skip evaluation if model not saved\n",
    "    \n",
    "    # Predict on Test Data\n",
    "    predictions_scaled = model.predict(X_test_seq).flatten()\n",
    "    \n",
    "    # Inverse Transform Predictions and Targets\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()\n",
    "    y_test = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Ensure Consistent Lengths\n",
    "    print(f\" - Length of y_test: {len(y_test)}\")\n",
    "    print(f\" - Length of predictions: {len(predictions)}\")\n",
    "    \n",
    "    # Evaluation Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    gru_model_performance[stock] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "    \n",
    "    print(f\" - Evaluation Metrics for GRU {stock}: RMSE = {rmse:.4f}, MAE = {mae:.4f}, R2 = {r2:.4f}\")\n",
    "    \n",
    "    print(f\"GRU model training and evaluation completed for {stock}.\\n\")\n",
    "\n",
    "# Summary of GRU Model Performance\n",
    "print(f\"\\n{'='*50}\\nSummary of GRU Model Performance\\n{'='*50}\")\n",
    "for stock, metrics in gru_model_performance.items():\n",
    "    print(f\"{stock}: RMSE = {metrics['RMSE']:.4f}, MAE = {metrics['MAE']:.4f}, R2 = {metrics['R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8bb105-329c-443d-a3a0-bb1bd94f072d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and Evaluating XGBoost Model for AAPL\n",
      "==================================================\n",
      " - XGBoost model trained for AAPL\n",
      " - Feature names saved for AAPL at ../models/xgb_models/feature_names_AAPL.pkl\n",
      " - Overall Evaluation Metrics for AAPL:\n",
      "    RMSE = 21.5184\n",
      "    MAE = 12.9100\n",
      "    R2 = 0.3334\n",
      "    MAPE = 6.13%\n",
      " - XGBoost model saved for AAPL at ../models/xgb_models/xgb_AAPL_model.json\n",
      "Training and evaluation completed for AAPL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating XGBoost Model for MSFT\n",
      "==================================================\n",
      " - XGBoost model trained for MSFT\n",
      " - Feature names saved for MSFT at ../models/xgb_models/feature_names_MSFT.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:126: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:140: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:126: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:140: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Overall Evaluation Metrics for MSFT:\n",
      "    RMSE = 53.0361\n",
      "    MAE = 36.3703\n",
      "    R2 = 0.3896\n",
      "    MAPE = 8.81%\n",
      " - XGBoost model saved for MSFT at ../models/xgb_models/xgb_MSFT_model.json\n",
      "Training and evaluation completed for MSFT.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating XGBoost Model for GOOGL\n",
      "==================================================\n",
      " - XGBoost model trained for GOOGL\n",
      " - Feature names saved for GOOGL at ../models/xgb_models/feature_names_GOOGL.pkl\n",
      " - Overall Evaluation Metrics for GOOGL:\n",
      "    RMSE = 12.2651\n",
      "    MAE = 6.6552\n",
      "    R2 = 0.8036\n",
      "    MAPE = 4.05%\n",
      " - XGBoost model saved for GOOGL at ../models/xgb_models/xgb_GOOGL_model.json\n",
      "Training and evaluation completed for GOOGL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating XGBoost Model for AMZN\n",
      "==================================================\n",
      " - XGBoost model trained for AMZN\n",
      " - Feature names saved for AMZN at ../models/xgb_models/feature_names_AMZN.pkl\n",
      " - Overall Evaluation Metrics for AMZN:\n",
      "    RMSE = 3.0123\n",
      "    MAE = 1.7337\n",
      "    R2 = 0.9926\n",
      "    MAPE = 1.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:126: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:140: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:126: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:133: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/256936105.py:140: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - XGBoost model saved for AMZN at ../models/xgb_models/xgb_AMZN_model.json\n",
      "Training and evaluation completed for AMZN.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Overall Evaluation Metrics for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>21.518377</td>\n",
       "      <td>12.909998</td>\n",
       "      <td>0.333433</td>\n",
       "      <td>6.129564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>53.036127</td>\n",
       "      <td>36.370332</td>\n",
       "      <td>0.389636</td>\n",
       "      <td>8.805656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>12.265134</td>\n",
       "      <td>6.655197</td>\n",
       "      <td>0.803620</td>\n",
       "      <td>4.047240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>3.012312</td>\n",
       "      <td>1.733682</td>\n",
       "      <td>0.992608</td>\n",
       "      <td>1.115294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RMSE        MAE        R2      MAPE\n",
       "AAPL   21.518377  12.909998  0.333433  6.129564\n",
       "MSFT   53.036127  36.370332  0.389636  8.805656\n",
       "GOOGL  12.265134   6.655197  0.803620  4.047240\n",
       "AMZN    3.012312   1.733682  0.992608  1.115294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Overall Evaluation Metrics table for XGBoost saved as 'overall_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for AAPL - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.523657</td>\n",
       "      <td>6.369372</td>\n",
       "      <td>0.896859</td>\n",
       "      <td>3.478552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.804222</td>\n",
       "      <td>5.086796</td>\n",
       "      <td>0.842367</td>\n",
       "      <td>2.791202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.442090</td>\n",
       "      <td>1.087113</td>\n",
       "      <td>0.978204</td>\n",
       "      <td>0.658404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.118708</td>\n",
       "      <td>0.900531</td>\n",
       "      <td>0.892222</td>\n",
       "      <td>0.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.670529</td>\n",
       "      <td>4.572242</td>\n",
       "      <td>0.343929</td>\n",
       "      <td>2.440303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20.647992</td>\n",
       "      <td>16.177428</td>\n",
       "      <td>-1.657299</td>\n",
       "      <td>7.924047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>35.747513</td>\n",
       "      <td>31.628786</td>\n",
       "      <td>-3.620084</td>\n",
       "      <td>14.577750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>31.392237</td>\n",
       "      <td>24.412861</td>\n",
       "      <td>-1.190113</td>\n",
       "      <td>11.248215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>33.645263</td>\n",
       "      <td>25.136786</td>\n",
       "      <td>-0.990752</td>\n",
       "      <td>11.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>36.003623</td>\n",
       "      <td>25.089042</td>\n",
       "      <td>-0.531958</td>\n",
       "      <td>10.970298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>6.364981</td>\n",
       "      <td>4.409575</td>\n",
       "      <td>0.905119</td>\n",
       "      <td>2.430350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>11.730759</td>\n",
       "      <td>8.672877</td>\n",
       "      <td>0.832534</td>\n",
       "      <td>4.574893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month       RMSE        MAE        R2       MAPE\n",
       "0       1   8.523657   6.369372  0.896859   3.478552\n",
       "1       2   6.804222   5.086796  0.842367   2.791202\n",
       "2       3   1.442090   1.087113  0.978204   0.658404\n",
       "3       4   1.118708   0.900531  0.892222   0.538700\n",
       "4       5   6.670529   4.572242  0.343929   2.440303\n",
       "5       6  20.647992  16.177428 -1.657299   7.924047\n",
       "6       7  35.747513  31.628786 -3.620084  14.577750\n",
       "7       8  31.392237  24.412861 -1.190113  11.248215\n",
       "8       9  33.645263  25.136786 -0.990752  11.380400\n",
       "9      10  36.003623  25.089042 -0.531958  10.970298\n",
       "10     11   6.364981   4.409575  0.905119   2.430350\n",
       "11     12  11.730759   8.672877  0.832534   4.574893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for AAPL saved as 'AAPL_Month_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for MSFT - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36.305385</td>\n",
       "      <td>25.919526</td>\n",
       "      <td>0.776810</td>\n",
       "      <td>6.732587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49.648069</td>\n",
       "      <td>36.173885</td>\n",
       "      <td>0.560395</td>\n",
       "      <td>8.936369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>52.757535</td>\n",
       "      <td>36.996665</td>\n",
       "      <td>0.513296</td>\n",
       "      <td>9.024713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>55.333173</td>\n",
       "      <td>41.041689</td>\n",
       "      <td>0.224465</td>\n",
       "      <td>9.992887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55.227619</td>\n",
       "      <td>39.414850</td>\n",
       "      <td>-0.113806</td>\n",
       "      <td>9.469837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>68.167317</td>\n",
       "      <td>47.658436</td>\n",
       "      <td>-0.676842</td>\n",
       "      <td>10.916555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>77.853655</td>\n",
       "      <td>57.961684</td>\n",
       "      <td>-1.137751</td>\n",
       "      <td>13.109001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>51.615486</td>\n",
       "      <td>36.976830</td>\n",
       "      <td>-0.346456</td>\n",
       "      <td>9.021289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>60.327816</td>\n",
       "      <td>43.222759</td>\n",
       "      <td>-0.449236</td>\n",
       "      <td>10.230167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>55.482820</td>\n",
       "      <td>39.271974</td>\n",
       "      <td>-0.089090</td>\n",
       "      <td>9.464120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>21.060545</td>\n",
       "      <td>14.782812</td>\n",
       "      <td>0.899330</td>\n",
       "      <td>4.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>23.268873</td>\n",
       "      <td>16.860064</td>\n",
       "      <td>0.866351</td>\n",
       "      <td>4.613035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month       RMSE        MAE        R2       MAPE\n",
       "0       1  36.305385  25.919526  0.776810   6.732587\n",
       "1       2  49.648069  36.173885  0.560395   8.936369\n",
       "2       3  52.757535  36.996665  0.513296   9.024713\n",
       "3       4  55.333173  41.041689  0.224465   9.992887\n",
       "4       5  55.227619  39.414850 -0.113806   9.469837\n",
       "5       6  68.167317  47.658436 -0.676842  10.916555\n",
       "6       7  77.853655  57.961684 -1.137751  13.109001\n",
       "7       8  51.615486  36.976830 -0.346456   9.021289\n",
       "8       9  60.327816  43.222759 -0.449236  10.230167\n",
       "9      10  55.482820  39.271974 -0.089090   9.464120\n",
       "10     11  21.060545  14.782812  0.899330   4.114800\n",
       "11     12  23.268873  16.860064  0.866351   4.613035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for MSFT saved as 'MSFT_Month_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for GOOGL - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.543017</td>\n",
       "      <td>1.047128</td>\n",
       "      <td>0.996436</td>\n",
       "      <td>0.875734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.927376</td>\n",
       "      <td>0.721307</td>\n",
       "      <td>0.998463</td>\n",
       "      <td>0.635649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.270706</td>\n",
       "      <td>1.000780</td>\n",
       "      <td>0.996931</td>\n",
       "      <td>0.827740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.760894</td>\n",
       "      <td>5.526607</td>\n",
       "      <td>0.910253</td>\n",
       "      <td>3.588421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.393014</td>\n",
       "      <td>12.480026</td>\n",
       "      <td>0.628874</td>\n",
       "      <td>7.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20.834226</td>\n",
       "      <td>14.850243</td>\n",
       "      <td>0.436490</td>\n",
       "      <td>8.489723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>24.999600</td>\n",
       "      <td>18.166975</td>\n",
       "      <td>0.278244</td>\n",
       "      <td>10.098494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>12.109877</td>\n",
       "      <td>8.993366</td>\n",
       "      <td>0.475421</td>\n",
       "      <td>5.588208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8.551095</td>\n",
       "      <td>6.071232</td>\n",
       "      <td>0.542098</td>\n",
       "      <td>3.847165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>11.981554</td>\n",
       "      <td>8.619460</td>\n",
       "      <td>0.605677</td>\n",
       "      <td>5.322074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.195212</td>\n",
       "      <td>0.896434</td>\n",
       "      <td>0.996492</td>\n",
       "      <td>0.864442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.874064</td>\n",
       "      <td>0.674530</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.614790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month       RMSE        MAE        R2       MAPE\n",
       "0       1   1.543017   1.047128  0.996436   0.875734\n",
       "1       2   0.927376   0.721307  0.998463   0.635649\n",
       "2       3   1.270706   1.000780  0.996931   0.827740\n",
       "3       4   7.760894   5.526607  0.910253   3.588421\n",
       "4       5  17.393014  12.480026  0.628874   7.324100\n",
       "5       6  20.834226  14.850243  0.436490   8.489723\n",
       "6       7  24.999600  18.166975  0.278244  10.098494\n",
       "7       8  12.109877   8.993366  0.475421   5.588208\n",
       "8       9   8.551095   6.071232  0.542098   3.847165\n",
       "9      10  11.981554   8.619460  0.605677   5.322074\n",
       "10     11   1.195212   0.896434  0.996492   0.864442\n",
       "11     12   0.874064   0.674530  0.998426   0.614790"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for GOOGL saved as 'GOOGL_Month_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for AMZN - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.058915</td>\n",
       "      <td>0.844711</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.747608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.900813</td>\n",
       "      <td>0.672055</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.553332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.953712</td>\n",
       "      <td>0.793332</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.645173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.782520</td>\n",
       "      <td>1.433868</td>\n",
       "      <td>0.997907</td>\n",
       "      <td>0.988127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.219901</td>\n",
       "      <td>1.676648</td>\n",
       "      <td>0.996289</td>\n",
       "      <td>1.056928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3.572012</td>\n",
       "      <td>2.401610</td>\n",
       "      <td>0.985860</td>\n",
       "      <td>1.440424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7.408559</td>\n",
       "      <td>4.827604</td>\n",
       "      <td>0.939950</td>\n",
       "      <td>2.580227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.410268</td>\n",
       "      <td>1.065073</td>\n",
       "      <td>0.994563</td>\n",
       "      <td>0.678367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3.645815</td>\n",
       "      <td>2.458877</td>\n",
       "      <td>0.979642</td>\n",
       "      <td>1.403266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.515444</td>\n",
       "      <td>2.814587</td>\n",
       "      <td>0.986898</td>\n",
       "      <td>1.694704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.249471</td>\n",
       "      <td>0.969070</td>\n",
       "      <td>0.997497</td>\n",
       "      <td>0.871110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.011071</td>\n",
       "      <td>0.781944</td>\n",
       "      <td>0.998945</td>\n",
       "      <td>0.695328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month      RMSE       MAE        R2      MAPE\n",
       "0       1  1.058915  0.844711  0.998764  0.747608\n",
       "1       2  0.900813  0.672055  0.999378  0.553332\n",
       "2       3  0.953712  0.793332  0.999436  0.645173\n",
       "3       4  1.782520  1.433868  0.997907  0.988127\n",
       "4       5  2.219901  1.676648  0.996289  1.056928\n",
       "5       6  3.572012  2.401610  0.985860  1.440424\n",
       "6       7  7.408559  4.827604  0.939950  2.580227\n",
       "7       8  1.410268  1.065073  0.994563  0.678367\n",
       "8       9  3.645815  2.458877  0.979642  1.403266\n",
       "9      10  3.515444  2.814587  0.986898  1.694704\n",
       "10     11  1.249471  0.969070  0.997497  0.871110\n",
       "11     12  1.011071  0.781944  0.998945  0.695328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for AMZN saved as 'AMZN_Month_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative RMSE Across Month for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.523657</td>\n",
       "      <td>36.305385</td>\n",
       "      <td>1.543017</td>\n",
       "      <td>1.058915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.804222</td>\n",
       "      <td>49.648069</td>\n",
       "      <td>0.927376</td>\n",
       "      <td>0.900813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.442090</td>\n",
       "      <td>52.757535</td>\n",
       "      <td>1.270706</td>\n",
       "      <td>0.953712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.118708</td>\n",
       "      <td>55.333173</td>\n",
       "      <td>7.760894</td>\n",
       "      <td>1.782520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.670529</td>\n",
       "      <td>55.227619</td>\n",
       "      <td>17.393014</td>\n",
       "      <td>2.219901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.647992</td>\n",
       "      <td>68.167317</td>\n",
       "      <td>20.834226</td>\n",
       "      <td>3.572012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.747513</td>\n",
       "      <td>77.853655</td>\n",
       "      <td>24.999600</td>\n",
       "      <td>7.408559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.392237</td>\n",
       "      <td>51.615486</td>\n",
       "      <td>12.109877</td>\n",
       "      <td>1.410268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33.645263</td>\n",
       "      <td>60.327816</td>\n",
       "      <td>8.551095</td>\n",
       "      <td>3.645815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.003623</td>\n",
       "      <td>55.482820</td>\n",
       "      <td>11.981554</td>\n",
       "      <td>3.515444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.364981</td>\n",
       "      <td>21.060545</td>\n",
       "      <td>1.195212</td>\n",
       "      <td>1.249471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.730759</td>\n",
       "      <td>23.268873</td>\n",
       "      <td>0.874064</td>\n",
       "      <td>1.011071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL       MSFT      GOOGL      AMZN\n",
       "Month                                           \n",
       "1       8.523657  36.305385   1.543017  1.058915\n",
       "2       6.804222  49.648069   0.927376  0.900813\n",
       "3       1.442090  52.757535   1.270706  0.953712\n",
       "4       1.118708  55.333173   7.760894  1.782520\n",
       "5       6.670529  55.227619  17.393014  2.219901\n",
       "6      20.647992  68.167317  20.834226  3.572012\n",
       "7      35.747513  77.853655  24.999600  7.408559\n",
       "8      31.392237  51.615486  12.109877  1.410268\n",
       "9      33.645263  60.327816   8.551095  3.645815\n",
       "10     36.003623  55.482820  11.981554  3.515444\n",
       "11      6.364981  21.060545   1.195212  1.249471\n",
       "12     11.730759  23.268873   0.874064  1.011071"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative RMSE Across Month table for XGBoost saved as 'comparative_RMSE_across_Month_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAE Across Month for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.369372</td>\n",
       "      <td>25.919526</td>\n",
       "      <td>1.047128</td>\n",
       "      <td>0.844711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.086796</td>\n",
       "      <td>36.173885</td>\n",
       "      <td>0.721307</td>\n",
       "      <td>0.672055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.087113</td>\n",
       "      <td>36.996665</td>\n",
       "      <td>1.000780</td>\n",
       "      <td>0.793332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900531</td>\n",
       "      <td>41.041689</td>\n",
       "      <td>5.526607</td>\n",
       "      <td>1.433868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.572242</td>\n",
       "      <td>39.414850</td>\n",
       "      <td>12.480026</td>\n",
       "      <td>1.676648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.177428</td>\n",
       "      <td>47.658436</td>\n",
       "      <td>14.850243</td>\n",
       "      <td>2.401610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.628786</td>\n",
       "      <td>57.961684</td>\n",
       "      <td>18.166975</td>\n",
       "      <td>4.827604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.412861</td>\n",
       "      <td>36.976830</td>\n",
       "      <td>8.993366</td>\n",
       "      <td>1.065073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.136786</td>\n",
       "      <td>43.222759</td>\n",
       "      <td>6.071232</td>\n",
       "      <td>2.458877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.089042</td>\n",
       "      <td>39.271974</td>\n",
       "      <td>8.619460</td>\n",
       "      <td>2.814587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.409575</td>\n",
       "      <td>14.782812</td>\n",
       "      <td>0.896434</td>\n",
       "      <td>0.969070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.672877</td>\n",
       "      <td>16.860064</td>\n",
       "      <td>0.674530</td>\n",
       "      <td>0.781944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL       MSFT      GOOGL      AMZN\n",
       "Month                                           \n",
       "1       6.369372  25.919526   1.047128  0.844711\n",
       "2       5.086796  36.173885   0.721307  0.672055\n",
       "3       1.087113  36.996665   1.000780  0.793332\n",
       "4       0.900531  41.041689   5.526607  1.433868\n",
       "5       4.572242  39.414850  12.480026  1.676648\n",
       "6      16.177428  47.658436  14.850243  2.401610\n",
       "7      31.628786  57.961684  18.166975  4.827604\n",
       "8      24.412861  36.976830   8.993366  1.065073\n",
       "9      25.136786  43.222759   6.071232  2.458877\n",
       "10     25.089042  39.271974   8.619460  2.814587\n",
       "11      4.409575  14.782812   0.896434  0.969070\n",
       "12      8.672877  16.860064   0.674530  0.781944"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAE Across Month table for XGBoost saved as 'comparative_MAE_across_Month_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative R2 Across Month for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.896859</td>\n",
       "      <td>0.776810</td>\n",
       "      <td>0.996436</td>\n",
       "      <td>0.998764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842367</td>\n",
       "      <td>0.560395</td>\n",
       "      <td>0.998463</td>\n",
       "      <td>0.999378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978204</td>\n",
       "      <td>0.513296</td>\n",
       "      <td>0.996931</td>\n",
       "      <td>0.999436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.892222</td>\n",
       "      <td>0.224465</td>\n",
       "      <td>0.910253</td>\n",
       "      <td>0.997907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.343929</td>\n",
       "      <td>-0.113806</td>\n",
       "      <td>0.628874</td>\n",
       "      <td>0.996289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.657299</td>\n",
       "      <td>-0.676842</td>\n",
       "      <td>0.436490</td>\n",
       "      <td>0.985860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.620084</td>\n",
       "      <td>-1.137751</td>\n",
       "      <td>0.278244</td>\n",
       "      <td>0.939950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.190113</td>\n",
       "      <td>-0.346456</td>\n",
       "      <td>0.475421</td>\n",
       "      <td>0.994563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.990752</td>\n",
       "      <td>-0.449236</td>\n",
       "      <td>0.542098</td>\n",
       "      <td>0.979642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.531958</td>\n",
       "      <td>-0.089090</td>\n",
       "      <td>0.605677</td>\n",
       "      <td>0.986898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.905119</td>\n",
       "      <td>0.899330</td>\n",
       "      <td>0.996492</td>\n",
       "      <td>0.997497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.832534</td>\n",
       "      <td>0.866351</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.998945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AAPL      MSFT     GOOGL      AMZN\n",
       "Month                                        \n",
       "1      0.896859  0.776810  0.996436  0.998764\n",
       "2      0.842367  0.560395  0.998463  0.999378\n",
       "3      0.978204  0.513296  0.996931  0.999436\n",
       "4      0.892222  0.224465  0.910253  0.997907\n",
       "5      0.343929 -0.113806  0.628874  0.996289\n",
       "6     -1.657299 -0.676842  0.436490  0.985860\n",
       "7     -3.620084 -1.137751  0.278244  0.939950\n",
       "8     -1.190113 -0.346456  0.475421  0.994563\n",
       "9     -0.990752 -0.449236  0.542098  0.979642\n",
       "10    -0.531958 -0.089090  0.605677  0.986898\n",
       "11     0.905119  0.899330  0.996492  0.997497\n",
       "12     0.832534  0.866351  0.998426  0.998945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative R2 Across Month table for XGBoost saved as 'comparative_R2_across_Month_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAPE Across Month for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.478552</td>\n",
       "      <td>6.732587</td>\n",
       "      <td>0.875734</td>\n",
       "      <td>0.747608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.791202</td>\n",
       "      <td>8.936369</td>\n",
       "      <td>0.635649</td>\n",
       "      <td>0.553332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658404</td>\n",
       "      <td>9.024713</td>\n",
       "      <td>0.827740</td>\n",
       "      <td>0.645173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.538700</td>\n",
       "      <td>9.992887</td>\n",
       "      <td>3.588421</td>\n",
       "      <td>0.988127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.440303</td>\n",
       "      <td>9.469837</td>\n",
       "      <td>7.324100</td>\n",
       "      <td>1.056928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.924047</td>\n",
       "      <td>10.916555</td>\n",
       "      <td>8.489723</td>\n",
       "      <td>1.440424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.577750</td>\n",
       "      <td>13.109001</td>\n",
       "      <td>10.098494</td>\n",
       "      <td>2.580227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.248215</td>\n",
       "      <td>9.021289</td>\n",
       "      <td>5.588208</td>\n",
       "      <td>0.678367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.380400</td>\n",
       "      <td>10.230167</td>\n",
       "      <td>3.847165</td>\n",
       "      <td>1.403266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.970298</td>\n",
       "      <td>9.464120</td>\n",
       "      <td>5.322074</td>\n",
       "      <td>1.694704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.430350</td>\n",
       "      <td>4.114800</td>\n",
       "      <td>0.864442</td>\n",
       "      <td>0.871110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.574893</td>\n",
       "      <td>4.613035</td>\n",
       "      <td>0.614790</td>\n",
       "      <td>0.695328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL       MSFT      GOOGL      AMZN\n",
       "Month                                           \n",
       "1       3.478552   6.732587   0.875734  0.747608\n",
       "2       2.791202   8.936369   0.635649  0.553332\n",
       "3       0.658404   9.024713   0.827740  0.645173\n",
       "4       0.538700   9.992887   3.588421  0.988127\n",
       "5       2.440303   9.469837   7.324100  1.056928\n",
       "6       7.924047  10.916555   8.489723  1.440424\n",
       "7      14.577750  13.109001  10.098494  2.580227\n",
       "8      11.248215   9.021289   5.588208  0.678367\n",
       "9      11.380400  10.230167   3.847165  1.403266\n",
       "10     10.970298   9.464120   5.322074  1.694704\n",
       "11      2.430350   4.114800   0.864442  0.871110\n",
       "12      4.574893   4.613035   0.614790  0.695328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAPE Across Month table for XGBoost saved as 'comparative_MAPE_across_Month_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for AAPL - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.294782</td>\n",
       "      <td>4.116058</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>2.274706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.349159</td>\n",
       "      <td>7.081580</td>\n",
       "      <td>0.236126</td>\n",
       "      <td>3.571376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33.590584</td>\n",
       "      <td>27.027238</td>\n",
       "      <td>-1.527266</td>\n",
       "      <td>12.390954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22.651456</td>\n",
       "      <td>13.045289</td>\n",
       "      <td>0.468602</td>\n",
       "      <td>6.119599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter       RMSE        MAE        R2       MAPE\n",
       "0        1   6.294782   4.116058  0.892308   2.274706\n",
       "1        2  12.349159   7.081580  0.236126   3.571376\n",
       "2        3  33.590584  27.027238 -1.527266  12.390954\n",
       "3        4  22.651456  13.045289  0.468602   6.119599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for AAPL saved as 'AAPL_Quarter_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for MSFT - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>46.839806</td>\n",
       "      <td>33.043404</td>\n",
       "      <td>0.624667</td>\n",
       "      <td>8.232660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>59.706445</td>\n",
       "      <td>42.586401</td>\n",
       "      <td>-0.087160</td>\n",
       "      <td>10.104347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63.990341</td>\n",
       "      <td>45.883925</td>\n",
       "      <td>-0.589401</td>\n",
       "      <td>10.753880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37.432592</td>\n",
       "      <td>24.057653</td>\n",
       "      <td>0.696435</td>\n",
       "      <td>6.155011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter       RMSE        MAE        R2       MAPE\n",
       "0        1  46.839806  33.043404  0.624667   8.232660\n",
       "1        2  59.706445  42.586401 -0.087160  10.104347\n",
       "2        3  63.990341  45.883925 -0.589401  10.753880\n",
       "3        4  37.432592  24.057653  0.696435   6.155011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for MSFT saved as 'MSFT_Quarter_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for GOOGL - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.277032</td>\n",
       "      <td>0.927616</td>\n",
       "      <td>0.997210</td>\n",
       "      <td>0.782831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16.283202</td>\n",
       "      <td>10.957774</td>\n",
       "      <td>0.666223</td>\n",
       "      <td>6.471797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16.783292</td>\n",
       "      <td>11.106801</td>\n",
       "      <td>0.368030</td>\n",
       "      <td>6.531439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.154225</td>\n",
       "      <td>3.540482</td>\n",
       "      <td>0.923354</td>\n",
       "      <td>2.351612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter       RMSE        MAE        R2      MAPE\n",
       "0        1   1.277032   0.927616  0.997210  0.782831\n",
       "1        2  16.283202  10.957774  0.666223  6.471797\n",
       "2        3  16.783292  11.106801  0.368030  6.531439\n",
       "3        4   7.154225   3.540482  0.923354  2.351612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for GOOGL saved as 'GOOGL_Quarter_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for AMZN - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.974186</td>\n",
       "      <td>0.772005</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.650198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.619120</td>\n",
       "      <td>1.829004</td>\n",
       "      <td>0.994598</td>\n",
       "      <td>1.157080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.800279</td>\n",
       "      <td>2.748368</td>\n",
       "      <td>0.964612</td>\n",
       "      <td>1.535643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.276936</td>\n",
       "      <td>1.557946</td>\n",
       "      <td>0.995457</td>\n",
       "      <td>1.104349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter      RMSE       MAE        R2      MAPE\n",
       "0        1  0.974186  0.772005  0.999272  0.650198\n",
       "1        2  2.619120  1.829004  0.994598  1.157080\n",
       "2        3  4.800279  2.748368  0.964612  1.535643\n",
       "3        4  2.276936  1.557946  0.995457  1.104349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for AMZN saved as 'AMZN_Quarter_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative RMSE Across Quarter for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.294782</td>\n",
       "      <td>46.839806</td>\n",
       "      <td>1.277032</td>\n",
       "      <td>0.974186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.349159</td>\n",
       "      <td>59.706445</td>\n",
       "      <td>16.283202</td>\n",
       "      <td>2.619120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.590584</td>\n",
       "      <td>63.990341</td>\n",
       "      <td>16.783292</td>\n",
       "      <td>4.800279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.651456</td>\n",
       "      <td>37.432592</td>\n",
       "      <td>7.154225</td>\n",
       "      <td>2.276936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL       MSFT      GOOGL      AMZN\n",
       "Quarter                                           \n",
       "1         6.294782  46.839806   1.277032  0.974186\n",
       "2        12.349159  59.706445  16.283202  2.619120\n",
       "3        33.590584  63.990341  16.783292  4.800279\n",
       "4        22.651456  37.432592   7.154225  2.276936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative RMSE Across Quarter table for XGBoost saved as 'comparative_RMSE_across_Quarter_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAE Across Quarter for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.116058</td>\n",
       "      <td>33.043404</td>\n",
       "      <td>0.927616</td>\n",
       "      <td>0.772005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.081580</td>\n",
       "      <td>42.586401</td>\n",
       "      <td>10.957774</td>\n",
       "      <td>1.829004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.027238</td>\n",
       "      <td>45.883925</td>\n",
       "      <td>11.106801</td>\n",
       "      <td>2.748368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.045289</td>\n",
       "      <td>24.057653</td>\n",
       "      <td>3.540482</td>\n",
       "      <td>1.557946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL       MSFT      GOOGL      AMZN\n",
       "Quarter                                           \n",
       "1         4.116058  33.043404   0.927616  0.772005\n",
       "2         7.081580  42.586401  10.957774  1.829004\n",
       "3        27.027238  45.883925  11.106801  2.748368\n",
       "4        13.045289  24.057653   3.540482  1.557946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAE Across Quarter table for XGBoost saved as 'comparative_MAE_across_Quarter_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative R2 Across Quarter for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.624667</td>\n",
       "      <td>0.997210</td>\n",
       "      <td>0.999272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236126</td>\n",
       "      <td>-0.087160</td>\n",
       "      <td>0.666223</td>\n",
       "      <td>0.994598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.527266</td>\n",
       "      <td>-0.589401</td>\n",
       "      <td>0.368030</td>\n",
       "      <td>0.964612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.468602</td>\n",
       "      <td>0.696435</td>\n",
       "      <td>0.923354</td>\n",
       "      <td>0.995457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL      MSFT     GOOGL      AMZN\n",
       "Quarter                                        \n",
       "1        0.892308  0.624667  0.997210  0.999272\n",
       "2        0.236126 -0.087160  0.666223  0.994598\n",
       "3       -1.527266 -0.589401  0.368030  0.964612\n",
       "4        0.468602  0.696435  0.923354  0.995457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative R2 Across Quarter table for XGBoost saved as 'comparative_R2_across_Quarter_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAPE Across Quarter for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.274706</td>\n",
       "      <td>8.232660</td>\n",
       "      <td>0.782831</td>\n",
       "      <td>0.650198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.571376</td>\n",
       "      <td>10.104347</td>\n",
       "      <td>6.471797</td>\n",
       "      <td>1.157080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.390954</td>\n",
       "      <td>10.753880</td>\n",
       "      <td>6.531439</td>\n",
       "      <td>1.535643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.119599</td>\n",
       "      <td>6.155011</td>\n",
       "      <td>2.351612</td>\n",
       "      <td>1.104349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL       MSFT     GOOGL      AMZN\n",
       "Quarter                                          \n",
       "1         2.274706   8.232660  0.782831  0.650198\n",
       "2         3.571376  10.104347  6.471797  1.157080\n",
       "3        12.390954  10.753880  6.531439  1.535643\n",
       "4         6.119599   6.155011  2.351612  1.104349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAPE Across Quarter table for XGBoost saved as 'comparative_MAPE_across_Quarter_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for AAPL - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>28.796521</td>\n",
       "      <td>18.265201</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>8.275229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>4.049072</td>\n",
       "      <td>2.225362</td>\n",
       "      <td>0.847172</td>\n",
       "      <td>1.232589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>30.101011</td>\n",
       "      <td>24.205393</td>\n",
       "      <td>-1.697060</td>\n",
       "      <td>11.302339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>9.282704</td>\n",
       "      <td>6.736506</td>\n",
       "      <td>0.860473</td>\n",
       "      <td>3.628497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       RMSE        MAE        R2       MAPE\n",
       "0  Autumn  28.796521  18.265201  0.056138   8.275229\n",
       "1  Spring   4.049072   2.225362  0.847172   1.232589\n",
       "2  Summer  30.101011  24.205393 -1.697060  11.302339\n",
       "3  Winter   9.282704   6.736506  0.860473   3.628497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for AAPL saved as 'AAPL_Season_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for MSFT - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>48.823337</td>\n",
       "      <td>32.417538</td>\n",
       "      <td>0.443856</td>\n",
       "      <td>7.936328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>54.444675</td>\n",
       "      <td>39.123588</td>\n",
       "      <td>0.307172</td>\n",
       "      <td>9.487843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>66.423154</td>\n",
       "      <td>47.280988</td>\n",
       "      <td>-0.663950</td>\n",
       "      <td>10.970065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>37.743444</td>\n",
       "      <td>26.154915</td>\n",
       "      <td>0.732530</td>\n",
       "      <td>6.724702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       RMSE        MAE        R2       MAPE\n",
       "0  Autumn  48.823337  32.417538  0.443856   7.936328\n",
       "1  Spring  54.444675  39.123588  0.307172   9.487843\n",
       "2  Summer  66.423154  47.280988 -0.663950  10.970065\n",
       "3  Winter  37.743444  26.154915  0.732530   6.724702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for MSFT saved as 'MSFT_Season_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for GOOGL - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>8.623782</td>\n",
       "      <td>5.262797</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>3.383358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>11.127692</td>\n",
       "      <td>6.396450</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>3.945145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>19.883711</td>\n",
       "      <td>13.871844</td>\n",
       "      <td>0.377868</td>\n",
       "      <td>7.993662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1.158802</td>\n",
       "      <td>0.815859</td>\n",
       "      <td>0.997685</td>\n",
       "      <td>0.709932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       RMSE        MAE        R2      MAPE\n",
       "0  Autumn   8.623782   5.262797  0.865441  3.383358\n",
       "1  Spring  11.127692   6.396450  0.841629  3.945145\n",
       "2  Summer  19.883711  13.871844  0.377868  7.993662\n",
       "3  Winter   1.158802   0.815859  0.997685  0.709932"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for GOOGL saved as 'GOOGL_Season_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for AMZN - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>3.013583</td>\n",
       "      <td>2.092224</td>\n",
       "      <td>0.991574</td>\n",
       "      <td>1.330543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>1.737037</td>\n",
       "      <td>1.302144</td>\n",
       "      <td>0.998018</td>\n",
       "      <td>0.896566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>4.782771</td>\n",
       "      <td>2.730331</td>\n",
       "      <td>0.968669</td>\n",
       "      <td>1.547347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.767793</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.667275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season      RMSE       MAE        R2      MAPE\n",
       "0  Autumn  3.013583  2.092224  0.991574  1.330543\n",
       "1  Spring  1.737037  1.302144  0.998018  0.896566\n",
       "2  Summer  4.782771  2.730331  0.968669  1.547347\n",
       "3  Winter  0.993921  0.767793  0.999110  0.667275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for AMZN saved as 'AMZN_Season_evaluation_metrics_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative RMSE Across Season for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>28.796521</td>\n",
       "      <td>48.823337</td>\n",
       "      <td>8.623782</td>\n",
       "      <td>3.013583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>4.049072</td>\n",
       "      <td>54.444675</td>\n",
       "      <td>11.127692</td>\n",
       "      <td>1.737037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>30.101011</td>\n",
       "      <td>66.423154</td>\n",
       "      <td>19.883711</td>\n",
       "      <td>4.782771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>9.282704</td>\n",
       "      <td>37.743444</td>\n",
       "      <td>1.158802</td>\n",
       "      <td>0.993921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL       MSFT      GOOGL      AMZN\n",
       "Season                                           \n",
       "Autumn  28.796521  48.823337   8.623782  3.013583\n",
       "Spring   4.049072  54.444675  11.127692  1.737037\n",
       "Summer  30.101011  66.423154  19.883711  4.782771\n",
       "Winter   9.282704  37.743444   1.158802  0.993921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative RMSE Across Season table for XGBoost saved as 'comparative_RMSE_across_Season_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAE Across Season for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>18.265201</td>\n",
       "      <td>32.417538</td>\n",
       "      <td>5.262797</td>\n",
       "      <td>2.092224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>2.225362</td>\n",
       "      <td>39.123588</td>\n",
       "      <td>6.396450</td>\n",
       "      <td>1.302144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>24.205393</td>\n",
       "      <td>47.280988</td>\n",
       "      <td>13.871844</td>\n",
       "      <td>2.730331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>6.736506</td>\n",
       "      <td>26.154915</td>\n",
       "      <td>0.815859</td>\n",
       "      <td>0.767793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL       MSFT      GOOGL      AMZN\n",
       "Season                                           \n",
       "Autumn  18.265201  32.417538   5.262797  2.092224\n",
       "Spring   2.225362  39.123588   6.396450  1.302144\n",
       "Summer  24.205393  47.280988  13.871844  2.730331\n",
       "Winter   6.736506  26.154915   0.815859  0.767793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAE Across Season table for XGBoost saved as 'comparative_MAE_across_Season_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative R2 Across Season for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>0.056138</td>\n",
       "      <td>0.443856</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>0.991574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>0.847172</td>\n",
       "      <td>0.307172</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0.998018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>-1.697060</td>\n",
       "      <td>-0.663950</td>\n",
       "      <td>0.377868</td>\n",
       "      <td>0.968669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>0.860473</td>\n",
       "      <td>0.732530</td>\n",
       "      <td>0.997685</td>\n",
       "      <td>0.999110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL      MSFT     GOOGL      AMZN\n",
       "Season                                        \n",
       "Autumn  0.056138  0.443856  0.865441  0.991574\n",
       "Spring  0.847172  0.307172  0.841629  0.998018\n",
       "Summer -1.697060 -0.663950  0.377868  0.968669\n",
       "Winter  0.860473  0.732530  0.997685  0.999110"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative R2 Across Season table for XGBoost saved as 'comparative_R2_across_Season_xgb.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAPE Across Season for All Stocks - XGBoost\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>8.275229</td>\n",
       "      <td>7.936328</td>\n",
       "      <td>3.383358</td>\n",
       "      <td>1.330543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>1.232589</td>\n",
       "      <td>9.487843</td>\n",
       "      <td>3.945145</td>\n",
       "      <td>0.896566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>11.302339</td>\n",
       "      <td>10.970065</td>\n",
       "      <td>7.993662</td>\n",
       "      <td>1.547347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>3.628497</td>\n",
       "      <td>6.724702</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.667275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL       MSFT     GOOGL      AMZN\n",
       "Season                                          \n",
       "Autumn   8.275229   7.936328  3.383358  1.330543\n",
       "Spring   1.232589   9.487843  3.945145  0.896566\n",
       "Summer  11.302339  10.970065  7.993662  1.547347\n",
       "Winter   3.628497   6.724702  0.709932  0.667275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAPE Across Season table for XGBoost saved as 'comparative_MAPE_across_Season_xgb.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Training and Evaluating XGBoost Models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import pickle\n",
    "\n",
    "# Define Parameters\n",
    "TIMESTEPS = 60  # Ensure consistency with LSTM and GRU models\n",
    "model_save_dir = '../models/xgb_models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "overall_metrics_xgb = {}\n",
    "grouped_metrics_all_xgb = {'Month': {}, 'Quarter': {}, 'Season': {}}\n",
    "\n",
    "# Function to Add Time Features\n",
    "def add_time_features_xgb(eval_df):\n",
    "    eval_df['Month'] = eval_df['Date'].dt.month\n",
    "    eval_df['Quarter'] = eval_df['Date'].dt.quarter\n",
    "    eval_df['Season'] = eval_df['Month'].apply(\n",
    "        lambda month: 'Winter' if month in [12, 1, 2] else\n",
    "                      'Spring' if month in [3, 4, 5] else\n",
    "                      'Summer' if month in [6, 7, 8] else\n",
    "                      'Autumn'\n",
    "    )\n",
    "    return eval_df\n",
    "\n",
    "# Iterate Through Each Stock for Evaluation and Plotting\n",
    "for stock in scaled_daily_data.keys():\n",
    "    print(f\"\\n{'='*50}\\nTraining and Evaluating XGBoost Model for {stock}\\n{'='*50}\")\n",
    "    \n",
    "    # Retrieve Scaled Data\n",
    "    data = scaled_daily_data[stock]\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    y_train_scaled = data['y_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_test_scaled = data['y_test_scaled']\n",
    "    scaler_X = data['scaler_X']\n",
    "    scaler_y = data['scaler_y']\n",
    "    test_dates = data.get('test_dates')  # Retrieve 'test_dates'\n",
    "    \n",
    "    # Ensure X_train_scaled is a DataFrame with feature names\n",
    "    if isinstance(X_train_scaled, np.ndarray):\n",
    "        X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=scaler_X.feature_names_in_, index=X_train_scaled.index)\n",
    "    else:\n",
    "        X_train_scaled_df = X_train_scaled\n",
    "    \n",
    "    # Initialize and Train XGBoost Regressor\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train_scaled_df, y_train_scaled)\n",
    "    print(f\" - XGBoost model trained for {stock}\")\n",
    "    \n",
    "    # Save feature names used in training\n",
    "    feature_names = X_train_scaled_df.columns.tolist()\n",
    "    feature_names_path = os.path.join(model_save_dir, f'feature_names_{stock}.pkl')\n",
    "    with open(feature_names_path, 'wb') as f:\n",
    "        pickle.dump(feature_names, f)\n",
    "    print(f\" - Feature names saved for {stock} at {feature_names_path}\")\n",
    "    \n",
    "    # Prepare test data with correct feature names\n",
    "    if isinstance(X_test_scaled, np.ndarray):\n",
    "        X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=scaler_X.feature_names_in_, index=X_test_scaled.index)\n",
    "    else:\n",
    "        X_test_scaled_df = X_test_scaled\n",
    "    \n",
    "    # Predict on Test Data\n",
    "    predictions_scaled = xgb_model.predict(X_test_scaled_df)\n",
    "    \n",
    "    # Inverse Transform Predictions and Targets\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()\n",
    "    y_test = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Create Evaluation DataFrame\n",
    "    if isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "        dates = X_test_scaled_df.index\n",
    "    elif 'Date' in X_test_scaled_df.columns:\n",
    "        dates = pd.to_datetime(X_test_scaled_df['Date'])\n",
    "    elif test_dates is not None and len(test_dates) == len(y_test):\n",
    "        dates = test_dates\n",
    "    else:\n",
    "        print(f\" - No Date information found for {stock}. Creating dummy dates.\")\n",
    "        dates = pd.date_range(start='2020-01-01', periods=len(y_test), freq='D')\n",
    "    \n",
    "    eval_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Actual': y_test,\n",
    "        'Predicted': predictions\n",
    "    })\n",
    "    \n",
    "    # Add Time Features\n",
    "    eval_df = add_time_features_xgb(eval_df)\n",
    "    \n",
    "    # Calculate Overall Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(eval_df['Actual'], eval_df['Predicted']))\n",
    "    mae = mean_absolute_error(eval_df['Actual'], eval_df['Predicted'])\n",
    "    r2 = r2_score(eval_df['Actual'], eval_df['Predicted'])\n",
    "    mape = mean_absolute_percentage_error(eval_df['Actual'], eval_df['Predicted']) * 100\n",
    "    \n",
    "    overall_metrics_xgb[stock] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    print(f\" - Overall Evaluation Metrics for {stock}:\")\n",
    "    print(f\"    RMSE = {rmse:.4f}\")\n",
    "    print(f\"    MAE = {mae:.4f}\")\n",
    "    print(f\"    R2 = {r2:.4f}\")\n",
    "    print(f\"    MAPE = {mape:.2f}%\")\n",
    "    \n",
    "    # Calculate Grouped Metrics\n",
    "    grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Actual'], x['Predicted'])),\n",
    "        'MAE': mean_absolute_error(x['Actual'], x['Predicted']),\n",
    "        'R2': r2_score(x['Actual'], x['Predicted']),\n",
    "        'MAPE': mean_absolute_percentage_error(x['Actual'], x['Predicted']) * 100\n",
    "    }))\n",
    "    \n",
    "    grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Actual'], x['Predicted'])),\n",
    "        'MAE': mean_absolute_error(x['Actual'], x['Predicted']),\n",
    "        'R2': r2_score(x['Actual'], x['Predicted']),\n",
    "        'MAPE': mean_absolute_percentage_error(x['Actual'], x['Predicted']) * 100\n",
    "    }))\n",
    "    \n",
    "    grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Actual'], x['Predicted'])),\n",
    "        'MAE': mean_absolute_error(x['Actual'], x['Predicted']),\n",
    "        'R2': r2_score(x['Actual'], x['Predicted']),\n",
    "        'MAPE': mean_absolute_percentage_error(x['Actual'], x['Predicted']) * 100\n",
    "    }))\n",
    "    \n",
    "    # Reset index to turn the grouping column into a regular column\n",
    "    grouped_metrics_month = grouped_metrics_month.reset_index()\n",
    "    grouped_metrics_quarter = grouped_metrics_quarter.reset_index()\n",
    "    grouped_metrics_season = grouped_metrics_season.reset_index()\n",
    "    \n",
    "    grouped_metrics_all_xgb['Month'][stock] = grouped_metrics_month\n",
    "    grouped_metrics_all_xgb['Quarter'][stock] = grouped_metrics_quarter\n",
    "    grouped_metrics_all_xgb['Season'][stock] = grouped_metrics_season\n",
    "\n",
    "    # Save the trained model\n",
    "    model_save_path = os.path.join(model_save_dir, f'xgb_{stock}_model.json')\n",
    "    xgb_model.save_model(model_save_path)\n",
    "    print(f\" - XGBoost model saved for {stock} at {model_save_path}\")\n",
    "    \n",
    "    print(f\"Training and evaluation completed for {stock}.\\n\")\n",
    "\n",
    "# Create Overall Metrics Table\n",
    "overall_metrics_xgb_df = pd.DataFrame(overall_metrics_xgb).T\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Overall Evaluation Metrics for All Stocks - XGBoost\")\n",
    "print(\"=\"*50)\n",
    "display(overall_metrics_xgb_df)\n",
    "overall_metrics_xgb_df.to_csv('overall_evaluation_metrics_xgb.csv')\n",
    "print(\"\\n - Overall Evaluation Metrics table for XGBoost saved as 'overall_evaluation_metrics_xgb.csv'.\")\n",
    "\n",
    "# Function to Create Grouped Metrics Tables\n",
    "def create_grouped_metrics_tables_xgb(grouped_metrics_all_xgb, grouping):\n",
    "    grouped_metrics_tables_xgb = {}\n",
    "    for stock, metrics in grouped_metrics_all_xgb[grouping].items():\n",
    "        metrics_df = metrics  # Already reset index in the loop\n",
    "        grouped_metrics_tables_xgb[stock] = metrics_df\n",
    "    return grouped_metrics_tables_xgb\n",
    "\n",
    "# Create and Save Grouped Metrics Tables\n",
    "for grouping in ['Month', 'Quarter', 'Season']:\n",
    "    grouped_tables_xgb = create_grouped_metrics_tables_xgb(grouped_metrics_all_xgb, grouping)\n",
    "    for stock, table in grouped_tables_xgb.items():\n",
    "        print(f\"\\n{'='*50}\\n{grouping} Evaluation Metrics for {stock} - XGBoost\\n{'='*50}\")\n",
    "        display(table)\n",
    "        filename = f'{stock}_{grouping}_evaluation_metrics_xgb.csv'\n",
    "        table.to_csv(filename, index=False)\n",
    "        print(f\" - {grouping} Evaluation Metrics table for {stock} saved as '{filename}'.\")\n",
    "    \n",
    "    # Create Comparative Metrics Tables Across Stocks\n",
    "    for metric in ['RMSE', 'MAE', 'R2', 'MAPE']:\n",
    "        comparative_df_xgb = pd.DataFrame({stock: grouped_metrics_all_xgb[grouping][stock][metric] for stock in grouped_metrics_all_xgb[grouping].keys()})\n",
    "        comparative_df_xgb.index = grouped_metrics_all_xgb[grouping][stock][grouping]\n",
    "        comparative_df_xgb.index.name = grouping\n",
    "        print(f\"\\n{'='*50}\\nComparative {metric} Across {grouping} for All Stocks - XGBoost\\n{'='*50}\")\n",
    "        display(comparative_df_xgb)\n",
    "        filename = f'comparative_{metric}_across_{grouping}_xgb.csv'\n",
    "        comparative_df_xgb.to_csv(filename)\n",
    "        print(f\" - Comparative {metric} Across {grouping} table for XGBoost saved as '{filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfa9342-cdf6-4acb-8bcb-d0ce6bcdbd43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and Evaluating Random Forest Model for AAPL\n",
      "==================================================\n",
      " - Random Forest model trained for AAPL\n",
      " - Feature names saved for AAPL at ../models/random_forest_models/feature_names_AAPL.pkl\n",
      " - Overall Evaluation Metrics for AAPL:\n",
      "    RMSE = 21.0155\n",
      "    MAE = 12.3651\n",
      "    R2 = 0.3642\n",
      "    MAPE = 5.85%\n",
      " - Random Forest model saved for AAPL at ../models/random_forest_models/rf_AAPL_model.joblib\n",
      "Training and evaluation completed for AAPL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating Random Forest Model for MSFT\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:123: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:130: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:137: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Random Forest model trained for MSFT\n",
      " - Feature names saved for MSFT at ../models/random_forest_models/feature_names_MSFT.pkl\n",
      " - Overall Evaluation Metrics for MSFT:\n",
      "    RMSE = 52.4910\n",
      "    MAE = 35.9495\n",
      "    R2 = 0.4021\n",
      "    MAPE = 8.71%\n",
      " - Random Forest model saved for MSFT at ../models/random_forest_models/rf_MSFT_model.joblib\n",
      "Training and evaluation completed for MSFT.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating Random Forest Model for GOOGL\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:123: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:130: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:137: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Random Forest model trained for GOOGL\n",
      " - Feature names saved for GOOGL at ../models/random_forest_models/feature_names_GOOGL.pkl\n",
      " - Overall Evaluation Metrics for GOOGL:\n",
      "    RMSE = 11.8120\n",
      "    MAE = 6.4051\n",
      "    R2 = 0.8179\n",
      "    MAPE = 3.91%\n",
      " - Random Forest model saved for GOOGL at ../models/random_forest_models/rf_GOOGL_model.joblib\n",
      "Training and evaluation completed for GOOGL.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating Random Forest Model for AMZN\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:123: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:130: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:137: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Random Forest model trained for AMZN\n",
      " - Feature names saved for AMZN at ../models/random_forest_models/feature_names_AMZN.pkl\n",
      " - Overall Evaluation Metrics for AMZN:\n",
      "    RMSE = 2.9358\n",
      "    MAE = 1.6861\n",
      "    R2 = 0.9930\n",
      "    MAPE = 1.10%\n",
      " - Random Forest model saved for AMZN at ../models/random_forest_models/rf_AMZN_model.joblib\n",
      "Training and evaluation completed for AMZN.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Overall Evaluation Metrics for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:123: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:130: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
      "/var/folders/m_/x4c205xx5dz905qk58qc78gm0000gn/T/ipykernel_9451/2355512353.py:137: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>21.015516</td>\n",
       "      <td>12.365092</td>\n",
       "      <td>0.364223</td>\n",
       "      <td>5.849518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>52.490979</td>\n",
       "      <td>35.949461</td>\n",
       "      <td>0.402119</td>\n",
       "      <td>8.705810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>11.812010</td>\n",
       "      <td>6.405069</td>\n",
       "      <td>0.817862</td>\n",
       "      <td>3.908214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>2.935761</td>\n",
       "      <td>1.686115</td>\n",
       "      <td>0.992978</td>\n",
       "      <td>1.100694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RMSE        MAE        R2      MAPE\n",
       "AAPL   21.015516  12.365092  0.364223  5.849518\n",
       "MSFT   52.490979  35.949461  0.402119  8.705810\n",
       "GOOGL  11.812010   6.405069  0.817862  3.908214\n",
       "AMZN    2.935761   1.686115  0.992978  1.100694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Overall Evaluation Metrics table for Random Forest saved as 'overall_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for AAPL - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.569826</td>\n",
       "      <td>5.483422</td>\n",
       "      <td>0.918651</td>\n",
       "      <td>3.012598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.316650</td>\n",
       "      <td>3.941839</td>\n",
       "      <td>0.903758</td>\n",
       "      <td>2.179968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.194161</td>\n",
       "      <td>0.994367</td>\n",
       "      <td>0.985054</td>\n",
       "      <td>0.610899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.190077</td>\n",
       "      <td>0.955172</td>\n",
       "      <td>0.878032</td>\n",
       "      <td>0.569247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.553307</td>\n",
       "      <td>4.408831</td>\n",
       "      <td>0.366785</td>\n",
       "      <td>2.346895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20.430917</td>\n",
       "      <td>16.001960</td>\n",
       "      <td>-1.601720</td>\n",
       "      <td>7.836589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>35.061171</td>\n",
       "      <td>30.889723</td>\n",
       "      <td>-3.444378</td>\n",
       "      <td>14.221990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>30.859990</td>\n",
       "      <td>23.135860</td>\n",
       "      <td>-1.116477</td>\n",
       "      <td>10.567676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>32.438764</td>\n",
       "      <td>23.841383</td>\n",
       "      <td>-0.850537</td>\n",
       "      <td>10.747264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>35.440438</td>\n",
       "      <td>24.593986</td>\n",
       "      <td>-0.484406</td>\n",
       "      <td>10.737619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>6.410442</td>\n",
       "      <td>4.566174</td>\n",
       "      <td>0.903759</td>\n",
       "      <td>2.529794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>11.229287</td>\n",
       "      <td>8.157472</td>\n",
       "      <td>0.846546</td>\n",
       "      <td>4.273994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month       RMSE        MAE        R2       MAPE\n",
       "0       1   7.569826   5.483422  0.918651   3.012598\n",
       "1       2   5.316650   3.941839  0.903758   2.179968\n",
       "2       3   1.194161   0.994367  0.985054   0.610899\n",
       "3       4   1.190077   0.955172  0.878032   0.569247\n",
       "4       5   6.553307   4.408831  0.366785   2.346895\n",
       "5       6  20.430917  16.001960 -1.601720   7.836589\n",
       "6       7  35.061171  30.889723 -3.444378  14.221990\n",
       "7       8  30.859990  23.135860 -1.116477  10.567676\n",
       "8       9  32.438764  23.841383 -0.850537  10.747264\n",
       "9      10  35.440438  24.593986 -0.484406  10.737619\n",
       "10     11   6.410442   4.566174  0.903759   2.529794\n",
       "11     12  11.229287   8.157472  0.846546   4.273994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for AAPL saved as 'AAPL_Month_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for MSFT - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35.877189</td>\n",
       "      <td>25.667412</td>\n",
       "      <td>0.782043</td>\n",
       "      <td>6.682965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49.366630</td>\n",
       "      <td>36.275398</td>\n",
       "      <td>0.565365</td>\n",
       "      <td>9.004785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>52.292542</td>\n",
       "      <td>36.505128</td>\n",
       "      <td>0.521837</td>\n",
       "      <td>8.887320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>54.464016</td>\n",
       "      <td>40.143372</td>\n",
       "      <td>0.248637</td>\n",
       "      <td>9.753013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>54.748695</td>\n",
       "      <td>39.281576</td>\n",
       "      <td>-0.094573</td>\n",
       "      <td>9.453885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>67.669103</td>\n",
       "      <td>47.070929</td>\n",
       "      <td>-0.652420</td>\n",
       "      <td>10.764869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>77.090155</td>\n",
       "      <td>57.129577</td>\n",
       "      <td>-1.096028</td>\n",
       "      <td>12.904041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>51.158665</td>\n",
       "      <td>36.625654</td>\n",
       "      <td>-0.322728</td>\n",
       "      <td>8.935016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>59.684210</td>\n",
       "      <td>42.696979</td>\n",
       "      <td>-0.418479</td>\n",
       "      <td>10.097535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>54.634849</td>\n",
       "      <td>38.578609</td>\n",
       "      <td>-0.056054</td>\n",
       "      <td>9.292085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>20.686770</td>\n",
       "      <td>14.439118</td>\n",
       "      <td>0.902871</td>\n",
       "      <td>4.023320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>22.996520</td>\n",
       "      <td>16.846178</td>\n",
       "      <td>0.869461</td>\n",
       "      <td>4.638298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month       RMSE        MAE        R2       MAPE\n",
       "0       1  35.877189  25.667412  0.782043   6.682965\n",
       "1       2  49.366630  36.275398  0.565365   9.004785\n",
       "2       3  52.292542  36.505128  0.521837   8.887320\n",
       "3       4  54.464016  40.143372  0.248637   9.753013\n",
       "4       5  54.748695  39.281576 -0.094573   9.453885\n",
       "5       6  67.669103  47.070929 -0.652420  10.764869\n",
       "6       7  77.090155  57.129577 -1.096028  12.904041\n",
       "7       8  51.158665  36.625654 -0.322728   8.935016\n",
       "8       9  59.684210  42.696979 -0.418479  10.097535\n",
       "9      10  54.634849  38.578609 -0.056054   9.292085\n",
       "10     11  20.686770  14.439118  0.902871   4.023320\n",
       "11     12  22.996520  16.846178  0.869461   4.638298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for MSFT saved as 'MSFT_Month_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for GOOGL - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.561016</td>\n",
       "      <td>1.166854</td>\n",
       "      <td>0.996353</td>\n",
       "      <td>0.970260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.185179</td>\n",
       "      <td>0.879562</td>\n",
       "      <td>0.997490</td>\n",
       "      <td>0.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.031326</td>\n",
       "      <td>0.888361</td>\n",
       "      <td>0.997979</td>\n",
       "      <td>0.758934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.200949</td>\n",
       "      <td>4.994309</td>\n",
       "      <td>0.922736</td>\n",
       "      <td>3.236044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16.729100</td>\n",
       "      <td>12.015641</td>\n",
       "      <td>0.656666</td>\n",
       "      <td>7.063202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20.437090</td>\n",
       "      <td>14.526080</td>\n",
       "      <td>0.457768</td>\n",
       "      <td>8.294879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>24.088874</td>\n",
       "      <td>17.420144</td>\n",
       "      <td>0.329872</td>\n",
       "      <td>9.674413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>11.301584</td>\n",
       "      <td>8.337376</td>\n",
       "      <td>0.543112</td>\n",
       "      <td>5.175187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>7.980653</td>\n",
       "      <td>5.535097</td>\n",
       "      <td>0.601154</td>\n",
       "      <td>3.503924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>11.579684</td>\n",
       "      <td>8.352230</td>\n",
       "      <td>0.631685</td>\n",
       "      <td>5.154417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.447989</td>\n",
       "      <td>1.143531</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>1.072447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.037349</td>\n",
       "      <td>0.848727</td>\n",
       "      <td>0.997782</td>\n",
       "      <td>0.774448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month       RMSE        MAE        R2      MAPE\n",
       "0       1   1.561016   1.166854  0.996353  0.970260\n",
       "1       2   1.185179   0.879562  0.997490  0.770596\n",
       "2       3   1.031326   0.888361  0.997979  0.758934\n",
       "3       4   7.200949   4.994309  0.922736  3.236044\n",
       "4       5  16.729100  12.015641  0.656666  7.063202\n",
       "5       6  20.437090  14.526080  0.457768  8.294879\n",
       "6       7  24.088874  17.420144  0.329872  9.674413\n",
       "7       8  11.301584   8.337376  0.543112  5.175187\n",
       "8       9   7.980653   5.535097  0.601154  3.503924\n",
       "9      10  11.579684   8.352230  0.631685  5.154417\n",
       "10     11   1.447989   1.143531  0.994852  1.072447\n",
       "11     12   1.037349   0.848727  0.997782  0.774448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for GOOGL saved as 'GOOGL_Month_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Month Evaluation Metrics for AMZN - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.212346</td>\n",
       "      <td>1.015518</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.892610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.154936</td>\n",
       "      <td>0.824639</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.663614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.987668</td>\n",
       "      <td>0.817505</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.675989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.758486</td>\n",
       "      <td>1.431511</td>\n",
       "      <td>0.997963</td>\n",
       "      <td>1.017657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.995899</td>\n",
       "      <td>1.474755</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.943215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3.571356</td>\n",
       "      <td>2.292149</td>\n",
       "      <td>0.985865</td>\n",
       "      <td>1.360212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7.135266</td>\n",
       "      <td>4.424334</td>\n",
       "      <td>0.944299</td>\n",
       "      <td>2.344278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.632501</td>\n",
       "      <td>1.133920</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.740345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3.488826</td>\n",
       "      <td>2.415065</td>\n",
       "      <td>0.981357</td>\n",
       "      <td>1.402757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.429965</td>\n",
       "      <td>2.681868</td>\n",
       "      <td>0.987527</td>\n",
       "      <td>1.614068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.191406</td>\n",
       "      <td>0.882668</td>\n",
       "      <td>0.997724</td>\n",
       "      <td>0.821810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.918565</td>\n",
       "      <td>0.797363</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.717931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month      RMSE       MAE        R2      MAPE\n",
       "0       1  1.212346  1.015518  0.998380  0.892610\n",
       "1       2  1.154936  0.824639  0.998978  0.663614\n",
       "2       3  0.987668  0.817505  0.999395  0.675989\n",
       "3       4  1.758486  1.431511  0.997963  1.017657\n",
       "4       5  1.995899  1.474755  0.997000  0.943215\n",
       "5       6  3.571356  2.292149  0.985865  1.360212\n",
       "6       7  7.135266  4.424334  0.944299  2.344278\n",
       "7       8  1.632501  1.133920  0.992715  0.740345\n",
       "8       9  3.488826  2.415065  0.981357  1.402757\n",
       "9      10  3.429965  2.681868  0.987527  1.614068\n",
       "10     11  1.191406  0.882668  0.997724  0.821810\n",
       "11     12  0.918565  0.797363  0.999130  0.717931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Month Evaluation Metrics table for AMZN saved as 'AMZN_Month_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative RMSE Across Month for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.569826</td>\n",
       "      <td>35.877189</td>\n",
       "      <td>1.561016</td>\n",
       "      <td>1.212346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.316650</td>\n",
       "      <td>49.366630</td>\n",
       "      <td>1.185179</td>\n",
       "      <td>1.154936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.194161</td>\n",
       "      <td>52.292542</td>\n",
       "      <td>1.031326</td>\n",
       "      <td>0.987668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.190077</td>\n",
       "      <td>54.464016</td>\n",
       "      <td>7.200949</td>\n",
       "      <td>1.758486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.553307</td>\n",
       "      <td>54.748695</td>\n",
       "      <td>16.729100</td>\n",
       "      <td>1.995899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.430917</td>\n",
       "      <td>67.669103</td>\n",
       "      <td>20.437090</td>\n",
       "      <td>3.571356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.061171</td>\n",
       "      <td>77.090155</td>\n",
       "      <td>24.088874</td>\n",
       "      <td>7.135266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.859990</td>\n",
       "      <td>51.158665</td>\n",
       "      <td>11.301584</td>\n",
       "      <td>1.632501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32.438764</td>\n",
       "      <td>59.684210</td>\n",
       "      <td>7.980653</td>\n",
       "      <td>3.488826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.440438</td>\n",
       "      <td>54.634849</td>\n",
       "      <td>11.579684</td>\n",
       "      <td>3.429965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.410442</td>\n",
       "      <td>20.686770</td>\n",
       "      <td>1.447989</td>\n",
       "      <td>1.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.229287</td>\n",
       "      <td>22.996520</td>\n",
       "      <td>1.037349</td>\n",
       "      <td>0.918565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL       MSFT      GOOGL      AMZN\n",
       "Month                                           \n",
       "1       7.569826  35.877189   1.561016  1.212346\n",
       "2       5.316650  49.366630   1.185179  1.154936\n",
       "3       1.194161  52.292542   1.031326  0.987668\n",
       "4       1.190077  54.464016   7.200949  1.758486\n",
       "5       6.553307  54.748695  16.729100  1.995899\n",
       "6      20.430917  67.669103  20.437090  3.571356\n",
       "7      35.061171  77.090155  24.088874  7.135266\n",
       "8      30.859990  51.158665  11.301584  1.632501\n",
       "9      32.438764  59.684210   7.980653  3.488826\n",
       "10     35.440438  54.634849  11.579684  3.429965\n",
       "11      6.410442  20.686770   1.447989  1.191406\n",
       "12     11.229287  22.996520   1.037349  0.918565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative RMSE Across Month table for Random Forest saved as 'comparative_RMSE_across_Month_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAE Across Month for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.483422</td>\n",
       "      <td>25.667412</td>\n",
       "      <td>1.166854</td>\n",
       "      <td>1.015518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.941839</td>\n",
       "      <td>36.275398</td>\n",
       "      <td>0.879562</td>\n",
       "      <td>0.824639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994367</td>\n",
       "      <td>36.505128</td>\n",
       "      <td>0.888361</td>\n",
       "      <td>0.817505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.955172</td>\n",
       "      <td>40.143372</td>\n",
       "      <td>4.994309</td>\n",
       "      <td>1.431511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.408831</td>\n",
       "      <td>39.281576</td>\n",
       "      <td>12.015641</td>\n",
       "      <td>1.474755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.001960</td>\n",
       "      <td>47.070929</td>\n",
       "      <td>14.526080</td>\n",
       "      <td>2.292149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.889723</td>\n",
       "      <td>57.129577</td>\n",
       "      <td>17.420144</td>\n",
       "      <td>4.424334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.135860</td>\n",
       "      <td>36.625654</td>\n",
       "      <td>8.337376</td>\n",
       "      <td>1.133920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.841383</td>\n",
       "      <td>42.696979</td>\n",
       "      <td>5.535097</td>\n",
       "      <td>2.415065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.593986</td>\n",
       "      <td>38.578609</td>\n",
       "      <td>8.352230</td>\n",
       "      <td>2.681868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.566174</td>\n",
       "      <td>14.439118</td>\n",
       "      <td>1.143531</td>\n",
       "      <td>0.882668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.157472</td>\n",
       "      <td>16.846178</td>\n",
       "      <td>0.848727</td>\n",
       "      <td>0.797363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL       MSFT      GOOGL      AMZN\n",
       "Month                                           \n",
       "1       5.483422  25.667412   1.166854  1.015518\n",
       "2       3.941839  36.275398   0.879562  0.824639\n",
       "3       0.994367  36.505128   0.888361  0.817505\n",
       "4       0.955172  40.143372   4.994309  1.431511\n",
       "5       4.408831  39.281576  12.015641  1.474755\n",
       "6      16.001960  47.070929  14.526080  2.292149\n",
       "7      30.889723  57.129577  17.420144  4.424334\n",
       "8      23.135860  36.625654   8.337376  1.133920\n",
       "9      23.841383  42.696979   5.535097  2.415065\n",
       "10     24.593986  38.578609   8.352230  2.681868\n",
       "11      4.566174  14.439118   1.143531  0.882668\n",
       "12      8.157472  16.846178   0.848727  0.797363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAE Across Month table for Random Forest saved as 'comparative_MAE_across_Month_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative R2 Across Month for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918651</td>\n",
       "      <td>0.782043</td>\n",
       "      <td>0.996353</td>\n",
       "      <td>0.998380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.903758</td>\n",
       "      <td>0.565365</td>\n",
       "      <td>0.997490</td>\n",
       "      <td>0.998978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985054</td>\n",
       "      <td>0.521837</td>\n",
       "      <td>0.997979</td>\n",
       "      <td>0.999395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.878032</td>\n",
       "      <td>0.248637</td>\n",
       "      <td>0.922736</td>\n",
       "      <td>0.997963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.366785</td>\n",
       "      <td>-0.094573</td>\n",
       "      <td>0.656666</td>\n",
       "      <td>0.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.601720</td>\n",
       "      <td>-0.652420</td>\n",
       "      <td>0.457768</td>\n",
       "      <td>0.985865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.444378</td>\n",
       "      <td>-1.096028</td>\n",
       "      <td>0.329872</td>\n",
       "      <td>0.944299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.116477</td>\n",
       "      <td>-0.322728</td>\n",
       "      <td>0.543112</td>\n",
       "      <td>0.992715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.850537</td>\n",
       "      <td>-0.418479</td>\n",
       "      <td>0.601154</td>\n",
       "      <td>0.981357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.484406</td>\n",
       "      <td>-0.056054</td>\n",
       "      <td>0.631685</td>\n",
       "      <td>0.987527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.903759</td>\n",
       "      <td>0.902871</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>0.997724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.846546</td>\n",
       "      <td>0.869461</td>\n",
       "      <td>0.997782</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AAPL      MSFT     GOOGL      AMZN\n",
       "Month                                        \n",
       "1      0.918651  0.782043  0.996353  0.998380\n",
       "2      0.903758  0.565365  0.997490  0.998978\n",
       "3      0.985054  0.521837  0.997979  0.999395\n",
       "4      0.878032  0.248637  0.922736  0.997963\n",
       "5      0.366785 -0.094573  0.656666  0.997000\n",
       "6     -1.601720 -0.652420  0.457768  0.985865\n",
       "7     -3.444378 -1.096028  0.329872  0.944299\n",
       "8     -1.116477 -0.322728  0.543112  0.992715\n",
       "9     -0.850537 -0.418479  0.601154  0.981357\n",
       "10    -0.484406 -0.056054  0.631685  0.987527\n",
       "11     0.903759  0.902871  0.994852  0.997724\n",
       "12     0.846546  0.869461  0.997782  0.999130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative R2 Across Month table for Random Forest saved as 'comparative_R2_across_Month_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAPE Across Month for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.012598</td>\n",
       "      <td>6.682965</td>\n",
       "      <td>0.970260</td>\n",
       "      <td>0.892610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.179968</td>\n",
       "      <td>9.004785</td>\n",
       "      <td>0.770596</td>\n",
       "      <td>0.663614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.610899</td>\n",
       "      <td>8.887320</td>\n",
       "      <td>0.758934</td>\n",
       "      <td>0.675989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.569247</td>\n",
       "      <td>9.753013</td>\n",
       "      <td>3.236044</td>\n",
       "      <td>1.017657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.346895</td>\n",
       "      <td>9.453885</td>\n",
       "      <td>7.063202</td>\n",
       "      <td>0.943215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.836589</td>\n",
       "      <td>10.764869</td>\n",
       "      <td>8.294879</td>\n",
       "      <td>1.360212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.221990</td>\n",
       "      <td>12.904041</td>\n",
       "      <td>9.674413</td>\n",
       "      <td>2.344278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.567676</td>\n",
       "      <td>8.935016</td>\n",
       "      <td>5.175187</td>\n",
       "      <td>0.740345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.747264</td>\n",
       "      <td>10.097535</td>\n",
       "      <td>3.503924</td>\n",
       "      <td>1.402757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.737619</td>\n",
       "      <td>9.292085</td>\n",
       "      <td>5.154417</td>\n",
       "      <td>1.614068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.529794</td>\n",
       "      <td>4.023320</td>\n",
       "      <td>1.072447</td>\n",
       "      <td>0.821810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.273994</td>\n",
       "      <td>4.638298</td>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.717931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL       MSFT     GOOGL      AMZN\n",
       "Month                                          \n",
       "1       3.012598   6.682965  0.970260  0.892610\n",
       "2       2.179968   9.004785  0.770596  0.663614\n",
       "3       0.610899   8.887320  0.758934  0.675989\n",
       "4       0.569247   9.753013  3.236044  1.017657\n",
       "5       2.346895   9.453885  7.063202  0.943215\n",
       "6       7.836589  10.764869  8.294879  1.360212\n",
       "7      14.221990  12.904041  9.674413  2.344278\n",
       "8      10.567676   8.935016  5.175187  0.740345\n",
       "9      10.747264  10.097535  3.503924  1.402757\n",
       "10     10.737619   9.292085  5.154417  1.614068\n",
       "11      2.529794   4.023320  1.072447  0.821810\n",
       "12      4.273994   4.638298  0.774448  0.717931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAPE Across Month table for Random Forest saved as 'comparative_MAPE_across_Month_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for AAPL - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.344335</td>\n",
       "      <td>3.425283</td>\n",
       "      <td>0.922374</td>\n",
       "      <td>1.908975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.212970</td>\n",
       "      <td>6.985832</td>\n",
       "      <td>0.252882</td>\n",
       "      <td>3.520528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32.793339</td>\n",
       "      <td>25.922342</td>\n",
       "      <td>-1.408725</td>\n",
       "      <td>11.832752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22.258604</td>\n",
       "      <td>12.757539</td>\n",
       "      <td>0.486875</td>\n",
       "      <td>5.974046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter       RMSE        MAE        R2       MAPE\n",
       "0        1   5.344335   3.425283  0.922374   1.908975\n",
       "1        2  12.212970   6.985832  0.252882   3.520528\n",
       "2        3  32.793339  25.922342 -1.408725  11.832752\n",
       "3        4  22.258604  12.757539  0.486875   5.974046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for AAPL saved as 'AAPL_Quarter_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for MSFT - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>46.451611</td>\n",
       "      <td>32.819715</td>\n",
       "      <td>0.630862</td>\n",
       "      <td>8.189780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>59.104670</td>\n",
       "      <td>42.056838</td>\n",
       "      <td>-0.065355</td>\n",
       "      <td>9.971514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63.361484</td>\n",
       "      <td>45.318707</td>\n",
       "      <td>-0.558315</td>\n",
       "      <td>10.613755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>36.867534</td>\n",
       "      <td>23.696669</td>\n",
       "      <td>0.705531</td>\n",
       "      <td>6.072605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter       RMSE        MAE        R2       MAPE\n",
       "0        1  46.451611  32.819715  0.630862   8.189780\n",
       "1        2  59.104670  42.056838 -0.065355   9.971514\n",
       "2        3  63.361484  45.318707 -0.558315  10.613755\n",
       "3        4  36.867534  23.696669  0.705531   6.072605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for MSFT saved as 'MSFT_Quarter_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for GOOGL - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.276508</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.997212</td>\n",
       "      <td>0.833074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15.785297</td>\n",
       "      <td>10.515985</td>\n",
       "      <td>0.686323</td>\n",
       "      <td>6.202031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16.038045</td>\n",
       "      <td>10.458518</td>\n",
       "      <td>0.422909</td>\n",
       "      <td>6.136738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.940702</td>\n",
       "      <td>3.583410</td>\n",
       "      <td>0.927861</td>\n",
       "      <td>2.412062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter       RMSE        MAE        R2      MAPE\n",
       "0        1   1.276508   0.978402  0.997212  0.833074\n",
       "1        2  15.785297  10.515985  0.686323  6.202031\n",
       "2        3  16.038045  10.458518  0.422909  6.136738\n",
       "3        4   6.940702   3.583410  0.927861  2.412062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for GOOGL saved as 'GOOGL_Quarter_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Quarter Evaluation Metrics for AMZN - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.119772</td>\n",
       "      <td>0.885771</td>\n",
       "      <td>0.999038</td>\n",
       "      <td>0.744272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.549110</td>\n",
       "      <td>1.722137</td>\n",
       "      <td>0.994883</td>\n",
       "      <td>1.101071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.649197</td>\n",
       "      <td>2.625599</td>\n",
       "      <td>0.966805</td>\n",
       "      <td>1.479413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.207269</td>\n",
       "      <td>1.487875</td>\n",
       "      <td>0.995731</td>\n",
       "      <td>1.067064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter      RMSE       MAE        R2      MAPE\n",
       "0        1  1.119772  0.885771  0.999038  0.744272\n",
       "1        2  2.549110  1.722137  0.994883  1.101071\n",
       "2        3  4.649197  2.625599  0.966805  1.479413\n",
       "3        4  2.207269  1.487875  0.995731  1.067064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quarter Evaluation Metrics table for AMZN saved as 'AMZN_Quarter_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative RMSE Across Quarter for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.344335</td>\n",
       "      <td>46.451611</td>\n",
       "      <td>1.276508</td>\n",
       "      <td>1.119772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.212970</td>\n",
       "      <td>59.104670</td>\n",
       "      <td>15.785297</td>\n",
       "      <td>2.549110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.793339</td>\n",
       "      <td>63.361484</td>\n",
       "      <td>16.038045</td>\n",
       "      <td>4.649197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.258604</td>\n",
       "      <td>36.867534</td>\n",
       "      <td>6.940702</td>\n",
       "      <td>2.207269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL       MSFT      GOOGL      AMZN\n",
       "Quarter                                           \n",
       "1         5.344335  46.451611   1.276508  1.119772\n",
       "2        12.212970  59.104670  15.785297  2.549110\n",
       "3        32.793339  63.361484  16.038045  4.649197\n",
       "4        22.258604  36.867534   6.940702  2.207269"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative RMSE Across Quarter table for Random Forest saved as 'comparative_RMSE_across_Quarter_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAE Across Quarter for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.425283</td>\n",
       "      <td>32.819715</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.885771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.985832</td>\n",
       "      <td>42.056838</td>\n",
       "      <td>10.515985</td>\n",
       "      <td>1.722137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.922342</td>\n",
       "      <td>45.318707</td>\n",
       "      <td>10.458518</td>\n",
       "      <td>2.625599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.757539</td>\n",
       "      <td>23.696669</td>\n",
       "      <td>3.583410</td>\n",
       "      <td>1.487875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL       MSFT      GOOGL      AMZN\n",
       "Quarter                                           \n",
       "1         3.425283  32.819715   0.978402  0.885771\n",
       "2         6.985832  42.056838  10.515985  1.722137\n",
       "3        25.922342  45.318707  10.458518  2.625599\n",
       "4        12.757539  23.696669   3.583410  1.487875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAE Across Quarter table for Random Forest saved as 'comparative_MAE_across_Quarter_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative R2 Across Quarter for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.922374</td>\n",
       "      <td>0.630862</td>\n",
       "      <td>0.997212</td>\n",
       "      <td>0.999038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.252882</td>\n",
       "      <td>-0.065355</td>\n",
       "      <td>0.686323</td>\n",
       "      <td>0.994883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.408725</td>\n",
       "      <td>-0.558315</td>\n",
       "      <td>0.422909</td>\n",
       "      <td>0.966805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.486875</td>\n",
       "      <td>0.705531</td>\n",
       "      <td>0.927861</td>\n",
       "      <td>0.995731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL      MSFT     GOOGL      AMZN\n",
       "Quarter                                        \n",
       "1        0.922374  0.630862  0.997212  0.999038\n",
       "2        0.252882 -0.065355  0.686323  0.994883\n",
       "3       -1.408725 -0.558315  0.422909  0.966805\n",
       "4        0.486875  0.705531  0.927861  0.995731"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative R2 Across Quarter table for Random Forest saved as 'comparative_R2_across_Quarter_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAPE Across Quarter for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.908975</td>\n",
       "      <td>8.189780</td>\n",
       "      <td>0.833074</td>\n",
       "      <td>0.744272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.520528</td>\n",
       "      <td>9.971514</td>\n",
       "      <td>6.202031</td>\n",
       "      <td>1.101071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.832752</td>\n",
       "      <td>10.613755</td>\n",
       "      <td>6.136738</td>\n",
       "      <td>1.479413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.974046</td>\n",
       "      <td>6.072605</td>\n",
       "      <td>2.412062</td>\n",
       "      <td>1.067064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL       MSFT     GOOGL      AMZN\n",
       "Quarter                                          \n",
       "1         1.908975   8.189780  0.833074  0.744272\n",
       "2         3.520528   9.971514  6.202031  1.101071\n",
       "3        11.832752  10.613755  6.136738  1.479413\n",
       "4         5.974046   6.072605  2.412062  1.067064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAPE Across Quarter table for Random Forest saved as 'comparative_MAPE_across_Quarter_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for AAPL - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>28.108057</td>\n",
       "      <td>17.733575</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>8.026258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>3.961734</td>\n",
       "      <td>2.155534</td>\n",
       "      <td>0.853694</td>\n",
       "      <td>1.194306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>29.588004</td>\n",
       "      <td>23.453232</td>\n",
       "      <td>-1.605912</td>\n",
       "      <td>10.916004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>8.441225</td>\n",
       "      <td>5.892631</td>\n",
       "      <td>0.884623</td>\n",
       "      <td>3.171645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       RMSE        MAE        R2       MAPE\n",
       "0  Autumn  28.108057  17.733575  0.100730   8.026258\n",
       "1  Spring   3.961734   2.155534  0.853694   1.194306\n",
       "2  Summer  29.588004  23.453232 -1.605912  10.916004\n",
       "3  Winter   8.441225   5.892631  0.884623   3.171645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for AAPL saved as 'AAPL_Season_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for MSFT - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>48.178252</td>\n",
       "      <td>31.892595</td>\n",
       "      <td>0.458455</td>\n",
       "      <td>7.803344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>53.843660</td>\n",
       "      <td>38.624907</td>\n",
       "      <td>0.322384</td>\n",
       "      <td>9.359369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>65.840428</td>\n",
       "      <td>46.696330</td>\n",
       "      <td>-0.634883</td>\n",
       "      <td>10.823939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>37.427839</td>\n",
       "      <td>26.097501</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>6.738499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       RMSE        MAE        R2       MAPE\n",
       "0  Autumn  48.178252  31.892595  0.458455   7.803344\n",
       "1  Spring  53.843660  38.624907  0.322384   9.359369\n",
       "2  Summer  65.840428  46.696330 -0.634883  10.823939\n",
       "3  Winter  37.427839  26.097501  0.736985   6.738499"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for MSFT saved as 'MSFT_Season_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for GOOGL - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>8.262286</td>\n",
       "      <td>5.080965</td>\n",
       "      <td>0.876486</td>\n",
       "      <td>3.284634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>10.638116</td>\n",
       "      <td>6.028550</td>\n",
       "      <td>0.855258</td>\n",
       "      <td>3.719475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>19.201819</td>\n",
       "      <td>13.290324</td>\n",
       "      <td>0.419807</td>\n",
       "      <td>7.645700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1.281814</td>\n",
       "      <td>0.966461</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.839556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       RMSE        MAE        R2      MAPE\n",
       "0  Autumn   8.262286   5.080965  0.876486  3.284634\n",
       "1  Spring  10.638116   6.028550  0.855258  3.719475\n",
       "2  Summer  19.201819  13.290324  0.419807  7.645700\n",
       "3  Winter   1.281814   0.966461  0.997167  0.839556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for GOOGL saved as 'GOOGL_Season_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Season Evaluation Metrics for AMZN - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>2.910614</td>\n",
       "      <td>2.002825</td>\n",
       "      <td>0.992140</td>\n",
       "      <td>1.285507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>1.639379</td>\n",
       "      <td>1.240108</td>\n",
       "      <td>0.998234</td>\n",
       "      <td>0.877289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>4.668892</td>\n",
       "      <td>2.586885</td>\n",
       "      <td>0.970144</td>\n",
       "      <td>1.466013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>1.101751</td>\n",
       "      <td>0.880075</td>\n",
       "      <td>0.998907</td>\n",
       "      <td>0.759613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season      RMSE       MAE        R2      MAPE\n",
       "0  Autumn  2.910614  2.002825  0.992140  1.285507\n",
       "1  Spring  1.639379  1.240108  0.998234  0.877289\n",
       "2  Summer  4.668892  2.586885  0.970144  1.466013\n",
       "3  Winter  1.101751  0.880075  0.998907  0.759613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Season Evaluation Metrics table for AMZN saved as 'AMZN_Season_evaluation_metrics_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative RMSE Across Season for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>28.108057</td>\n",
       "      <td>48.178252</td>\n",
       "      <td>8.262286</td>\n",
       "      <td>2.910614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>3.961734</td>\n",
       "      <td>53.843660</td>\n",
       "      <td>10.638116</td>\n",
       "      <td>1.639379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>29.588004</td>\n",
       "      <td>65.840428</td>\n",
       "      <td>19.201819</td>\n",
       "      <td>4.668892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>8.441225</td>\n",
       "      <td>37.427839</td>\n",
       "      <td>1.281814</td>\n",
       "      <td>1.101751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL       MSFT      GOOGL      AMZN\n",
       "Season                                           \n",
       "Autumn  28.108057  48.178252   8.262286  2.910614\n",
       "Spring   3.961734  53.843660  10.638116  1.639379\n",
       "Summer  29.588004  65.840428  19.201819  4.668892\n",
       "Winter   8.441225  37.427839   1.281814  1.101751"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative RMSE Across Season table for Random Forest saved as 'comparative_RMSE_across_Season_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAE Across Season for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>17.733575</td>\n",
       "      <td>31.892595</td>\n",
       "      <td>5.080965</td>\n",
       "      <td>2.002825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>2.155534</td>\n",
       "      <td>38.624907</td>\n",
       "      <td>6.028550</td>\n",
       "      <td>1.240108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>23.453232</td>\n",
       "      <td>46.696330</td>\n",
       "      <td>13.290324</td>\n",
       "      <td>2.586885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>5.892631</td>\n",
       "      <td>26.097501</td>\n",
       "      <td>0.966461</td>\n",
       "      <td>0.880075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL       MSFT      GOOGL      AMZN\n",
       "Season                                           \n",
       "Autumn  17.733575  31.892595   5.080965  2.002825\n",
       "Spring   2.155534  38.624907   6.028550  1.240108\n",
       "Summer  23.453232  46.696330  13.290324  2.586885\n",
       "Winter   5.892631  26.097501   0.966461  0.880075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAE Across Season table for Random Forest saved as 'comparative_MAE_across_Season_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative R2 Across Season for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>0.100730</td>\n",
       "      <td>0.458455</td>\n",
       "      <td>0.876486</td>\n",
       "      <td>0.992140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>0.853694</td>\n",
       "      <td>0.322384</td>\n",
       "      <td>0.855258</td>\n",
       "      <td>0.998234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>-1.605912</td>\n",
       "      <td>-0.634883</td>\n",
       "      <td>0.419807</td>\n",
       "      <td>0.970144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>0.884623</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.998907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL      MSFT     GOOGL      AMZN\n",
       "Season                                        \n",
       "Autumn  0.100730  0.458455  0.876486  0.992140\n",
       "Spring  0.853694  0.322384  0.855258  0.998234\n",
       "Summer -1.605912 -0.634883  0.419807  0.970144\n",
       "Winter  0.884623  0.736985  0.997167  0.998907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative R2 Across Season table for Random Forest saved as 'comparative_R2_across_Season_rf.csv'.\n",
      "\n",
      "==================================================\n",
      "Comparative MAPE Across Season for All Stocks - Random Forest\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autumn</th>\n",
       "      <td>8.026258</td>\n",
       "      <td>7.803344</td>\n",
       "      <td>3.284634</td>\n",
       "      <td>1.285507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring</th>\n",
       "      <td>1.194306</td>\n",
       "      <td>9.359369</td>\n",
       "      <td>3.719475</td>\n",
       "      <td>0.877289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer</th>\n",
       "      <td>10.916004</td>\n",
       "      <td>10.823939</td>\n",
       "      <td>7.645700</td>\n",
       "      <td>1.466013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter</th>\n",
       "      <td>3.171645</td>\n",
       "      <td>6.738499</td>\n",
       "      <td>0.839556</td>\n",
       "      <td>0.759613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL       MSFT     GOOGL      AMZN\n",
       "Season                                          \n",
       "Autumn   8.026258   7.803344  3.284634  1.285507\n",
       "Spring   1.194306   9.359369  3.719475  0.877289\n",
       "Summer  10.916004  10.823939  7.645700  1.466013\n",
       "Winter   3.171645   6.738499  0.839556  0.759613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Comparative MAPE Across Season table for Random Forest saved as 'comparative_MAPE_across_Season_rf.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training and Evaluating Random Forest Models\n",
    "\n",
    "# Import necessary libraries (if not already imported)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Define Parameters\n",
    "model_save_dir = '../models/random_forest_models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "overall_metrics_rf = {}\n",
    "grouped_metrics_all_rf = {'Month': {}, 'Quarter': {}, 'Season': {}}\n",
    "\n",
    "# Function to Add Time Features (if not already added)\n",
    "def add_time_features_rf(eval_df):\n",
    "    eval_df['Month'] = eval_df['Date'].dt.month\n",
    "    eval_df['Quarter'] = eval_df['Date'].dt.quarter\n",
    "    eval_df['Season'] = eval_df['Month'].apply(\n",
    "        lambda month: 'Winter' if month in [12, 1, 2] else\n",
    "                      'Spring' if month in [3, 4, 5] else\n",
    "                      'Summer' if month in [6, 7, 8] else\n",
    "                      'Autumn'\n",
    "    )\n",
    "    return eval_df\n",
    "\n",
    "# Iterate Through Each Stock for Evaluation and Plotting\n",
    "for stock in scaled_daily_data.keys():\n",
    "    print(f\"\\n{'='*50}\\nTraining and Evaluating Random Forest Model for {stock}\\n{'='*50}\")\n",
    "    \n",
    "    # Retrieve Scaled Data\n",
    "    data = scaled_daily_data[stock]\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    y_train_scaled = data['y_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_test_scaled = data['y_test_scaled']\n",
    "    scaler_X = data['scaler_X']\n",
    "    scaler_y = data['scaler_y']\n",
    "    \n",
    "    # Ensure X_train_scaled is a DataFrame with feature names\n",
    "    if isinstance(X_train_scaled, np.ndarray):\n",
    "        X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=scaler_X.feature_names_in_)\n",
    "    else:\n",
    "        X_train_scaled_df = X_train_scaled\n",
    "    \n",
    "    # Initialize and Train Random Forest Regressor\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train_scaled_df, y_train_scaled)\n",
    "    print(f\" - Random Forest model trained for {stock}\")\n",
    "    \n",
    "    # Save feature names used in training\n",
    "    feature_names = X_train_scaled_df.columns.tolist()\n",
    "    feature_names_path = os.path.join(model_save_dir, f'feature_names_{stock.upper()}.pkl')\n",
    "    with open(feature_names_path, 'wb') as f:\n",
    "        pickle.dump(feature_names, f)\n",
    "    print(f\" - Feature names saved for {stock} at {feature_names_path}\")\n",
    "    \n",
    "    # Prepare test data with correct feature names\n",
    "    if isinstance(X_test_scaled, np.ndarray):\n",
    "        X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=scaler_X.feature_names_in_)\n",
    "    else:\n",
    "        X_test_scaled_df = X_test_scaled\n",
    "    \n",
    "    # Predict on Test Data\n",
    "    predictions_scaled = rf_model.predict(X_test_scaled_df)\n",
    "  \n",
    "    # Inverse Transform Predictions and Targets\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()\n",
    "    y_test = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Retrieve 'test_dates' from scaled_daily_data\n",
    "    test_dates = data.get('test_dates')\n",
    "    \n",
    "    # Create Evaluation DataFrame using 'test_dates'\n",
    "    if test_dates is not None and len(test_dates) == len(y_test):\n",
    "        dates = test_dates\n",
    "    else:\n",
    "        print(f\" - No 'test_dates' found for {stock}. Creating dummy dates.\")\n",
    "        dates = pd.date_range(start='2020-01-01', periods=len(y_test), freq='D')\n",
    "    \n",
    "    eval_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Actual': y_test,\n",
    "        'Predicted': predictions\n",
    "    })\n",
    "    \n",
    "    # Add Time Features\n",
    "    eval_df = add_time_features_rf(eval_df)\n",
    "    \n",
    "    # Calculate Overall Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(eval_df['Actual'], eval_df['Predicted']))\n",
    "    mae = mean_absolute_error(eval_df['Actual'], eval_df['Predicted'])\n",
    "    r2 = r2_score(eval_df['Actual'], eval_df['Predicted'])\n",
    "    mape = mean_absolute_percentage_error(eval_df['Actual'], eval_df['Predicted']) * 100\n",
    "    \n",
    "    overall_metrics_rf[stock] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    print(f\" - Overall Evaluation Metrics for {stock}:\")\n",
    "    print(f\"    RMSE = {rmse:.4f}\")\n",
    "    print(f\"    MAE = {mae:.4f}\")\n",
    "    print(f\"    R2 = {r2:.4f}\")\n",
    "    print(f\"    MAPE = {mape:.2f}%\")\n",
    "    \n",
    "    # Calculate Grouped Metrics\n",
    "    grouped_metrics_month = eval_df.groupby('Month').apply(lambda x: pd.Series({\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Actual'], x['Predicted'])),\n",
    "        'MAE': mean_absolute_error(x['Actual'], x['Predicted']),\n",
    "        'R2': r2_score(x['Actual'], x['Predicted']),\n",
    "        'MAPE': mean_absolute_percentage_error(x['Actual'], x['Predicted']) * 100\n",
    "    }))\n",
    "    \n",
    "    grouped_metrics_quarter = eval_df.groupby('Quarter').apply(lambda x: pd.Series({\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Actual'], x['Predicted'])),\n",
    "        'MAE': mean_absolute_error(x['Actual'], x['Predicted']),\n",
    "        'R2': r2_score(x['Actual'], x['Predicted']),\n",
    "        'MAPE': mean_absolute_percentage_error(x['Actual'], x['Predicted']) * 100\n",
    "    }))\n",
    "    \n",
    "    grouped_metrics_season = eval_df.groupby('Season').apply(lambda x: pd.Series({\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Actual'], x['Predicted'])),\n",
    "        'MAE': mean_absolute_error(x['Actual'], x['Predicted']),\n",
    "        'R2': r2_score(x['Actual'], x['Predicted']),\n",
    "        'MAPE': mean_absolute_percentage_error(x['Actual'], x['Predicted']) * 100\n",
    "    }))\n",
    "    \n",
    "    grouped_metrics_all_rf['Month'][stock] = grouped_metrics_month\n",
    "    grouped_metrics_all_rf['Quarter'][stock] = grouped_metrics_quarter\n",
    "    grouped_metrics_all_rf['Season'][stock] = grouped_metrics_season\n",
    "    \n",
    "    # Save the trained model using joblib and change the file extension to .joblib\n",
    "    model_save_path = os.path.join(model_save_dir, f'rf_{stock.upper()}_model.joblib')\n",
    "    joblib.dump(rf_model, model_save_path)\n",
    "    print(f\" - Random Forest model saved for {stock} at {model_save_path}\")\n",
    "    \n",
    "    print(f\"Training and evaluation completed for {stock}.\\n\")\n",
    "\n",
    "# Create Overall Metrics Table\n",
    "overall_metrics_rf_df = pd.DataFrame(overall_metrics_rf).T\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Overall Evaluation Metrics for All Stocks - Random Forest\")\n",
    "print(\"=\"*50)\n",
    "display(overall_metrics_rf_df)\n",
    "overall_metrics_rf_df.to_csv('overall_evaluation_metrics_rf.csv')\n",
    "print(\"\\n - Overall Evaluation Metrics table for Random Forest saved as 'overall_evaluation_metrics_rf.csv'.\")\n",
    "\n",
    "# Function to Create Grouped Metrics Tables\n",
    "def create_grouped_metrics_tables_rf(grouped_metrics_all_rf, grouping):\n",
    "    grouped_metrics_tables_rf = {}\n",
    "    for stock, metrics in grouped_metrics_all_rf[grouping].items():\n",
    "        metrics_df = metrics.reset_index()\n",
    "        metrics_df.columns = [grouping] + list(metrics_df.columns[1:])\n",
    "        grouped_metrics_tables_rf[stock] = metrics_df\n",
    "    return grouped_metrics_tables_rf\n",
    "\n",
    "# Create and Save Grouped Metrics Tables\n",
    "for grouping in ['Month', 'Quarter', 'Season']:\n",
    "    grouped_tables_rf = create_grouped_metrics_tables_rf(grouped_metrics_all_rf, grouping)\n",
    "    for stock, table in grouped_tables_rf.items():\n",
    "        print(f\"\\n{'='*50}\\n{grouping} Evaluation Metrics for {stock} - Random Forest\\n{'='*50}\")\n",
    "        display(table)\n",
    "        filename = f'{stock}_{grouping}_evaluation_metrics_rf.csv'\n",
    "        table.to_csv(filename, index=False)\n",
    "        print(f\" - {grouping} Evaluation Metrics table for {stock} saved as '{filename}'.\")\n",
    "    \n",
    "    # Create Comparative Metrics Tables Across Stocks\n",
    "    for metric in ['RMSE', 'MAE', 'R2', 'MAPE']:\n",
    "        comparative_df_rf = pd.DataFrame({stock: grouped_metrics_all_rf[grouping][stock][metric] for stock in grouped_metrics_all_rf[grouping].keys()})\n",
    "        comparative_df_rf.index.name = grouping\n",
    "        print(f\"\\n{'='*50}\\nComparative {metric} Across {grouping} for All Stocks - Random Forest\\n{'='*50}\")\n",
    "        display(comparative_df_rf)\n",
    "        filename = f'comparative_{metric}_across_{grouping}_rf.csv'\n",
    "        comparative_df_rf.to_csv(filename)\n",
    "        print(f\" - Comparative {metric} Across {grouping} table for Random Forest saved as '{filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ddb11f-7a92-4407-ad3f-0d806d529537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Stock: AAPL\n",
      "==================================================\n",
      " - Loaded XGBoost model for AAPL.\n",
      " - Loaded Random Forest model for AAPL.\n",
      " - Loaded LSTM model for AAPL.\n",
      " - Loaded GRU model for AAPL.\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n",
      " - XGBoost predictions generated for AAPL.\n",
      " - Random Forest predictions generated for AAPL.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      " - LSTM predictions generated for AAPL.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      " - GRU predictions generated for AAPL.\n",
      " - Meta-features for training data populated for AAPL.\n",
      " - Meta-features for testing data populated for AAPL.\n",
      " - Target variables stored for AAPL.\n",
      "\n",
      "==================================================\n",
      "Processing Stock: MSFT\n",
      "==================================================\n",
      " - Loaded XGBoost model for MSFT.\n",
      " - Loaded Random Forest model for MSFT.\n",
      " - Loaded LSTM model for MSFT.\n",
      " - Loaded GRU model for MSFT.\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n",
      " - XGBoost predictions generated for MSFT.\n",
      " - Random Forest predictions generated for MSFT.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      " - LSTM predictions generated for MSFT.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      " - GRU predictions generated for MSFT.\n",
      " - Meta-features for training data populated for MSFT.\n",
      " - Meta-features for testing data populated for MSFT.\n",
      " - Target variables stored for MSFT.\n",
      "\n",
      "==================================================\n",
      "Processing Stock: GOOGL\n",
      "==================================================\n",
      " - Loaded XGBoost model for GOOGL.\n",
      " - Loaded Random Forest model for GOOGL.\n",
      " - Loaded LSTM model for GOOGL.\n",
      " - Loaded GRU model for GOOGL.\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n",
      " - XGBoost predictions generated for GOOGL.\n",
      " - Random Forest predictions generated for GOOGL.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      " - LSTM predictions generated for GOOGL.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      " - GRU predictions generated for GOOGL.\n",
      " - Meta-features for training data populated for GOOGL.\n",
      " - Meta-features for testing data populated for GOOGL.\n",
      " - Target variables stored for GOOGL.\n",
      "\n",
      "==================================================\n",
      "Processing Stock: AMZN\n",
      "==================================================\n",
      " - Loaded XGBoost model for AMZN.\n",
      " - Loaded Random Forest model for AMZN.\n",
      " - Loaded LSTM model for AMZN.\n",
      " - Loaded GRU model for AMZN.\n",
      " - Training sequences: (1951, 60, 36), Training targets: (1951,)\n",
      " - Testing sequences: (443, 60, 36), Testing targets: (443,)\n",
      " - XGBoost predictions generated for AMZN.\n",
      " - Random Forest predictions generated for AMZN.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      " - LSTM predictions generated for AMZN.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      " - GRU predictions generated for AMZN.\n",
      " - Meta-features for training data populated for AMZN.\n",
      " - Meta-features for testing data populated for AMZN.\n",
      " - Target variables stored for AMZN.\n",
      "\n",
      "==================================================\n",
      "Meta-Features DataFrame Shapes\n",
      "==================================================\n",
      " - AAPL: meta_features_train shape: (1951, 4), meta_features_test shape: (443, 4), y_train shape: (1951,), y_test shape: (443,)\n",
      " - MSFT: meta_features_train shape: (1951, 4), meta_features_test shape: (443, 4), y_train shape: (1951,), y_test shape: (443,)\n",
      " - GOOGL: meta_features_train shape: (1951, 4), meta_features_test shape: (443, 4), y_train shape: (1951,), y_test shape: (443,)\n",
      " - AMZN: meta_features_train shape: (1951, 4), meta_features_test shape: (443, 4), y_train shape: (1951,), y_test shape: (443,)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 10A: Generating Meta-Features from Base Models\n",
    "\n",
    "# Define Paths for Models\n",
    "xgb_model_dir = '../models/xgb_models'\n",
    "rf_model_dir = '../models/random_forest_models'\n",
    "lstm_model_dir = '../models/lstm_models'\n",
    "gru_model_dir = '../models/gru_models'\n",
    "meta_model_dir = '../models/meta_model'\n",
    "os.makedirs(meta_model_dir, exist_ok=True)\n",
    "\n",
    "# Initialize Dictionaries to Store Meta-Features and Targets\n",
    "meta_features_train_dict = {}\n",
    "meta_features_test_dict = {}\n",
    "y_train_dict = {}\n",
    "y_test_dict = {}\n",
    "\n",
    "# Function to Create Sequences (Assuming it's defined in a common cell)\n",
    "def create_sequences(X, y, timesteps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(timesteps, len(X)):\n",
    "        X_seq.append(X[i-timesteps:i].values)\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Iterate Through Each Stock to Populate Meta-Features\n",
    "for stock in stocks:\n",
    "    stock_upper = stock.upper()  # Ensure stock symbol is uppercase\n",
    "    print(f\"\\n{'='*50}\\nProcessing Stock: {stock_upper}\\n{'='*50}\")\n",
    "\n",
    "    # ----- Load Base Models -----\n",
    "    missing_models = []\n",
    "    \n",
    "    # Load XGBoost Model\n",
    "    xgb_model_path = os.path.join(xgb_model_dir, f'xgb_{stock_upper}_model.json')\n",
    "    if not os.path.exists(xgb_model_path):\n",
    "        missing_models.append('XGBoost')\n",
    "    else:\n",
    "        try:\n",
    "            xgb_model = xgb.XGBRegressor()\n",
    "            xgb_model.load_model(xgb_model_path)\n",
    "            print(f\" - Loaded XGBoost model for {stock_upper}.\")\n",
    "        except Exception as e:\n",
    "            print(f\" - Error loading XGBoost model for {stock_upper}: {e}\")\n",
    "            missing_models.append('XGBoost')\n",
    "    \n",
    "    # Load Random Forest Model\n",
    "    rf_model_path = os.path.join(rf_model_dir, f'rf_{stock_upper}_model.joblib')\n",
    "    if not os.path.exists(rf_model_path):\n",
    "        missing_models.append('Random Forest')\n",
    "    else:\n",
    "        try:\n",
    "            rf_model = joblib.load(rf_model_path)\n",
    "            print(f\" - Loaded Random Forest model for {stock_upper}.\")\n",
    "        except Exception as e:\n",
    "            print(f\" - Error loading Random Forest model for {stock_upper}: {e}\")\n",
    "            missing_models.append('Random Forest')\n",
    "\n",
    "    # Load LSTM Model\n",
    "    lstm_model_path = os.path.join(lstm_model_dir, f'lstm_{stock_upper}_best.keras')\n",
    "    if not os.path.exists(lstm_model_path):\n",
    "        missing_models.append('LSTM')\n",
    "    else:\n",
    "        try:\n",
    "            lstm_model = load_model(lstm_model_path)\n",
    "            print(f\" - Loaded LSTM model for {stock_upper}.\")\n",
    "        except Exception as e:\n",
    "            print(f\" - Error loading LSTM model for {stock_upper}: {e}\")\n",
    "            missing_models.append('LSTM')\n",
    "\n",
    "    # Load GRU Model\n",
    "    gru_model_path = os.path.join(gru_model_dir, f'gru_{stock_upper}_best.keras')\n",
    "    if not os.path.exists(gru_model_path):\n",
    "        missing_models.append('GRU')\n",
    "    else:\n",
    "        try:\n",
    "            gru_model = load_model(gru_model_path)\n",
    "            print(f\" - Loaded GRU model for {stock_upper}.\")\n",
    "        except Exception as e:\n",
    "            print(f\" - Error loading GRU model for {stock_upper}: {e}\")\n",
    "            missing_models.append('GRU')\n",
    "\n",
    "    if missing_models:\n",
    "        print(f\" - Missing or failed to load models for {stock_upper}: {', '.join(missing_models)}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # ----- Retrieve Scaled Data -----\n",
    "    data = scaled_daily_data.get(stock)\n",
    "    if data is None:\n",
    "        print(f\" - No scaled data found for {stock_upper}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Check for 'test_dates'\n",
    "    if 'test_dates' not in data:\n",
    "        print(f\" - 'test_dates' not found for {stock_upper}. Skipping.\")\n",
    "        continue\n",
    "    test_dates = data['test_dates']\n",
    "\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_train_scaled = data['y_train_scaled']\n",
    "    y_test_scaled = data['y_test_scaled']\n",
    "    scaler_y = data['scaler_y']\n",
    "\n",
    "    # ----- Create Sequences for LSTM and GRU Models -----\n",
    "    TIMESTEPS = 60  # Ensure consistency\n",
    "    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, TIMESTEPS)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, TIMESTEPS)\n",
    "    \n",
    "    print(f\" - Training sequences: {X_train_seq.shape}, Training targets: {y_train_seq.shape}\")\n",
    "    print(f\" - Testing sequences: {X_test_seq.shape}, Testing targets: {y_test_seq.shape}\")\n",
    "    \n",
    "    # ----- Generate Predictions from Base Models -----\n",
    "    try:\n",
    "        # XGBoost Predictions\n",
    "        xgb_pred_train_scaled = xgb_model.predict(X_train_scaled.iloc[TIMESTEPS:])\n",
    "        xgb_pred_test_scaled = xgb_model.predict(X_test_scaled.iloc[TIMESTEPS:])\n",
    "        xgb_pred_train = scaler_y.inverse_transform(xgb_pred_train_scaled.reshape(-1, 1)).flatten()\n",
    "        xgb_pred_test = scaler_y.inverse_transform(xgb_pred_test_scaled.reshape(-1, 1)).flatten()\n",
    "        print(f\" - XGBoost predictions generated for {stock_upper}.\")\n",
    "        \n",
    "        # Random Forest Predictions\n",
    "        rf_pred_train_scaled = rf_model.predict(X_train_scaled.iloc[TIMESTEPS:])\n",
    "        rf_pred_test_scaled = rf_model.predict(X_test_scaled.iloc[TIMESTEPS:])\n",
    "        rf_pred_train = scaler_y.inverse_transform(rf_pred_train_scaled.reshape(-1, 1)).flatten()\n",
    "        rf_pred_test = scaler_y.inverse_transform(rf_pred_test_scaled.reshape(-1, 1)).flatten()\n",
    "        print(f\" - Random Forest predictions generated for {stock_upper}.\")\n",
    "        \n",
    "        # LSTM Predictions\n",
    "        lstm_pred_train_scaled = lstm_model.predict(X_train_seq).flatten()\n",
    "        lstm_pred_test_scaled = lstm_model.predict(X_test_seq).flatten()\n",
    "        lstm_pred_train = scaler_y.inverse_transform(lstm_pred_train_scaled.reshape(-1, 1)).flatten()\n",
    "        lstm_pred_test = scaler_y.inverse_transform(lstm_pred_test_scaled.reshape(-1, 1)).flatten()\n",
    "        print(f\" - LSTM predictions generated for {stock_upper}.\")\n",
    "        \n",
    "        # GRU Predictions\n",
    "        gru_pred_train_scaled = gru_model.predict(X_train_seq).flatten()\n",
    "        gru_pred_test_scaled = gru_model.predict(X_test_seq).flatten()\n",
    "        gru_pred_train = scaler_y.inverse_transform(gru_pred_train_scaled.reshape(-1, 1)).flatten()\n",
    "        gru_pred_test = scaler_y.inverse_transform(gru_pred_test_scaled.reshape(-1, 1)).flatten()\n",
    "        print(f\" - GRU predictions generated for {stock_upper}.\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error during prediction generation for {stock_upper}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ----- Align Predictions and Targets -----\n",
    "    # Determine the minimum length to ensure alignment\n",
    "    min_length_train = min(len(xgb_pred_train), len(rf_pred_train), len(lstm_pred_train), len(gru_pred_train), len(y_train_seq))\n",
    "    min_length_test = min(len(xgb_pred_test), len(rf_pred_test), len(lstm_pred_test), len(gru_pred_test), len(y_test_seq))\n",
    "    \n",
    "    # Slice predictions and targets to min_length\n",
    "    xgb_pred_train = xgb_pred_train[:min_length_train]\n",
    "    rf_pred_train = rf_pred_train[:min_length_train]\n",
    "    lstm_pred_train = lstm_pred_train[:min_length_train]\n",
    "    gru_pred_train = gru_pred_train[:min_length_train]\n",
    "    y_train = scaler_y.inverse_transform(y_train_seq[:min_length_train].reshape(-1, 1)).flatten()\n",
    "    \n",
    "    xgb_pred_test = xgb_pred_test[:min_length_test]\n",
    "    rf_pred_test = rf_pred_test[:min_length_test]\n",
    "    lstm_pred_test = lstm_pred_test[:min_length_test]\n",
    "    gru_pred_test = gru_pred_test[:min_length_test]\n",
    "    y_test = scaler_y.inverse_transform(y_test_seq[:min_length_test].reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # ----- Populate Meta-Features for Training Data -----\n",
    "    meta_features_train = pd.DataFrame({\n",
    "        'XGB_Pred': xgb_pred_train,\n",
    "        'RF_Pred': rf_pred_train,\n",
    "        'LSTM_Pred': lstm_pred_train,\n",
    "        'GRU_Pred': gru_pred_train\n",
    "    })\n",
    "    meta_features_train_dict[stock] = meta_features_train\n",
    "    print(f\" - Meta-features for training data populated for {stock_upper}.\")\n",
    "    \n",
    "    # ----- Populate Meta-Features for Test Data -----\n",
    "    meta_features_test = pd.DataFrame({\n",
    "        'XGB_Pred': xgb_pred_test,\n",
    "        'RF_Pred': rf_pred_test,\n",
    "        'LSTM_Pred': lstm_pred_test,\n",
    "        'GRU_Pred': gru_pred_test\n",
    "    })\n",
    "    meta_features_test_dict[stock] = meta_features_test\n",
    "    print(f\" - Meta-features for testing data populated for {stock_upper}.\")\n",
    "    \n",
    "    # ----- Store Target Variables -----\n",
    "    y_train_dict[stock] = y_train\n",
    "    y_test_dict[stock] = y_test\n",
    "    print(f\" - Target variables stored for {stock_upper}.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\nMeta-Features DataFrame Shapes\\n\" + \"=\"*50)\n",
    "for stock in meta_features_train_dict.keys():\n",
    "    print(f\" - {stock}: meta_features_train shape: {meta_features_train_dict[stock].shape}, meta_features_test shape: {meta_features_test_dict[stock].shape}, y_train shape: {y_train_dict[stock].shape}, y_test shape: {y_test_dict[stock].shape}\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc7b9b8-c188-4262-8c64-6fdd430e259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Meta-Models for Each Stock\n",
      "==================================================\n",
      "\n",
      "Training Meta-Model for AAPL\n",
      " - Meta-Model (Ridge Regression) trained successfully for AAPL.\n",
      " - Meta-Model saved at '../models/meta_model/stacking_meta_model_AAPL.joblib'\n",
      " - Meta-model feature names saved at '../models/meta_model/meta_feature_names_AAPL.pkl'\n",
      " - File size of saved meta-model for AAPL: 1036 bytes\n",
      " - Meta-Model loaded successfully after saving for AAPL\n",
      " - Meta-Predictions generated for AAPL.\n",
      "\n",
      "Meta-Model Evaluation Metrics for AAPL:\n",
      "    RMSE = 22.8628\n",
      "    MAE = 14.3100\n",
      "    R2 = -0.0161\n",
      "    MAPE = 6.74%\n",
      " - Time features added to the meta-model evaluation DataFrame for AAPL.\n",
      " - Meta-Model predictions saved at '../models/meta_model/meta_predictions_AAPL.csv'\n",
      " - Meta-Model performance metrics stored for AAPL.\n",
      "\n",
      "Descriptive Statistics for AAPL:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <td>443.0</td>\n",
       "      <td>187.283838</td>\n",
       "      <td>22.706633</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>172.175003</td>\n",
       "      <td>183.860001</td>\n",
       "      <td>194.965004</td>\n",
       "      <td>236.479996</td>\n",
       "      <td>0.688458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <td>443.0</td>\n",
       "      <td>173.247324</td>\n",
       "      <td>8.202596</td>\n",
       "      <td>143.090083</td>\n",
       "      <td>172.264543</td>\n",
       "      <td>176.573400</td>\n",
       "      <td>178.394041</td>\n",
       "      <td>179.893591</td>\n",
       "      <td>0.688458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean        std         min         25%         50%  \\\n",
       "Actual     443.0  187.283838  22.706633  143.000000  172.175003  183.860001   \n",
       "Predicted  443.0  173.247324   8.202596  143.090083  172.264543  176.573400   \n",
       "\n",
       "                  75%         max  Correlation  \n",
       "Actual     194.965004  236.479996     0.688458  \n",
       "Predicted  178.394041  179.893591     0.688458  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Detailed metrics saved for AAPL at '../models/meta_model/detailed_metrics_AAPL.csv'\n",
      "\n",
      "Training Meta-Model for MSFT\n",
      " - Meta-Model (Ridge Regression) trained successfully for MSFT.\n",
      " - Meta-Model saved at '../models/meta_model/stacking_meta_model_MSFT.joblib'\n",
      " - Meta-model feature names saved at '../models/meta_model/meta_feature_names_MSFT.pkl'\n",
      " - File size of saved meta-model for MSFT: 1036 bytes\n",
      " - Meta-Model loaded successfully after saving for MSFT\n",
      " - Meta-Predictions generated for MSFT.\n",
      "\n",
      "Meta-Model Evaluation Metrics for MSFT:\n",
      "    RMSE = 56.5649\n",
      "    MAE = 41.0254\n",
      "    R2 = 0.0324\n",
      "    MAPE = 9.89%\n",
      " - Time features added to the meta-model evaluation DataFrame for MSFT.\n",
      " - Meta-Model predictions saved at '../models/meta_model/meta_predictions_MSFT.csv'\n",
      " - Meta-Model performance metrics stored for MSFT.\n",
      "\n",
      "Descriptive Statistics for MSFT:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <td>443.0</td>\n",
       "      <td>366.145237</td>\n",
       "      <td>57.569260</td>\n",
       "      <td>242.710007</td>\n",
       "      <td>325.985001</td>\n",
       "      <td>374.070007</td>\n",
       "      <td>416.220001</td>\n",
       "      <td>467.559998</td>\n",
       "      <td>0.812971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <td>443.0</td>\n",
       "      <td>325.988641</td>\n",
       "      <td>25.195417</td>\n",
       "      <td>244.037868</td>\n",
       "      <td>326.062129</td>\n",
       "      <td>338.290217</td>\n",
       "      <td>339.737897</td>\n",
       "      <td>342.160162</td>\n",
       "      <td>0.812971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean        std         min         25%         50%  \\\n",
       "Actual     443.0  366.145237  57.569260  242.710007  325.985001  374.070007   \n",
       "Predicted  443.0  325.988641  25.195417  244.037868  326.062129  338.290217   \n",
       "\n",
       "                  75%         max  Correlation  \n",
       "Actual     416.220001  467.559998     0.812971  \n",
       "Predicted  339.737897  342.160162     0.812971  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Detailed metrics saved for MSFT at '../models/meta_model/detailed_metrics_MSFT.csv'\n",
      "\n",
      "Training Meta-Model for GOOGL\n",
      " - Meta-Model (Ridge Regression) trained successfully for GOOGL.\n",
      " - Meta-Model saved at '../models/meta_model/stacking_meta_model_GOOGL.joblib'\n",
      " - Meta-model feature names saved at '../models/meta_model/meta_feature_names_GOOGL.pkl'\n",
      " - File size of saved meta-model for GOOGL: 1036 bytes\n",
      " - Meta-Model loaded successfully after saving for GOOGL\n",
      " - Meta-Predictions generated for GOOGL.\n",
      "\n",
      "Meta-Model Evaluation Metrics for GOOGL:\n",
      "    RMSE = 12.9345\n",
      "    MAE = 7.3082\n",
      "    R2 = 0.7248\n",
      "    MAPE = 4.38%\n",
      " - Time features added to the meta-model evaluation DataFrame for GOOGL.\n",
      " - Meta-Model predictions saved at '../models/meta_model/meta_predictions_GOOGL.csv'\n",
      " - Meta-Model performance metrics stored for GOOGL.\n",
      "\n",
      "Descriptive Statistics for GOOGL:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <td>443.0</td>\n",
       "      <td>139.437404</td>\n",
       "      <td>24.682654</td>\n",
       "      <td>89.129997</td>\n",
       "      <td>123.584999</td>\n",
       "      <td>137.399994</td>\n",
       "      <td>161.635002</td>\n",
       "      <td>191.179993</td>\n",
       "      <td>0.92833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <td>443.0</td>\n",
       "      <td>132.529753</td>\n",
       "      <td>16.942178</td>\n",
       "      <td>89.901272</td>\n",
       "      <td>123.752378</td>\n",
       "      <td>137.472600</td>\n",
       "      <td>147.056648</td>\n",
       "      <td>148.985035</td>\n",
       "      <td>0.92833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean        std        min         25%         50%  \\\n",
       "Actual     443.0  139.437404  24.682654  89.129997  123.584999  137.399994   \n",
       "Predicted  443.0  132.529753  16.942178  89.901272  123.752378  137.472600   \n",
       "\n",
       "                  75%         max  Correlation  \n",
       "Actual     161.635002  191.179993      0.92833  \n",
       "Predicted  147.056648  148.985035      0.92833  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Detailed metrics saved for GOOGL at '../models/meta_model/detailed_metrics_GOOGL.csv'\n",
      "\n",
      "Training Meta-Model for AMZN\n",
      " - Meta-Model (Ridge Regression) trained successfully for AMZN.\n",
      " - Meta-Model saved at '../models/meta_model/stacking_meta_model_AMZN.joblib'\n",
      " - Meta-model feature names saved at '../models/meta_model/meta_feature_names_AMZN.pkl'\n",
      " - File size of saved meta-model for AMZN: 1036 bytes\n",
      " - Meta-Model loaded successfully after saving for AMZN\n",
      " - Meta-Predictions generated for AMZN.\n",
      "\n",
      "Meta-Model Evaluation Metrics for AMZN:\n",
      "    RMSE = 3.0815\n",
      "    MAE = 1.7260\n",
      "    R2 = 0.9904\n",
      "    MAPE = 1.06%\n",
      " - Time features added to the meta-model evaluation DataFrame for AMZN.\n",
      " - Meta-Model predictions saved at '../models/meta_model/meta_predictions_AMZN.csv'\n",
      " - Meta-Model performance metrics stored for AMZN.\n",
      "\n",
      "Descriptive Statistics for AMZN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <td>443.0</td>\n",
       "      <td>149.469413</td>\n",
       "      <td>31.541288</td>\n",
       "      <td>90.730003</td>\n",
       "      <td>127.115002</td>\n",
       "      <td>147.419998</td>\n",
       "      <td>179.770004</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.996619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <td>443.0</td>\n",
       "      <td>148.343762</td>\n",
       "      <td>30.197046</td>\n",
       "      <td>91.127857</td>\n",
       "      <td>127.505768</td>\n",
       "      <td>146.792020</td>\n",
       "      <td>179.182356</td>\n",
       "      <td>185.401356</td>\n",
       "      <td>0.996619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean        std        min         25%         50%  \\\n",
       "Actual     443.0  149.469413  31.541288  90.730003  127.115002  147.419998   \n",
       "Predicted  443.0  148.343762  30.197046  91.127857  127.505768  146.792020   \n",
       "\n",
       "                  75%         max  Correlation  \n",
       "Actual     179.770004  200.000000     0.996619  \n",
       "Predicted  179.182356  185.401356     0.996619  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Detailed metrics saved for AMZN at '../models/meta_model/detailed_metrics_AMZN.csv'\n",
      "\n",
      "==================================================\n",
      "Overall Evaluation Metrics for All Stocks - Meta Stacked Model\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>22.8628</td>\n",
       "      <td>14.3100</td>\n",
       "      <td>-0.0161</td>\n",
       "      <td>6.7429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>56.5649</td>\n",
       "      <td>41.0254</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>9.8878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>12.9345</td>\n",
       "      <td>7.3082</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>4.3816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>3.0815</td>\n",
       "      <td>1.7260</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>1.0578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RMSE      MAE      R2    MAPE\n",
       "AAPL   22.8628  14.3100 -0.0161  6.7429\n",
       "MSFT   56.5649  41.0254  0.0324  9.8878\n",
       "GOOGL  12.9345   7.3082  0.7248  4.3816\n",
       "AMZN    3.0815   1.7260  0.9904  1.0578"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Overall Evaluation Metrics table for Meta Stacked Model saved as 'overall_evaluation_metrics_meta_stacked.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10B: Training and Evaluating the Stacking Meta-Model\n",
    "\n",
    "# Initialize a dictionary to store meta-model performance\n",
    "meta_model_per_stock = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\nTraining Meta-Models for Each Stock\\n\" + \"=\"*50)\n",
    "\n",
    "for stock in meta_features_train_dict.keys():\n",
    "    print(f\"\\nTraining Meta-Model for {stock}\")\n",
    "    \n",
    "    meta_features_train = meta_features_train_dict[stock]\n",
    "    meta_features_test = meta_features_test_dict[stock]\n",
    "    y_train = y_train_dict[stock]\n",
    "    y_test = y_test_dict[stock]\n",
    "    \n",
    "    # Check if meta_features_train and y_train are non-empty\n",
    "    if meta_features_train.empty or len(y_train) == 0:\n",
    "        print(f\" - Empty meta-features or target variables for {stock}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # ----- Train Meta-Model (Ridge Regression with Cross-Validation) -----\n",
    "    try:\n",
    "        meta_model = RidgeCV()\n",
    "        meta_model.fit(meta_features_train, y_train)\n",
    "        print(f\" - Meta-Model (Ridge Regression) trained successfully for {stock}.\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error training Meta-Model for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ----- Save Meta-Model -----\n",
    "    meta_model_path = os.path.join(meta_model_dir, f'stacking_meta_model_{stock.upper()}.joblib')\n",
    "    try:\n",
    "        joblib.dump(meta_model, meta_model_path)\n",
    "        print(f\" - Meta-Model saved at '{meta_model_path}'\")\n",
    "    \n",
    "        # Save the feature names used during training\n",
    "        meta_feature_names = meta_features_train.columns.tolist()\n",
    "        feature_names_path = os.path.join(meta_model_dir, f'meta_feature_names_{stock.upper()}.pkl')\n",
    "        with open(feature_names_path, 'wb') as f:\n",
    "            pickle.dump(meta_feature_names, f)\n",
    "        print(f\" - Meta-model feature names saved at '{feature_names_path}'\")\n",
    "    \n",
    "        # Additional logging for file size and integrity check\n",
    "        file_size = os.path.getsize(meta_model_path)\n",
    "        print(f\" - File size of saved meta-model for {stock}: {file_size} bytes\")\n",
    "    \n",
    "        # Verify by loading the saved meta-model immediately\n",
    "        loaded_meta_model = joblib.load(meta_model_path)\n",
    "        print(f\" - Meta-Model loaded successfully after saving for {stock}\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error saving or loading Meta-Model for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ----- Generate Meta-Predictions on Test Data -----\n",
    "    try:\n",
    "        # Ensure meta_features_test has the same columns in the same order\n",
    "        meta_features_test = meta_features_test[meta_feature_names]\n",
    "    \n",
    "        meta_pred_test = meta_model.predict(meta_features_test)\n",
    "        print(f\" - Meta-Predictions generated for {stock}.\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error generating Meta-Predictions for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ----- Evaluate Meta-Model -----\n",
    "    try:\n",
    "        rmse_meta = np.sqrt(mean_squared_error(y_test, meta_pred_test))\n",
    "        mae_meta = mean_absolute_error(y_test, meta_pred_test)\n",
    "        r2_meta = r2_score(y_test, meta_pred_test)\n",
    "        mape_meta = mean_absolute_percentage_error(y_test, meta_pred_test) * 100\n",
    "        \n",
    "        meta_model_per_stock[stock] = {\n",
    "            'RMSE': rmse_meta,\n",
    "            'MAE': mae_meta,\n",
    "            'R2': r2_meta,\n",
    "            'MAPE': mape_meta\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nMeta-Model Evaluation Metrics for {stock}:\")\n",
    "        print(f\"    RMSE = {rmse_meta:.4f}\")\n",
    "        print(f\"    MAE = {mae_meta:.4f}\")\n",
    "        print(f\"    R2 = {r2_meta:.4f}\")\n",
    "        print(f\"    MAPE = {mape_meta:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error evaluating Meta-Model for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ----- Create Evaluation DataFrame for Meta-Model -----\n",
    "    try:\n",
    "        # Align test_dates with predictions\n",
    "        adjusted_test_dates = pd.date_range(start='2020-01-01', periods=len(meta_pred_test), freq='D')\n",
    "        \n",
    "        eval_df_meta = pd.DataFrame({\n",
    "            'Date': adjusted_test_dates,\n",
    "            'Actual': y_test,\n",
    "            'Meta_Predicted': meta_pred_test\n",
    "        })\n",
    "        \n",
    "        # ----- Add Time Features -----\n",
    "        eval_df_meta['Month'] = eval_df_meta['Date'].dt.month\n",
    "        eval_df_meta['Quarter'] = eval_df_meta['Date'].dt.quarter\n",
    "        eval_df_meta['Season'] = eval_df_meta['Month'].apply(\n",
    "            lambda month: 'Winter' if month in [12, 1, 2] else\n",
    "                          'Spring' if month in [3, 4, 5] else\n",
    "                          'Summer' if month in [6, 7, 8] else\n",
    "                          'Autumn'\n",
    "        )\n",
    "        print(f\" - Time features added to the meta-model evaluation DataFrame for {stock}.\")\n",
    "        \n",
    "        # ----- Save Meta-Model Predictions -----\n",
    "        meta_pred_save_path = os.path.join(meta_model_dir, f'meta_predictions_{stock.upper()}.csv')\n",
    "        eval_df_meta.to_csv(meta_pred_save_path, index=False)\n",
    "        print(f\" - Meta-Model predictions saved at '{meta_pred_save_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error saving Meta-Model predictions for {stock}: {e}\")\n",
    "    \n",
    "    # ----- Store Meta-Model Performance -----\n",
    "    print(f\" - Meta-Model performance metrics stored for {stock}.\")\n",
    "    \n",
    "    # ----- Detailed Descriptive Statistics -----\n",
    "    try:\n",
    "        df = pd.DataFrame({\n",
    "            'Actual': y_test,\n",
    "            'Predicted': meta_pred_test\n",
    "        })\n",
    "        descriptive_stats = df.describe().T\n",
    "        correlation = df.corr().loc['Actual', 'Predicted']\n",
    "        descriptive_stats['Correlation'] = correlation\n",
    "        print(f\"\\nDescriptive Statistics for {stock}:\")\n",
    "        display(descriptive_stats)\n",
    "        \n",
    "        # Save Descriptive Statistics\n",
    "        detailed_metrics_path = os.path.join(meta_model_dir, f'detailed_metrics_{stock.upper()}.csv')\n",
    "        descriptive_stats.to_csv(detailed_metrics_path)\n",
    "        print(f\" - Detailed metrics saved for {stock} at '{detailed_metrics_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error generating detailed statistics for {stock}: {e}\")\n",
    "    \n",
    "# ----- Create Overall Metrics Table -----\n",
    "overall_metrics_meta_df = pd.DataFrame(meta_model_per_stock).T\n",
    "overall_metrics_meta_df = overall_metrics_meta_df[['RMSE', 'MAE', 'R2', 'MAPE']].round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Overall Evaluation Metrics for All Stocks - Meta Stacked Model\")\n",
    "print(\"=\"*50)\n",
    "display(overall_metrics_meta_df)\n",
    "overall_metrics_meta_df.to_csv('overall_evaluation_metrics_meta_stacked.csv')\n",
    "print(\"\\n - Overall Evaluation Metrics table for Meta Stacked Model saved as 'overall_evaluation_metrics_meta_stacked.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb1493d1-a997-4702-9859-9b3b9a9bbb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Define Essential Functions for all models\n",
    "\n",
    "# Function to load all necessary models and scalers for a given stock\n",
    "def load_models(stock):\n",
    "    try:\n",
    "        # Define model directories\n",
    "        xgb_model_dir = '../models/xgb_models'\n",
    "        rf_model_dir = '../models/random_forest_models'\n",
    "        lstm_model_dir = '../models/lstm_models'\n",
    "        gru_model_dir = '../models/gru_models'\n",
    "        meta_model_dir = '../models/meta_model'\n",
    "        scalers_dir = '../models/scalers'\n",
    "        \n",
    "        # Load XGBoost Model\n",
    "        xgb_model_path = os.path.join(xgb_model_dir, f'xgb_{stock}_model.json')\n",
    "        xgb_model = xgb.XGBRegressor()\n",
    "        xgb_model.load_model(xgb_model_path)\n",
    "        print(f\" - Loaded XGBoost model from '{xgb_model_path}'\")\n",
    "        \n",
    "        # Load Random Forest Model\n",
    "        rf_model_path = os.path.join(rf_model_dir, f'rf_{stock}_model.pkl')\n",
    "        rf_model = joblib.load(rf_model_path)\n",
    "        print(f\" - Loaded Random Forest model from '{rf_model_path}'\")\n",
    "        \n",
    "        # Load LSTM Model\n",
    "        lstm_model_path = os.path.join(lstm_model_dir, f'lstm_{stock}_best.keras')\n",
    "        lstm_model = load_model(lstm_model_path)\n",
    "        print(f\" - Loaded LSTM model from '{lstm_model_path}'\")\n",
    "        \n",
    "        # Load GRU Model\n",
    "        gru_model_path = os.path.join(gru_model_dir, f'gru_{stock}_best.keras')\n",
    "        gru_model = load_model(gru_model_path)\n",
    "        print(f\" - Loaded GRU model from '{gru_model_path}'\")\n",
    "        \n",
    "        # Load Meta-Model\n",
    "        meta_model_path = os.path.join(meta_model_dir, f'stacking_meta_model_{stock}.pkl')\n",
    "        meta_model = joblib.load(meta_model_path)\n",
    "        print(f\" - Loaded Meta-Model from '{meta_model_path}'\")\n",
    "        \n",
    "        # Load Scalers\n",
    "        scaler_X_path = os.path.join(scalers_dir, f'minmax_scaler_X_{stock}.joblib')\n",
    "        scaler_y_path = os.path.join(scalers_dir, f'minmax_scaler_y_{stock}.joblib')\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "        print(f\" - Loaded Scalers from '{scaler_X_path}' and '{scaler_y_path}'\")\n",
    "        \n",
    "        return xgb_model, rf_model, lstm_model, gru_model, meta_model, scaler_X, scaler_y\n",
    "    except Exception as e:\n",
    "        print(f\" - Error loading models or scalers for {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate features for the next day forecast\n",
    "def generate_next_day_features(current_data_unscaled, scaler_X, timesteps=60):\n",
    "    if len(current_data_unscaled) < timesteps:\n",
    "        raise ValueError(\"Insufficient data to generate features.\")\n",
    "    \n",
    "    # Extract the most recent 'timesteps' worth of data\n",
    "    latest_data = current_data_unscaled.tail(timesteps).copy()\n",
    "\n",
    "    if 'Close' not in latest_data.columns:\n",
    "        raise KeyError(\"'Close' column is missing in current_data_unscaled.\")\n",
    "\n",
    "    # Drop 'Close' and 'Date' columns to get the feature columns\n",
    "    if 'Date' in latest_data.columns:\n",
    "        features_for_models = latest_data.drop(columns=['Close', 'Date'])\n",
    "    else:\n",
    "        features_for_models = latest_data.drop(columns=['Close'])\n",
    "\n",
    "    # Ensure features are in the same order as during training\n",
    "    expected_features = scaler_X.feature_names_in_\n",
    "    \n",
    "    # Check if there are any missing features compared to what was used during training\n",
    "    missing_features = set(expected_features) - set(features_for_models.columns)\n",
    "    if missing_features:\n",
    "        raise KeyError(f\"Missing required columns: {missing_features}\")\n",
    "    \n",
    "    # Arrange features in the expected order\n",
    "    features_for_models = features_for_models[expected_features]\n",
    "    \n",
    "    # 1. Scale features for XGBoost and Random Forest (single row for last day)\n",
    "    xgb_rf_features_scaled = scaler_X.transform(features_for_models.iloc[-1:].copy())  # Last row\n",
    "    \n",
    "    # 2. Scale features for LSTM and GRU (entire sequence of 'timesteps')\n",
    "    lstm_gru_features_scaled = scaler_X.transform(features_for_models).reshape(1, timesteps, -1)  # Sequence of 60 days\n",
    "    \n",
    "    # Latest features (last row) for future updates (e.g., updating 'Close' price)\n",
    "    latest_features = features_for_models.iloc[-1].copy()\n",
    "\n",
    "    # Return both single-row and sequence features\n",
    "    return xgb_rf_features_scaled, lstm_gru_features_scaled, latest_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16ae03e0-1934-44d3-b2ca-19136e0116ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Stock: AAPL\n",
      "==================================================\n",
      " - Loaded XGBoost model from '../models/xgb_models/xgb_AAPL_model.json'\n",
      " - Error loading models or scalers for AAPL: [Errno 2] No such file or directory: '../models/random_forest_models/rf_AAPL_model.pkl'\n",
      " - Skipping stock 'AAPL' due to model loading issues.\n",
      "\n",
      "==================================================\n",
      "Processing Stock: MSFT\n",
      "==================================================\n",
      " - Loaded XGBoost model from '../models/xgb_models/xgb_MSFT_model.json'\n",
      " - Error loading models or scalers for MSFT: [Errno 2] No such file or directory: '../models/random_forest_models/rf_MSFT_model.pkl'\n",
      " - Skipping stock 'MSFT' due to model loading issues.\n",
      "\n",
      "==================================================\n",
      "Processing Stock: GOOGL\n",
      "==================================================\n",
      " - Loaded XGBoost model from '../models/xgb_models/xgb_GOOGL_model.json'\n",
      " - Error loading models or scalers for GOOGL: [Errno 2] No such file or directory: '../models/random_forest_models/rf_GOOGL_model.pkl'\n",
      " - Skipping stock 'GOOGL' due to model loading issues.\n",
      "\n",
      "==================================================\n",
      "Processing Stock: AMZN\n",
      "==================================================\n",
      " - Loaded XGBoost model from '../models/xgb_models/xgb_AMZN_model.json'\n",
      " - Error loading models or scalers for AMZN: [Errno 2] No such file or directory: '../models/random_forest_models/rf_AMZN_model.pkl'\n",
      " - Skipping stock 'AMZN' due to model loading issues.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Initialize and Prepare Data\n",
    "\n",
    "# Define Paths\n",
    "raw_data_dir = '../data/stock_data'\n",
    "forecast_save_dir = '../models/future_forecasts'\n",
    "os.makedirs(forecast_save_dir, exist_ok=True)\n",
    "\n",
    "# Initialize a dictionary to store models and scaled data for each stock\n",
    "models_per_stock = {}\n",
    "timesteps = 60\n",
    "\n",
    "for stock in stocks:\n",
    "    print(f\"\\n{'='*50}\\nProcessing Stock: {stock}\\n{'='*50}\")\n",
    "    \n",
    "    # Load models\n",
    "    models = load_models(stock)\n",
    "    if models is None:\n",
    "        print(f\" - Skipping stock '{stock}' due to model loading issues.\")\n",
    "        continue\n",
    "    xgb_model, rf_model, lstm_model, gru_model, meta_model, scaler_X, scaler_y = models\n",
    "    \n",
    "    # Load raw data\n",
    "    raw_csv_path = os.path.join(raw_data_dir, f\"{stock}_daily.csv\")\n",
    "    if not os.path.exists(raw_csv_path):\n",
    "        print(f\" - Raw data CSV not found at '{raw_csv_path}'. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(raw_csv_path)\n",
    "        print(f\" - Loaded raw data from '{raw_csv_path}'. Shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error reading CSV for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Ensure 'Date' column is present\n",
    "    if 'Date' not in df.columns:\n",
    "        print(f\" - 'Date' column missing in '{raw_csv_path}'. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert 'Date' to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    if df['Date'].isnull().any():\n",
    "        print(f\" - Some 'Date' entries could not be converted to datetime for {stock}. Dropping these rows.\")\n",
    "        df.dropna(subset=['Date'], inplace=True)\n",
    "    \n",
    "    # Sort by Date\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add Enhanced 'Close' Price-Based Features\n",
    "    try:\n",
    "        df_fe = add_close_price_features(df)\n",
    "        print(f\" - Applied enhanced 'Close' price-based feature engineering. Shape: {df_fe.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error during feature engineering for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Keep only necessary recent data\n",
    "    current_data_unscaled = df_fe.tail(timesteps).copy()\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_cols = [col for col in current_data_unscaled.columns if col not in ['Date', 'Close']]\n",
    "    X_current = current_data_unscaled[feature_cols].copy()\n",
    "    \n",
    "    # Drop 'Date' column if present\n",
    "    if 'Date' in X_current.columns:\n",
    "        X_current = X_current.drop(columns=['Date'])\n",
    "        print(\" - Dropped 'Date' column from features.\")\n",
    "    \n",
    "    # Ensure features are in the same order as during training\n",
    "    expected_features = scaler_X.feature_names_in_\n",
    "    \n",
    "    # Identify missing features\n",
    "    missing_features = set(expected_features) - set(X_current.columns)\n",
    "    if missing_features:\n",
    "        print(f\" - Missing Features for {stock}: {missing_features}\")\n",
    "        # Add missing features with default values (e.g., 0)\n",
    "        for feature in missing_features:\n",
    "            X_current[feature] = 0  # Alternatively, use df_fe[feature].iloc[-1] or another strategy\n",
    "        print(f\" - Added missing features with default values for {stock}.\")\n",
    "    \n",
    "    # Reorder columns to match expected_features\n",
    "    X_current = X_current[expected_features]\n",
    "    \n",
    "    # Scale features and target\n",
    "    try:\n",
    "        X_current_scaled = pd.DataFrame(scaler_X.transform(X_current), columns=X_current.columns)\n",
    "        current_data_scaled = X_current_scaled.copy()\n",
    "        current_data_scaled['Close'] = scaler_y.transform(current_data_unscaled['Close'].values.reshape(-1, 1)).flatten()\n",
    "        current_data_scaled['Date'] = current_data_unscaled['Date'].values\n",
    "        print(f\" - Scaled current data for {stock}\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Error scaling data for {stock}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Store prepared data in models_per_stock\n",
    "    models_per_stock[stock] = {\n",
    "        'models': models,\n",
    "        'current_data_scaled': current_data_scaled,\n",
    "        'current_data_unscaled': current_data_unscaled,\n",
    "        'scaler_y': scaler_y,\n",
    "    }\n",
    "    \n",
    "    print(f\" - Current data for {stock} loaded and prepared. Total samples: {len(current_data_scaled)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b12903-ae4d-45c1-8e9f-ed3652e8a86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 13: Forecasting Future Prices\n",
    "\n",
    "def inverse_scale_prediction(scaler_y, prediction_scaled):\n",
    "    return scaler_y.inverse_transform([[prediction_scaled]])[0][0]\n",
    "\n",
    "# Define directories\n",
    "forecast_save_dir = '../models/future_forecasts'\n",
    "os.makedirs(forecast_save_dir, exist_ok=True)\n",
    "\n",
    "# Define forecast days\n",
    "forecast_days = 30\n",
    "\n",
    "# Initialize a dictionary to store forecast results\n",
    "forecast_results = {stock: [] for stock in models_per_stock.keys()}\n",
    "\n",
    "# Start forecasting\n",
    "for stock in models_per_stock.keys():\n",
    "    print(f\"\\nStarting Forecasting for {stock}\")\n",
    "    try:\n",
    "        models = models_per_stock[stock]['models']\n",
    "        current_data_scaled = models_per_stock[stock]['current_data_scaled']\n",
    "        current_data_unscaled = models_per_stock[stock]['current_data_unscaled']\n",
    "        scaler_X = models_per_stock[stock]['models'][5]  # scaler_X\n",
    "        scaler_y = models_per_stock[stock]['models'][6]  # scaler_y\n",
    "\n",
    "        # Corrected model unpacking\n",
    "        xgb_model, rf_model, lstm_model, gru_model, meta_model, scaler_X, scaler_y = models\n",
    "\n",
    "        # Create a copy of current_data_unscaled to update with predictions\n",
    "        updated_unscaled = current_data_unscaled.copy()\n",
    "\n",
    "        for day in range(1, forecast_days + 1):\n",
    "            try:\n",
    "                # Determine the timesteps for this iteration\n",
    "                timesteps = min(60, len(updated_unscaled))\n",
    "\n",
    "                # Generate features for XGBoost and Random Forest\n",
    "                xgb_rf_features_scaled, lstm_gru_features_scaled, latest_features = generate_next_day_features(\n",
    "                    updated_unscaled,\n",
    "                    scaler_X,\n",
    "                    timesteps=timesteps  # Use the current timesteps\n",
    "                )\n",
    "\n",
    "                # Ensure lstm_gru_features_scaled has the correct shape for LSTM/GRU\n",
    "                # Padding sequences if necessary\n",
    "                if lstm_gru_features_scaled.shape[1] < 60:\n",
    "                    padding_length = 60 - lstm_gru_features_scaled.shape[1]\n",
    "                    padding = np.zeros((lstm_gru_features_scaled.shape[0], padding_length, lstm_gru_features_scaled.shape[2]))\n",
    "                    lstm_gru_features_scaled = np.concatenate((padding, lstm_gru_features_scaled), axis=1)\n",
    "\n",
    "                # Make predictions with base models\n",
    "                # Ensure feature names are retained as pandas DataFrame\n",
    "                xgb_rf_features_scaled_df = pd.DataFrame(xgb_rf_features_scaled, columns=scaler_X.feature_names_in_)\n",
    "\n",
    "                xgb_pred_scaled = xgb_model.predict(xgb_rf_features_scaled_df)[0]\n",
    "                rf_pred_scaled = rf_model.predict(xgb_rf_features_scaled_df)[0]\n",
    "\n",
    "                # Flatten LSTM and GRU predictions to single values\n",
    "                lstm_pred_scaled = lstm_model.predict(lstm_gru_features_scaled).flatten()[0]  # Ensure it's a single value\n",
    "                gru_pred_scaled = gru_model.predict(lstm_gru_features_scaled).flatten()[0]    # Ensure it's a single value\n",
    "\n",
    "                # Debug: Print scaled predictions\n",
    "                print(f\" - Day {day}:\")\n",
    "                print(f\"   XGBoost_scaled = {xgb_pred_scaled}\")\n",
    "                print(f\"   RF_scaled      = {rf_pred_scaled}\")\n",
    "                print(f\"   LSTM_scaled    = {lstm_pred_scaled}\")\n",
    "                print(f\"   GRU_scaled     = {gru_pred_scaled}\")\n",
    "\n",
    "                # Meta-model prediction\n",
    "                meta_features = pd.DataFrame({\n",
    "                    'XGB_Pred': [xgb_pred_scaled],\n",
    "                    'RF_Pred': [rf_pred_scaled],\n",
    "                    'LSTM_Pred': [lstm_pred_scaled],\n",
    "                    'GRU_Pred': [gru_pred_scaled]\n",
    "                })\n",
    "\n",
    "                meta_pred_scaled = meta_model.predict(meta_features)[0]\n",
    "\n",
    "                # Debug: Print scaled meta-prediction\n",
    "                print(f\"   Meta-model_scaled_prediction = {meta_pred_scaled}\")\n",
    "\n",
    "                # Inversely scale the meta-prediction\n",
    "                meta_pred = inverse_scale_prediction(scaler_y, meta_pred_scaled)\n",
    "\n",
    "                # Debug: Print inversely scaled prediction\n",
    "                print(f\"   Meta-model_prediction (original scale) = {meta_pred}\")\n",
    "\n",
    "                # Validation: Ensure predicted 'Close' price is realistic\n",
    "                # Define realistic bounds based on previous 'Close' price\n",
    "                last_close_price = updated_unscaled['Close'].iloc[-1]\n",
    "                min_price = 0.5 * last_close_price\n",
    "                max_price = 1.5 * last_close_price\n",
    "                if meta_pred <= 0 or np.isnan(meta_pred):\n",
    "                    print(f\"   Warning: Predicted 'Close' is non-positive or NaN ({meta_pred}). Adjusting to previous 'Close' price.\")\n",
    "                    meta_pred = last_close_price\n",
    "                else:\n",
    "                    meta_pred = max(min(meta_pred, max_price), min_price)\n",
    "\n",
    "                # Append the prediction\n",
    "                forecast_results[stock].append(meta_pred)\n",
    "\n",
    "                # Update the unscaled data with the new prediction\n",
    "                # Assuming 'Close' is the target variable\n",
    "                new_row = latest_features.copy()\n",
    "                new_row['Close'] = meta_pred\n",
    "                new_row['Date'] = updated_unscaled['Date'].max() + BDay(1)  # Increment date by 1 business day\n",
    "\n",
    "                # Debug: Print the new row before feature engineering\n",
    "                print(f\"   New row before feature engineering:\\n{new_row}\")\n",
    "\n",
    "                # Convert new_row to DataFrame\n",
    "                new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "                # Append the new row to updated_unscaled using pd.concat()\n",
    "                updated_unscaled = pd.concat([updated_unscaled, new_row_df], ignore_index=True)\n",
    "\n",
    "                # Recalculate any derived features based on the new 'Close' price\n",
    "                updated_unscaled = add_close_price_features(updated_unscaled)\n",
    "\n",
    "                # Handle NaN values if any\n",
    "                updated_unscaled.ffill(inplace=True)\n",
    "                updated_unscaled.bfill(inplace=True)\n",
    "                updated_unscaled.fillna(0, inplace=True)\n",
    "\n",
    "                # Only trim if necessary\n",
    "                if len(updated_unscaled) > 60:\n",
    "                    updated_unscaled = updated_unscaled.tail(60).reset_index(drop=True)\n",
    "\n",
    "                # Debug: Print the last few rows of updated_unscaled to verify updates\n",
    "                print(f\"   Updated 'Close' prices after Day {day}:\")\n",
    "                print(updated_unscaled['Close'].tail(5).values)\n",
    "                print(f\"   Length of updated_unscaled after Day {day}: {len(updated_unscaled)}\")\n",
    "                print(f\"   Number of NaNs after feature engineering: {updated_unscaled.isna().sum().sum()}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" - Error at Day {day}: {e}\")\n",
    "                break  # Exit the loop if an error occurs\n",
    "\n",
    "        # Verify the number of predictions\n",
    "        num_predictions = len(forecast_results[stock])\n",
    "        print(f\"{stock}: Number of predictions = {num_predictions}, Expected = {forecast_days}\")\n",
    "\n",
    "        # Truncate excess predictions if any\n",
    "        if num_predictions > forecast_days:\n",
    "            print(f\"{stock}: Truncating {num_predictions - forecast_days} excess predictions.\")\n",
    "            forecast_results[stock] = forecast_results[stock][:forecast_days]\n",
    "        elif num_predictions < forecast_days:\n",
    "            print(f\"{stock}: Missing {forecast_days - num_predictions} predictions.\")\n",
    "            # Optionally, handle missing predictions\n",
    "            # For now, we'll skip saving forecasts for this stock\n",
    "            continue\n",
    "\n",
    "        # Create Forecast DataFrame\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'Day': range(1, forecast_days + 1),\n",
    "            f'{stock}_Predicted': forecast_results[stock]\n",
    "        })\n",
    "\n",
    "        # Save Forecast\n",
    "        forecast_save_path = os.path.join(forecast_save_dir, f'future_forecasts_{stock}.csv')\n",
    "        forecast_df.to_csv(forecast_save_path, index=False)\n",
    "        print(f\" - Forecast saved at '{forecast_save_path}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" - Error forecasting for {stock}: {e}\")\n",
    "\n",
    "# Display a sample of forecast_results\n",
    "for stock in models_per_stock.keys():\n",
    "    preds = forecast_results.get(stock, [])\n",
    "    if preds:\n",
    "        print(f\"\\nSample Predictions for {stock}: {preds[:5]} ...\")\n",
    "    else:\n",
    "        print(f\"\\nNo predictions available for {stock}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8825e712-a801-4c36-9688-01848a88f671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 14: Forecasting Future Prices\n",
    "\n",
    "def inverse_scale_prediction(scaler_y, prediction_scaled):\n",
    "    return scaler_y.inverse_transform([[prediction_scaled]])[0][0]\n",
    "\n",
    "# Define directories\n",
    "forecast_save_dir = '../models/future_forecasts'\n",
    "os.makedirs(forecast_save_dir, exist_ok=True)\n",
    "\n",
    "# Define forecast days\n",
    "forecast_days = 30\n",
    "\n",
    "# Initialize a dictionary to store forecast results\n",
    "forecast_results = {stock: [] for stock in models_per_stock.keys()}\n",
    "\n",
    "# Start forecasting\n",
    "for stock in models_per_stock.keys():\n",
    "    print(f\"\\nStarting Forecasting for {stock}\")\n",
    "    try:\n",
    "        models = models_per_stock[stock]['models']\n",
    "        current_data_scaled = models_per_stock[stock]['current_data_scaled']\n",
    "        current_data_unscaled = models_per_stock[stock]['current_data_unscaled']\n",
    "        scaler_X = models_per_stock[stock]['models'][5]  # scaler_X\n",
    "        scaler_y = models_per_stock[stock]['models'][6]  # scaler_y\n",
    "\n",
    "        # Corrected model unpacking\n",
    "        xgb_model, rf_model, lstm_model, gru_model, meta_model, scaler_X, scaler_y = models\n",
    "\n",
    "        # Create a copy of current_data_unscaled to update with predictions\n",
    "        updated_unscaled = current_data_unscaled.copy()\n",
    "\n",
    "        for day in range(1, forecast_days + 1):\n",
    "            try:\n",
    "                # Determine the timesteps for this iteration\n",
    "                timesteps = min(60, len(updated_unscaled))\n",
    "\n",
    "                # Generate features for XGBoost and Random Forest\n",
    "                xgb_rf_features_scaled, lstm_gru_features_scaled, latest_features = generate_next_day_features(\n",
    "                    updated_unscaled,\n",
    "                    scaler_X,\n",
    "                    timesteps=timesteps  # Use the current timesteps\n",
    "                )\n",
    "\n",
    "                # Ensure lstm_gru_features_scaled has the correct shape for LSTM/GRU\n",
    "                # Padding sequences if necessary\n",
    "                if lstm_gru_features_scaled.shape[1] < 60:\n",
    "                    padding_length = 60 - lstm_gru_features_scaled.shape[1]\n",
    "                    padding = np.zeros((lstm_gru_features_scaled.shape[0], padding_length, lstm_gru_features_scaled.shape[2]))\n",
    "                    lstm_gru_features_scaled = np.concatenate((padding, lstm_gru_features_scaled), axis=1)\n",
    "\n",
    "                # Make predictions with base models\n",
    "                xgb_pred_scaled = xgb_model.predict(xgb_rf_features_scaled)[0]\n",
    "                rf_pred_scaled = rf_model.predict(xgb_rf_features_scaled)[0]\n",
    "                lstm_pred_scaled = lstm_model.predict(lstm_gru_features_scaled)[0][0]\n",
    "                gru_pred_scaled = gru_model.predict(lstm_gru_features_scaled)[0][0]\n",
    "\n",
    "                # Debug: Print scaled predictions\n",
    "                print(f\" - Day {day}:\")\n",
    "                print(f\"   XGBoost_scaled = {xgb_pred_scaled}\")\n",
    "                print(f\"   RF_scaled      = {rf_pred_scaled}\")\n",
    "                print(f\"   LSTM_scaled    = {lstm_pred_scaled}\")\n",
    "                print(f\"   GRU_scaled     = {gru_pred_scaled}\")\n",
    "\n",
    "                # Meta-model prediction\n",
    "                meta_features = np.array([xgb_pred_scaled, rf_pred_scaled, lstm_pred_scaled, gru_pred_scaled]).reshape(1, -1)\n",
    "                meta_pred_scaled = meta_model.predict(meta_features)[0]\n",
    "\n",
    "                # Debug: Print scaled meta-prediction\n",
    "                print(f\"   Meta-model_scaled_prediction = {meta_pred_scaled}\")\n",
    "\n",
    "                # Inversely scale the meta-prediction\n",
    "                meta_pred = inverse_scale_prediction(scaler_y, meta_pred_scaled)\n",
    "\n",
    "                # Debug: Print inversely scaled prediction\n",
    "                print(f\"   Meta-model_prediction (original scale) = {meta_pred}\")\n",
    "\n",
    "                # Validation: Ensure predicted 'Close' price is realistic\n",
    "                # Define realistic bounds based on previous 'Close' price\n",
    "                last_close_price = updated_unscaled['Close'].iloc[-1]\n",
    "                min_price = 0.5 * last_close_price\n",
    "                max_price = 1.5 * last_close_price\n",
    "                if meta_pred <= 0 or np.isnan(meta_pred):\n",
    "                    print(f\"   Warning: Predicted 'Close' is non-positive or NaN ({meta_pred}). Adjusting to previous 'Close' price.\")\n",
    "                    meta_pred = last_close_price\n",
    "                else:\n",
    "                    meta_pred = max(min(meta_pred, max_price), min_price)\n",
    "\n",
    "                # Append the prediction\n",
    "                forecast_results[stock].append(meta_pred)\n",
    "\n",
    "                # Update the unscaled data with the new prediction\n",
    "                # Assuming 'Close' is the target variable\n",
    "                new_row = latest_features.copy()\n",
    "                new_row['Close'] = meta_pred\n",
    "                new_row['Date'] = updated_unscaled['Date'].max() + BDay(1)  # Increment date by 1 business day\n",
    "\n",
    "                # Debug: Print the new row before feature engineering\n",
    "                print(f\"   New row before feature engineering:\\n{new_row}\")\n",
    "\n",
    "                # Convert new_row to DataFrame\n",
    "                new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "                # Append the new row to updated_unscaled using pd.concat()\n",
    "                updated_unscaled = pd.concat([updated_unscaled, new_row_df], ignore_index=True)\n",
    "\n",
    "                # Recalculate any derived features based on the new 'Close' price\n",
    "                updated_unscaled = add_close_price_features(updated_unscaled)\n",
    "\n",
    "                # Handle NaN values if any\n",
    "                updated_unscaled.ffill(inplace=True)\n",
    "                updated_unscaled.bfill(inplace=True)\n",
    "                updated_unscaled.fillna(0, inplace=True)\n",
    "\n",
    "                # Only trim if necessary\n",
    "                if len(updated_unscaled) > 60:\n",
    "                    updated_unscaled = updated_unscaled.tail(60).reset_index(drop=True)\n",
    "\n",
    "                # Debug: Print the last few rows of updated_unscaled to verify updates\n",
    "                print(f\"   Updated 'Close' prices after Day {day}:\")\n",
    "                print(updated_unscaled['Close'].tail(5).values)\n",
    "                print(f\"   Length of updated_unscaled after Day {day}: {len(updated_unscaled)}\")\n",
    "                print(f\"   Number of NaNs after feature engineering: {updated_unscaled.isna().sum().sum()}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" - Error at Day {day}: {e}\")\n",
    "                break  # Exit the loop if an error occurs\n",
    "\n",
    "        # Verify the number of predictions\n",
    "        num_predictions = len(forecast_results[stock])\n",
    "        print(f\"{stock}: Number of predictions = {num_predictions}, Expected = {forecast_days}\")\n",
    "\n",
    "        # Truncate excess predictions if any\n",
    "        if num_predictions > forecast_days:\n",
    "            print(f\"{stock}: Truncating {num_predictions - forecast_days} excess predictions.\")\n",
    "            forecast_results[stock] = forecast_results[stock][:forecast_days]\n",
    "        elif num_predictions < forecast_days:\n",
    "            print(f\"{stock}: Missing {forecast_days - num_predictions} predictions.\")\n",
    "            # Optionally, handle missing predictions\n",
    "            # For now, we'll skip saving forecasts for this stock\n",
    "            continue\n",
    "\n",
    "        # Create Forecast DataFrame\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'Day': range(1, forecast_days + 1),\n",
    "            f'{stock}_Predicted': forecast_results[stock]\n",
    "        })\n",
    "\n",
    "        # Save Forecast\n",
    "        forecast_save_path = os.path.join(forecast_save_dir, f'future_forecasts_{stock}.csv')\n",
    "        forecast_df.to_csv(forecast_save_path, index=False)\n",
    "        print(f\" - Forecast saved at '{forecast_save_path}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" - Error forecasting for {stock}: {e}\")\n",
    "\n",
    "# Display a sample of forecast_results\n",
    "for stock in models_per_stock.keys():\n",
    "    preds = forecast_results.get(stock, [])\n",
    "    if preds:\n",
    "        print(f\"\\nSample Predictions for {stock}: {preds[:5]} ...\")\n",
    "    else:\n",
    "        print(f\"\\nNo predictions available for {stock}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed971a0b-f6b9-4161-aca7-a8ae0b89a58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data for AAPL:\n",
      " - Forecast file for AAPL not found at '../models/future_forecasts/future_forecasts_AAPL.csv'.\n",
      " - Loaded historical data for AAPL from '../data/stock_data/AAPL_daily.csv'. Training Shape: (2484, 6), Validation Shape: (30, 6)\n",
      "\n",
      "Loading data for MSFT:\n",
      " - Forecast file for MSFT not found at '../models/future_forecasts/future_forecasts_MSFT.csv'.\n",
      " - Loaded historical data for MSFT from '../data/stock_data/MSFT_daily.csv'. Training Shape: (2484, 6), Validation Shape: (30, 6)\n",
      "\n",
      "Loading data for GOOGL:\n",
      " - Forecast file for GOOGL not found at '../models/future_forecasts/future_forecasts_GOOGL.csv'.\n",
      " - Loaded historical data for GOOGL from '../data/stock_data/GOOGL_daily.csv'. Training Shape: (2484, 6), Validation Shape: (30, 6)\n",
      "\n",
      "Loading data for AMZN:\n",
      " - Forecast file for AMZN not found at '../models/future_forecasts/future_forecasts_AMZN.csv'.\n",
      " - Loaded historical data for AMZN from '../data/stock_data/AMZN_daily.csv'. Training Shape: (2484, 6), Validation Shape: (30, 6)\n",
      "\n",
      "Inspecting data for AAPL:\n",
      "Training DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2479 2024-09-11  221.460007  223.089996  217.889999  222.660004  44587100\n",
      "2480 2024-09-12  222.500000  223.550003  219.820007  222.770004  37498200\n",
      "2481 2024-09-13  223.580002  224.039993  221.910004  222.500000  36766600\n",
      "2482 2024-09-16  216.539993  217.220001  213.919998  216.320007  59357400\n",
      "2483 2024-09-17  215.750000  216.899994  214.500000  216.789993  45519300\n",
      "Validation DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2509 2024-10-23  234.080002  235.139999  227.759995  230.759995  52287000\n",
      "2510 2024-10-24  229.979996  230.820007  228.410004  230.570007  31109500\n",
      "2511 2024-10-25  229.740005  233.220001  229.570007  231.410004  38802300\n",
      "2512 2024-10-28  233.320007  234.729996  232.550003  233.399994  36087100\n",
      "2513 2024-10-29  233.100006  234.330002  232.320007  233.669998  35332800\n",
      "\n",
      "Inspecting data for MSFT:\n",
      "Training DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2479 2024-09-11  415.500000  423.989990  409.579987  423.040009  19266900\n",
      "2480 2024-09-12  423.309998  427.369995  419.750000  427.000000  17418800\n",
      "2481 2024-09-13  425.829987  431.829987  425.459991  430.589996  15874600\n",
      "2482 2024-09-16  430.600006  433.529999  428.220001  431.339996  13834700\n",
      "2483 2024-09-17  440.230011  441.850006  432.269989  435.149994  18874200\n",
      "Validation DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2509 2024-10-23  430.859985  431.079987  422.529999  424.600006  19654400\n",
      "2510 2024-10-24  425.329987  425.980011  422.399994  424.730011  13581600\n",
      "2511 2024-10-25  426.760010  432.519989  426.570007  428.149994  16899100\n",
      "2512 2024-10-28  431.660004  431.940002  426.299988  426.589996  14882400\n",
      "2513 2024-10-29  428.000000  433.170013  425.799988  431.950012  17581800\n",
      "\n",
      "Inspecting data for GOOGL:\n",
      "Training DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2479 2024-09-11  149.919998  151.500000  147.520004  151.160004  29607700\n",
      "2480 2024-09-12  153.800003  154.820007  152.649994  154.690002  29695000\n",
      "2481 2024-09-13  155.429993  158.380005  155.210007  157.460007  29591200\n",
      "2482 2024-09-16  157.309998  158.250000  156.600006  158.059998  18379800\n",
      "2483 2024-09-17  159.020004  160.550003  158.380005  159.320007  20715600\n",
      "Validation DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2509 2024-10-23  164.759995  165.820007  161.929993  162.779999  18280500\n",
      "2510 2024-10-24  162.830002  163.330002  161.009995  162.720001  22412500\n",
      "2511 2024-10-25  163.669998  165.589996  163.419998  165.270004  19828900\n",
      "2512 2024-10-28  168.750000  168.750000  163.949997  166.720001  32138600\n",
      "2513 2024-10-29  167.729996  170.380005  167.089996  169.679993  41612900\n",
      "\n",
      "Inspecting data for AMZN:\n",
      "Training DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2479 2024-09-11  180.100006  184.990005  175.729996  184.520004  42564700\n",
      "2480 2024-09-12  184.800003  187.410004  183.539993  187.000000  33622500\n",
      "2481 2024-09-13  187.000000  188.500000  185.910004  186.490005  26495400\n",
      "2482 2024-09-16  185.289993  185.809998  183.360001  184.889999  26065500\n",
      "2483 2024-09-17  186.850006  189.449997  186.139999  186.880005  26091700\n",
      "Validation DataFrame Tail:\n",
      "           Date        Open        High         Low       Close    Volume\n",
      "2509 2024-10-23  188.850006  189.160004  183.690002  184.710007  31937100\n",
      "2510 2024-10-24  185.250000  187.110001  183.860001  186.380005  21647400\n",
      "2511 2024-10-25  187.850006  190.449997  187.529999  187.830002  29362100\n",
      "2512 2024-10-28  189.570007  190.210007  188.210007  188.389999  27930800\n",
      "2513 2024-10-29  188.580002  191.460007  187.820007  190.830002  35534000\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Loading Forecasts and Historical Data\n",
    "\n",
    "def load_forecast(stock, forecast_dir):\n",
    "    forecast_path = os.path.join(forecast_dir, f'future_forecasts_{stock}.csv')\n",
    "    if not os.path.exists(forecast_path):\n",
    "        print(f\" - Forecast file for {stock} not found at '{forecast_path}'.\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(forecast_path)\n",
    "        print(f\" - Loaded forecast for {stock} from '{forecast_path}'. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\" - Error loading forecast for {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_historical_data(stock, raw_data_dir, validation_days=30):\n",
    "    historical_path = os.path.join(raw_data_dir, f\"{stock}_daily.csv\")\n",
    "    if not os.path.exists(historical_path):\n",
    "        print(f\" - Historical data for {stock} not found at '{historical_path}'.\")\n",
    "        return None, None\n",
    "    try:\n",
    "        df = pd.read_csv(historical_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df.dropna(subset=['Date'], inplace=True)\n",
    "        df.sort_values('Date', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        if len(df) < validation_days + 1:\n",
    "            print(f\" - Not enough data for {stock} to perform backtesting. Required: {validation_days + 1}, Available: {len(df)}\")\n",
    "            return None, None\n",
    "        \n",
    "        training_df = df.iloc[:-validation_days].copy()\n",
    "        validation_df = df.iloc[-validation_days:].copy()\n",
    "        \n",
    "        print(f\" - Loaded historical data for {stock} from '{historical_path}'. Training Shape: {training_df.shape}, Validation Shape: {validation_df.shape}\")\n",
    "        return training_df, validation_df\n",
    "    except Exception as e:\n",
    "        print(f\" - Error loading historical data for {stock}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Define directories\n",
    "forecast_dir = '../models/future_forecasts'\n",
    "raw_data_dir = '../data/stock_data'  # Ensure this path is correct relative to your notebook\n",
    "\n",
    "# List of stocks\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
    "\n",
    "# Initialize dictionaries to store forecasts and historical data\n",
    "forecasts = {}\n",
    "historicals = {}\n",
    "\n",
    "# Load forecasts and historical data\n",
    "for stock in stocks:\n",
    "    print(f\"\\nLoading data for {stock}:\")\n",
    "    forecasts[stock] = load_forecast(stock, forecast_dir)\n",
    "    historicals[stock] = load_historical_data(stock, raw_data_dir, validation_days=30)\n",
    "\n",
    "# Inspect loaded data (Optional but recommended)\n",
    "for stock in stocks:\n",
    "    print(f\"\\nInspecting data for {stock}:\")\n",
    "    forecast_df = forecasts.get(stock)\n",
    "    historical_data = historicals.get(stock)\n",
    "    \n",
    "    if historical_data is not None:\n",
    "        training_df, validation_df = historical_data\n",
    "    else:\n",
    "        training_df, validation_df = None, None\n",
    "    \n",
    "    if forecast_df is not None:\n",
    "        print(\"Forecast DataFrame Head:\")\n",
    "        print(forecast_df.head())\n",
    "    \n",
    "    if training_df is not None:\n",
    "        print(\"Training DataFrame Tail:\")\n",
    "        print(training_df.tail())\n",
    "    \n",
    "    if validation_df is not None:\n",
    "        print(\"Validation DataFrame Tail:\")\n",
    "        print(validation_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ef105-bd4a-4720-9f79-7a5b8cb6e629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define directories (adjust paths as necessary)\n",
    "forecast_dir = '../models/future_forecasts'\n",
    "raw_data_dir = '../data/stock_data'  # Ensure this path is correct relative to your notebook\n",
    "\n",
    "# Function to load forecasts\n",
    "def load_forecast(stock, forecast_dir):\n",
    "    forecast_path = os.path.join(forecast_dir, f'future_forecasts_{stock}.csv')\n",
    "    if not os.path.exists(forecast_path):\n",
    "        print(f\" - Forecast file for {stock} not found at '{forecast_path}'.\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(forecast_path)\n",
    "        print(f\" - Loaded forecast for {stock} from '{forecast_path}'. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\" - Error loading forecast for {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to load historical data\n",
    "def load_historical_data(stock, raw_data_dir, validation_days=30):\n",
    "    historical_path = os.path.join(raw_data_dir, f\"{stock}_daily.csv\")\n",
    "    if not os.path.exists(historical_path):\n",
    "        print(f\" - Historical data for {stock} not found at '{historical_path}'.\")\n",
    "        return None, None\n",
    "    try:\n",
    "        df = pd.read_csv(historical_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df.dropna(subset=['Date'], inplace=True)\n",
    "        df.sort_values('Date', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        if len(df) < validation_days + 1:\n",
    "            print(f\" - Not enough data for {stock} to perform backtesting. Required: {validation_days + 1}, Available: {len(df)}\")\n",
    "            return None, None\n",
    "        \n",
    "        training_df = df.iloc[:-validation_days].copy()\n",
    "        validation_df = df.iloc[-validation_days:].copy()\n",
    "        \n",
    "        print(f\" - Loaded historical data for {stock} from '{historical_path}'. Training Shape: {training_df.shape}, Validation Shape: {validation_df.shape}\")\n",
    "        return training_df, validation_df\n",
    "    except Exception as e:\n",
    "        print(f\" - Error loading historical data for {stock}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize dictionaries to store forecasts and historical data\n",
    "forecasts = {}\n",
    "historicals = {}\n",
    "\n",
    "# Load forecasts and historical data\n",
    "for stock in stocks:\n",
    "    print(f\"\\nLoading data for {stock}:\")\n",
    "    forecasts[stock] = load_forecast(stock, forecast_dir)\n",
    "    historicals[stock] = load_historical_data(stock, raw_data_dir, validation_days=30)\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_rows', None)       # Display all rows\n",
    "pd.set_option('display.max_columns', None)    # Display all columns\n",
    "pd.set_option('display.width', None)          # No wrapping in output\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)  # Format floats\n",
    "\n",
    "# Plotting the forecasts alongside historical data\n",
    "for stock in stocks:\n",
    "    forecast_df = forecasts.get(stock)\n",
    "    historical_data = historicals.get(stock)\n",
    "    \n",
    "    if historical_data is not None and forecast_df is not None:\n",
    "        training_df, validation_df = historical_data\n",
    "        \n",
    "        # Combine training and validation data\n",
    "        historical_df = pd.concat([training_df, validation_df], ignore_index=True)\n",
    "        historical_df['Date'] = pd.to_datetime(historical_df['Date'])\n",
    "        \n",
    "        # Get the last date from the historical data\n",
    "        last_historical_date = historical_df['Date'].max()\n",
    "        \n",
    "        # Generate future dates for forecasts\n",
    "        forecast_days = forecast_df.shape[0]\n",
    "        \n",
    "        # Use custom business days to account for weekends and US Federal Holidays\n",
    "        us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "        future_dates = pd.date_range(start=last_historical_date + pd.Timedelta(days=1), periods=forecast_days, freq=us_bd)\n",
    "        \n",
    "        # Add dates to forecast_df\n",
    "        forecast_df['Date'] = future_dates\n",
    "        forecast_df.rename(columns={f'{stock}_Predicted': 'Predicted_Close'}, inplace=True)\n",
    "        \n",
    "        # Merge historical and forecast data\n",
    "        combined_df = pd.merge(historical_df[['Date', 'Close']], forecast_df[['Date', 'Predicted_Close']], on='Date', how='outer')\n",
    "        combined_df.sort_values('Date', inplace=True)\n",
    "        combined_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Focus on the last year of data\n",
    "        one_year_ago = last_historical_date - pd.DateOffset(years=1)\n",
    "        mask = combined_df['Date'] >= one_year_ago\n",
    "        combined_df_last_year = combined_df.loc[mask].reset_index(drop=True)\n",
    "        \n",
    "        # Print out the combined DataFrame for the last year\n",
    "        print(f\"\\nCombined Data for {stock} - Last Year:\")\n",
    "        print(combined_df_last_year[['Date', 'Close', 'Predicted_Close']].to_string(index=False))\n",
    "        \n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(14,7))\n",
    "        plt.plot(combined_df_last_year['Date'], combined_df_last_year['Close'], label='Actual Close Prices')\n",
    "        plt.plot(combined_df_last_year['Date'], combined_df_last_year['Predicted_Close'], label='Predicted Close Prices', linestyle='--')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.title(f'Stock Price Prediction for {stock} - Last Year')\n",
    "        plt.axvline(x=last_historical_date, color='grey', linestyle='--', label='Forecast Start')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Data not available for {stock}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f3d5f-d2c6-4aff-8a92-da616cc17b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Set the model directory path\n",
    "model_dir = '../models/meta_model'\n",
    "\n",
    "# Define the model path\n",
    "stock_symbol = 'AAPL'\n",
    "model_path = os.path.join(model_dir, f'stacking_meta_model_{stock_symbol}.pkl')\n",
    "\n",
    "# Try loading the model\n",
    "try:\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    print(f\"Meta model for {stock_symbol} loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading meta model for {stock_symbol}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99180474-0a29-4005-8675-f81261bdac15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set the model directory path\n",
    "model_dir = '../models/meta_model'\n",
    "\n",
    "# Define the model path\n",
    "stock_symbol = 'AAPL'\n",
    "model_path = os.path.join(model_dir, f'stacking_meta_model_{stock_symbol}.pkl')\n",
    "\n",
    "# Try loading the model\n",
    "try:\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    print(f\"Meta model for {stock_symbol} loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading meta model for {stock_symbol}: {e}\")\n",
    "\n",
    "# Example input features for testing\n",
    "gru_prediction = 0.5   # Example GRU model prediction\n",
    "lstm_prediction = 0.6  # Example LSTM model prediction\n",
    "rf_prediction = 0.4    # Example Random Forest model prediction\n",
    "xgb_prediction = 0.7   # Example XGBoost model prediction\n",
    "\n",
    "# Combine predictions into a DataFrame to match the trained model's feature names\n",
    "predictions_df = pd.DataFrame({\n",
    "    'XGB_Pred': [xgb_prediction],\n",
    "    'RF_Pred': [rf_prediction],\n",
    "    'LSTM_Pred': [lstm_prediction],\n",
    "    'GRU_Pred': [gru_prediction]\n",
    "})\n",
    "\n",
    "# Make a prediction using the meta-model\n",
    "try:\n",
    "    final_prediction = loaded_model.predict(predictions_df)[0]\n",
    "    print(f\"Meta-model final prediction: {final_prediction}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error making prediction with the meta model: {e}\")\n",
    "\n",
    "# (Optional) If you have a scaler to inverse transform the prediction, include it as well\n",
    "try:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler_y = joblib.load('../models/scalers/minmax_scaler_y_AAPL.joblib')\n",
    "    final_prediction_rescaled = scaler_y.inverse_transform([[final_prediction]])[0][0]\n",
    "    print(f\"Final prediction rescaled to original scale: {final_prediction_rescaled}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with inverse scaling: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf8c12-266e-4643-ae69-bbef348c399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Calculating and Summarizing Evaluation Metrics via Backtesting\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"Calculate evaluation metrics between actual and predicted values.\"\"\"\n",
    "    rmse = mean_squared_error(actual, predicted, squared=False)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    mape = (abs((actual - predicted) / actual).mean()) * 100\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "def inverse_scale_prediction(scaler_y, prediction_scaled):\n",
    "    \"\"\"Inverse scale the prediction using scaler_y.\"\"\"\n",
    "    return scaler_y.inverse_transform([[prediction_scaled]])[0][0]\n",
    "\n",
    "def evaluate_forecasts_backtesting(models_per_stock, forecast_days=30):\n",
    "    \"\"\"Evaluate forecasts against actual data using backtesting.\"\"\"\n",
    "    metrics_summary = {}\n",
    "    comparison_tables = {}\n",
    "\n",
    "    for stock, data in models_per_stock.items():\n",
    "        print(f\"\\nEvaluating Forecast for {stock}:\")\n",
    "        training_df, validation_df = data['training_validation']\n",
    "\n",
    "        if training_df is None or validation_df is None:\n",
    "            print(f\" - Insufficient data for {stock}. Skipping evaluation.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Extract models and scalers\n",
    "            xgb_model, rf_model, lstm_model, gru_model, meta_model, scaler_X, scaler_y = data['models']\n",
    "            \n",
    "            # Prepare initial input (last 'timesteps' days from training data)\n",
    "            timesteps = 60\n",
    "            initial_input_unscaled = training_df.tail(timesteps).copy()\n",
    "            updated_unscaled = initial_input_unscaled.copy()\n",
    "            \n",
    "            predicted_prices = []\n",
    "            \n",
    "            for day in range(forecast_days):\n",
    "                # Generate features\n",
    "                xgb_rf_features_scaled, lstm_gru_features_scaled, latest_features = generate_next_day_features(\n",
    "                    updated_unscaled, scaler_X, timesteps=timesteps\n",
    "                )\n",
    "                \n",
    "                # Base model predictions\n",
    "                xgb_pred_scaled = xgb_model.predict(xgb_rf_features_scaled)[0]\n",
    "                rf_pred_scaled = rf_model.predict(xgb_rf_features_scaled)[0]\n",
    "                lstm_pred_scaled = lstm_model.predict(lstm_gru_features_scaled)[0][0]\n",
    "                gru_pred_scaled = gru_model.predict(lstm_gru_features_scaled)[0][0]\n",
    "                \n",
    "                # Meta-model prediction\n",
    "                meta_features = pd.DataFrame([[xgb_pred_scaled, rf_pred_scaled, lstm_pred_scaled, gru_pred_scaled]])\n",
    "                meta_pred_scaled = meta_model.predict(meta_features)[0]\n",
    "                meta_pred = inverse_scale_prediction(scaler_y, meta_pred_scaled)\n",
    "                \n",
    "                # Append prediction\n",
    "                predicted_prices.append(meta_pred)\n",
    "                \n",
    "                # Update the data with the new prediction\n",
    "                new_row = latest_features.copy()\n",
    "                new_row['Close'] = meta_pred\n",
    "                new_row['Date'] = updated_unscaled['Date'].max() + BDay(1)\n",
    "                new_row_df = pd.DataFrame([new_row])\n",
    "                updated_unscaled = pd.concat([updated_unscaled, new_row_df], ignore_index=True)\n",
    "                \n",
    "                # Recalculate derived features\n",
    "                updated_unscaled = add_close_price_features(updated_unscaled)\n",
    "                updated_unscaled = updated_unscaled.tail(timesteps).reset_index(drop=True)\n",
    "            \n",
    "            # Actual vs Predicted\n",
    "            actual = validation_df['Close'].values\n",
    "            predicted = predicted_prices\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(actual, predicted)\n",
    "            metrics_summary[stock] = metrics\n",
    "            \n",
    "            # Create comparison table\n",
    "            comparison_df = pd.DataFrame({\n",
    "                'Date': validation_df['Date'],\n",
    "                'Actual_Close': actual,\n",
    "                'Predicted_Close': predicted\n",
    "            })\n",
    "            comparison_tables[stock] = comparison_df\n",
    "            \n",
    "            # Display metrics and comparison\n",
    "            print(f\" - RMSE: {metrics['RMSE']:.4f}\")\n",
    "            print(f\" - MAE: {metrics['MAE']:.4f}\")\n",
    "            print(f\" - R²: {metrics['R2']:.4f}\")\n",
    "            print(f\" - MAPE: {metrics['MAPE']:.2f}%\")\n",
    "            \n",
    "            print(f\"\\nComparison of Actual vs. Predicted Close Prices for {stock}:\")\n",
    "            display(comparison_df.head())\n",
    "            display(comparison_df.tail())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" - Error evaluating forecast for {stock}: {e}\")\n",
    "    \n",
    "    if metrics_summary:\n",
    "        # Summary DataFrame\n",
    "        metrics_df = pd.DataFrame(metrics_summary).T\n",
    "        metrics_df = metrics_df[['RMSE', 'MAE', 'R2', 'MAPE']]\n",
    "        print(\"\\nOverall Evaluation Metrics for All Stocks:\")\n",
    "        print(metrics_df)\n",
    "        \n",
    "        # Save metrics summary\n",
    "        summary_save_path = os.path.join(forecast_dir, 'overall_evaluation_metrics_backtesting.csv')\n",
    "        metrics_df.to_csv(summary_save_path)\n",
    "        print(f\"\\n - Overall Evaluation Metrics table saved as '{summary_save_path}'.\")\n",
    "        \n",
    "        # Save comparison tables\n",
    "        for stock, comp_df in comparison_tables.items():\n",
    "            comp_save_path = os.path.join(forecast_dir, f'comparison_actual_predicted_{stock}.csv')\n",
    "            comp_df.to_csv(comp_save_path, index=False)\n",
    "            print(f\" - Comparison table for {stock} saved at '{comp_save_path}'.\")\n",
    "        \n",
    "        return metrics_df, comparison_tables\n",
    "    else:\n",
    "        print(\"\\nNo evaluation metrics to summarize.\")\n",
    "        return pd.DataFrame(), {}\n",
    "\n",
    "# Placeholder Functions\n",
    "\n",
    "def generate_next_day_features(updated_unscaled, scaler_X, timesteps=60):\n",
    "    \"\"\"Generate features for the next day based on updated data.\"\"\"\n",
    "    # Example: Using only 'Close' price for simplicity\n",
    "    xgb_rf_features = updated_unscaled['Close'].values[-timesteps:].reshape(1, -1)\n",
    "    xgb_rf_features_scaled = scaler_X.transform(xgb_rf_features)\n",
    "    \n",
    "    lstm_gru_features = updated_unscaled['Close'].values[-timesteps:].reshape(1, timesteps, 1)\n",
    "    lstm_gru_features_scaled = scaler_X.transform(lstm_gru_features.reshape(-1, 1)).reshape(1, timesteps, 1)\n",
    "    \n",
    "    latest_features = updated_unscaled.iloc[-1].to_dict()\n",
    "    \n",
    "    return xgb_rf_features_scaled, lstm_gru_features_scaled, latest_features\n",
    "\n",
    "def add_close_price_features(df):\n",
    "    \"\"\"Add or recalculate any derived features based on the 'Close' price.\"\"\"\n",
    "    # Example: Adding moving averages\n",
    "    df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['MA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    \n",
    "    # Handle NaN values\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute Backtesting\n",
    "metrics_summary_df, comparison_tables = evaluate_forecasts_backtesting(models_per_stock, forecast_days=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
